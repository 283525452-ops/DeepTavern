# scripts/test_harvester.py
import sys
import os
import time

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.harvester.crawler import WebCrawler
from core.harvester.cleaner import LocalCleaner

def test_batch_pipeline():
    print("\n" + "="*50)
    print("ğŸ§ª æµ‹è¯•: å¤šæºèšåˆæŠ“å–æµç¨‹")
    print("="*50)
    
    keyword = "é»‘ç¥è¯æ‚Ÿç©º ç¬¬ä¸‰ç«  å‰§æƒ…è§£æ"
    crawler = WebCrawler()
    cleaner = LocalCleaner()
    
    # 1. æŠ“å–
    print(f"1ï¸âƒ£ æ­£åœ¨æœç´¢å¹¶æŠ“å– 3 ä¸ªç½‘é¡µ: {keyword} ...")
    results = crawler.search_and_fetch(keyword, max_results=3)
    
    if not results:
        print("âŒ æŠ“å–å¤±è´¥")
        return

    print(f"ğŸ“¦ æˆåŠŸæŠ“å– {len(results)} ä¸ªç½‘é¡µã€‚")
    
    # 2. æ„é€ æ•°æ®
    batch_data = [{'source': r['domain'], 'text': r['content']} for r in results]
    
    # 3. èšåˆ
    print(f"2ï¸âƒ£ æ­£åœ¨å‘é€ç»™ LLM è¿›è¡Œèšåˆæ€»ç»“ (è¾“å…¥æ€»é•¿: {sum(len(x['text']) for x in batch_data)} å­—ç¬¦)...")
    start = time.time()
    summary = cleaner.clean_batch(batch_data, keyword)
    end = time.time()
    
    print(f"\nâ±ï¸ LLM è€—æ—¶: {end - start:.2f} ç§’")
    
    if summary:
        print("\nâœ… [æ·±åº¦ç™¾ç§‘æ¡ç›®]:")
        print("-" * 40)
        print(summary)
        print("-" * 40)
    else:
        print("âŒ èšåˆå¤±è´¥")

if __name__ == "__main__":
    test_batch_pipeline()
