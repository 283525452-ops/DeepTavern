# core/workflow/backend_manager.py
"""
DeepTavern åå°ä»»åŠ¡ç®¡ç†å™¨ v4.5
- é€‚é…æ‰©å±•çŠ¶æ€ç³»ç»Ÿ
- çŠ¶æ€å¼•æ“è§£ææ›´ä¸°å¯Œçš„çŠ¶æ€å˜æ›´
"""

import json
import threading
import re
import time
import uuid
from typing import Dict, Any, Optional

from core.llm.api_client import APILLM
from core.llm.local_direct import LocalDirectLLM
from core.database.sqlite_manager import SQLiteManager
from core.database.vector_store import VectorStore
from core.database.graph_manager import GraphManager
from core.harvester.scheduler import KnowledgeHarvester
from core.workflow.prompts import get_prompt, PROMPT_GRAPH_EXTRACTOR
from config.settings import MODEL_CONFIG
from core.utils.logger import logger


class BackendManager:
    """
    åå°ä»»åŠ¡ç®¡ç†å™¨
    è´Ÿè´£ï¼šçŠ¶æ€æ›´æ–°ã€è®°å¿†å‹ç¼©ã€å›¾è°±æå–ã€çŸ¥è¯†çˆ¬å–
    """

    def __init__(self):
        logger.info("âš™ï¸ [åå°] åˆå§‹åŒ–åå°å·¥ä½œæµç®¡ç†å™¨...")
        
        self.db = SQLiteManager()
        self.vec = VectorStore()
        self.graph = GraphManager()

        # åŠ è½½å„ä¸ªåå° LLM
        def load_llm(role_key):
            conf = MODEL_CONFIG.get(role_key, {})
            if not conf:
                return APILLM({"model": "mock", "api_key": "none", "base_url": ""})
            model_path = str(conf.get("model", "")).lower()
            if model_path.endswith(".gguf"):
                return LocalDirectLLM(config=conf)
            else:
                return APILLM(conf)

        self.status_bot = load_llm("status")
        self.left_brain = load_llm("left_brain")
        self.right_brain = load_llm("critic")
        self.historian = load_llm("historian")
        self.sociologist = load_llm("sociologist")
        self.graph_extractor = load_llm("sociologist")  # å¤ç”¨

        # çŸ¥è¯†çˆ¬è™«
        self.harvester = KnowledgeHarvester()
        self.harvester.start()

        logger.info("âœ… [åå°] åå°æœåŠ¡å°±ç»ª")

    def _clean_json(self, text: str) -> Optional[Dict]:
        """ä» LLM è¾“å‡ºä¸­æå– JSON"""
        if not text:
            return None
        
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # å°è¯•æå– markdown ä»£ç å—
        match = re.search(r"```(?:json)?\s*([\s\S]*?)```", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1).strip())
            except json.JSONDecodeError:
                pass
        
        # å°è¯•æå–è£¸ JSON
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass
        
        return None

    def _deep_merge_state(self, base: Dict, update: Dict) -> Dict:
        """
        æ·±åº¦åˆå¹¶çŠ¶æ€
        update ä¸­çš„å­—æ®µä¼šè¦†ç›–/æ›´æ–° base ä¸­çš„å¯¹åº”å­—æ®µ
        """
        result = json.loads(json.dumps(base))  # æ·±æ‹·è´
        
        for key, value in update.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                # é€’å½’åˆå¹¶å­—å…¸
                result[key] = self._deep_merge_state(result[key], value)
            elif key in result and isinstance(result[key], list) and isinstance(value, list):
                # åˆ—è¡¨ç›´æ¥æ›¿æ¢ï¼ˆæˆ–è€…å¯ä»¥é€‰æ‹©åˆå¹¶ï¼‰
                result[key] = value
            else:
                result[key] = value
        
        return result

    # ==========================================
    # çŠ¶æ€æ›´æ–°ä»»åŠ¡
    # ==========================================

    def _task_status_update(self, user_input: str, narr_output: str) -> str:
        """
        çŠ¶æ€æ›´æ–°ä»»åŠ¡
        è§£æå¯¹è¯ï¼Œæ›´æ–°å®Œæ•´çš„æ¸¸æˆçŠ¶æ€
        """
        current_state = self.db.get_current_state()
        
        # ç¡®ä¿çŠ¶æ€ç»“æ„å®Œæ•´
        current_state = self._ensure_state_structure(current_state)
        
        prompt = get_prompt("status").format(
            current_state=json.dumps(current_state, ensure_ascii=False, indent=2),
            user_input=user_input,
            narrator_output=narr_output
        )
        
        logger.info("â³ [åå°] Status æ¨¡å‹æ­£åœ¨åˆ†æçŠ¶æ€å˜åŒ–...")
        
        try:
            raw = self.status_bot.generate([{"role": "user", "content": prompt}])
            data = self._clean_json(raw)
            
            if not data:
                logger.warning("âš ï¸ [çŠ¶æ€æ›´æ–°] JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´æ¨è¿›")
                # é»˜è®¤æ¨è¿› 10 åˆ†é’Ÿ
                return self._advance_time_default(current_state)
            
            timeline_tag = data.get("timeline_tag", "Unknown")
            state_update = data.get("state", {})
            
            if state_update:
                # æ·±åº¦åˆå¹¶çŠ¶æ€
                new_state = self._deep_merge_state(current_state, state_update)
                
                # åŒæ­¥ world_time å’Œ timeline_tag
                if "world_time" in state_update:
                    wt = state_update["world_time"]
                    if isinstance(wt, dict):
                        timeline_tag = f"Day {wt.get('day', 1)}, {wt.get('hour', 8):02d}:{wt.get('minute', 0):02d}"
                
                # ä¿å­˜çŠ¶æ€
                self.db.save_state(new_state, diff_summary=f"Time: {timeline_tag}")
                
                # æ—¥å¿—è®°å½•é‡è¦å˜åŒ–
                self._log_state_changes(current_state, new_state)
                
                logger.info(f"ğŸ•’ [çŠ¶æ€æ›´æ–°] æ—¶é—´æ¨è¿›è‡³: {timeline_tag}")
            else:
                timeline_tag = self._advance_time_default(current_state)
            
            return timeline_tag
            
        except Exception as e:
            logger.error(f"âŒ [çŠ¶æ€æ›´æ–°] é”™è¯¯: {e}")
            return self._advance_time_default(current_state)

    def _advance_time_default(self, current_state: Dict) -> str:
        """é»˜è®¤æ—¶é—´æ¨è¿›ï¼ˆ10åˆ†é’Ÿï¼‰"""
        world_time = current_state.get("world_time", {})
        
        if isinstance(world_time, dict):
            day = world_time.get("day", 1)
            hour = world_time.get("hour", 8)
            minute = world_time.get("minute", 0)
            
            minute += 10
            if minute >= 60:
                minute -= 60
                hour += 1
            if hour >= 24:
                hour -= 24
                day += 1
            
            world_time["day"] = day
            world_time["hour"] = hour
            world_time["minute"] = minute
            
            current_state["world_time"] = world_time
            
            # æ›´æ–° time_of_day
            if "scene" in current_state:
                current_state["scene"]["time_of_day"] = self._get_time_of_day(hour)
            
            self.db.save_state(current_state, diff_summary="Auto time advance")
            
            return f"Day {day}, {hour:02d}:{minute:02d}"
        else:
            return "Day 1, 08:00"

    def _get_time_of_day(self, hour: int) -> str:
        """æ ¹æ®å°æ—¶åˆ¤æ–­æ—¶æ®µ"""
        if 5 <= hour < 7:
            return "dawn"
        elif 7 <= hour < 12:
            return "morning"
        elif 12 <= hour < 17:
            return "afternoon"
        elif 17 <= hour < 20:
            return "evening"
        else:
            return "night"

    def _log_state_changes(self, old_state: Dict, new_state: Dict):
        """è®°å½•é‡è¦çš„çŠ¶æ€å˜åŒ–"""
        changes = []
        
        # HP å˜åŒ–
        old_hp = old_state.get("player", {}).get("hp", 100)
        new_hp = new_state.get("player", {}).get("hp", 100)
        if old_hp != new_hp:
            diff = new_hp - old_hp
            changes.append(f"HP: {old_hp} â†’ {new_hp} ({'+' if diff > 0 else ''}{diff})")
        
        # å…³ç³»å˜åŒ–
        old_rels = old_state.get("relationships", {})
        new_rels = new_state.get("relationships", {})
        for name in new_rels:
            if name not in old_rels:
                changes.append(f"æ–°å…³ç³»: {name}")
            elif new_rels[name] != old_rels.get(name):
                changes.append(f"å…³ç³»æ›´æ–°: {name}")
        
        # ç‰©å“å˜åŒ–
        old_inv = old_state.get("inventory", {})
        new_inv = new_state.get("inventory", {})
        for item in new_inv:
            if item not in old_inv:
                changes.append(f"è·å¾—ç‰©å“: {item}")
        for item in old_inv:
            if item not in new_inv:
                changes.append(f"å¤±å»ç‰©å“: {item}")
        
        # æŠ€èƒ½å˜åŒ–
        old_skills = old_state.get("skills", {})
        new_skills = new_state.get("skills", {})
        for skill in new_skills:
            if skill not in old_skills:
                changes.append(f"ä¹ å¾—æŠ€èƒ½: {skill}")
            elif isinstance(new_skills[skill], dict) and isinstance(old_skills.get(skill), dict):
                old_lvl = old_skills[skill].get("level", 1)
                new_lvl = new_skills[skill].get("level", 1)
                if new_lvl > old_lvl:
                    changes.append(f"æŠ€èƒ½å‡çº§: {skill} Lv.{old_lvl} â†’ Lv.{new_lvl}")
        
        # æ°›å›´å˜åŒ–
        old_atm = old_state.get("scene", {}).get("atmosphere", "")
        new_atm = new_state.get("scene", {}).get("atmosphere", "")
        if old_atm != new_atm and new_atm:
            changes.append(f"æ°›å›´å˜åŒ–: {old_atm} â†’ {new_atm}")
        
        if changes:
            logger.info(f"ğŸ“Š [çŠ¶æ€å˜åŒ–] {' | '.join(changes)}")

    def _ensure_state_structure(self, state: Dict) -> Dict:
        """ç¡®ä¿çŠ¶æ€ç»“æ„å®Œæ•´"""
        default_state = {
            "player": {
                "name": "Player",
                "hp": 100,
                "max_hp": 100,
                "mp": 50,
                "max_mp": 50,
                "status_effects": []
            },
            "skills": {},
            "inventory": {},
            "relationships": {},
            "scene": {
                "location": "æœªçŸ¥åœ°ç‚¹",
                "sub_location": "",
                "atmosphere": "æ—¥å¸¸",
                "weather": "æ™´æœ—",
                "time_of_day": "morning",
                "npcs_present": []
            },
            "world_time": {
                "day": 1,
                "hour": 8,
                "minute": 0
            },
            "narrator_persona": {
                "current_mood": "å¹³é™",
                "speech_style": "æ­£å¸¸"
            }
        }
        
        # åˆå¹¶ç¼ºå¤±çš„å­—æ®µ
        for key, value in default_state.items():
            if key not in state:
                state[key] = value
            elif isinstance(value, dict) and isinstance(state.get(key), dict):
                for sub_key, sub_value in value.items():
                    if sub_key not in state[key]:
                        state[key][sub_key] = sub_value
        
        # å…¼å®¹æ—§æ ¼å¼
        if "hp" in state and "player" not in state:
            state["player"] = {"hp": state.pop("hp"), "max_hp": 100}
        if "location" in state and "scene" not in state:
            state["scene"] = {"location": state.pop("location")}
        if isinstance(state.get("inventory"), list):
            old_inv = state["inventory"]
            state["inventory"] = {item: {"type": "item", "count": 1} for item in old_inv}
        if isinstance(state.get("world_time"), str):
            state["world_time"] = {"day": 1, "hour": 8, "minute": 0}
        
        return state

    # ==========================================
    # è®°å¿†å‹ç¼©ä»»åŠ¡
    # ==========================================

    def _task_recursive_summary(self, timeline_tag: str, session_id: str):
        """é€’å½’æ‘˜è¦ä»»åŠ¡"""
        msgs = self.db.get_unsummarized_messages(limit=5)
        if len(msgs) < 5:
            return

        logger.info(f"ğŸ“ [åå°] è§¦å‘é€’å½’æ€»ç»“ (å¤„ç† 5 æ¡æ¶ˆæ¯)...")
        raw_text = "\n".join([f"{m['role']}: {m['content']}" for m in msgs])

        # ä¸–ç•Œè§‚æ‹“å±•æ£€æµ‹
        try:
            expansion_prompt = (
                f"Analyze the following dialogue:\n{raw_text[:2000]}\n\n"
                "Identify ONE specific proper noun, event, or concept that needs external knowledge. "
                "Return ONLY the keyword. If nothing needs research, return 'NONE'."
            )
            
            keyword_raw = self.left_brain.generate([{"role": "user", "content": expansion_prompt}])
            keyword = keyword_raw.strip().replace('"', '').replace("'", "").split('\n')[0]
            
            if keyword and "NONE" not in keyword.upper() and len(keyword) < 30:
                logger.info(f"ğŸŒ [ä¸–ç•Œè§‚æ‹“å±•] è§¦å‘çˆ¬è™«: '{keyword}'")
                self.harvester.add_task(keyword, priority=5)
                
        except Exception as e:
            logger.error(f"âŒ [ä¸–ç•Œè§‚æ‹“å±•] å¤±è´¥: {e}")

        # å·¦è„‘å‹ç¼©
        left_prompt = get_prompt("left_brain").format(text=raw_text, time=timeline_tag)
        draft = self.left_brain.generate([{"role": "user", "content": left_prompt}])

        # å³è„‘å®¡æ ¸
        right_prompt = get_prompt("critic").format(draft=draft, original=raw_text)
        final_micro = self.right_brain.generate([{"role": "user", "content": right_prompt}])

        # ä¿å­˜å¾®è§‚è®°å¿†
        self.db.add_memory_node(final_micro, "MICRO", timeline_tag)
        self.db.mark_messages_summarized([m['id'] for m in msgs])

        # å‘é‡åŒ–
        vec_id = f"micro_{int(time.time())}_{uuid.uuid4().hex[:4]}"
        self.vec.add_memory(
            text=final_micro,
            metadata={
                "type": "episodic",
                "level": "MICRO",
                "timeline": timeline_tag,
                "session_id": session_id
            },
            memory_id=vec_id
        )
        logger.info(f"ğŸ’¾ [è®°å¿†å­˜å‚¨] å¾®è§‚æ€»ç»“å·²ä¿å­˜ | é¢„è§ˆ: {final_micro[:50]}...")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®è§‚æ€»ç»“
        micros = self.db.get_unmerged_micro_nodes(limit=10)
        if len(micros) >= 10:
            logger.info(f"ğŸ“š [åå°] è§¦å‘å®è§‚æ€»ç»“ (åˆå¹¶ 10 æ¡å¾®è§‚è®°å¿†)...")
            micro_text = "\n".join([f"[{m['timeline_tag']}] {m['summary_text']}" for m in micros])
            
            merge_prompt = get_prompt("right_brain_merge", 
                f"è¯·å°†ä»¥ä¸‹å¾®è§‚è®°å¿†åˆå¹¶æˆä¸€æ®µè¿è´¯çš„å®è§‚å™è¿°:\n{micro_text}")
            macro_summary = self.right_brain.generate([{"role": "user", "content": merge_prompt}])

            self.db.add_memory_node(macro_summary, "MACRO", micros[0]['timeline_tag'])
            self.db.mark_nodes_merged([m['id'] for m in micros])

            vec_id_macro = f"macro_{int(time.time())}_{uuid.uuid4().hex[:4]}"
            self.vec.add_memory(
                text=macro_summary,
                metadata={
                    "type": "episodic",
                    "level": "MACRO",
                    "session_id": session_id
                },
                memory_id=vec_id_macro
            )
            logger.info(f"ğŸ“œ [è®°å¿†å­˜å‚¨] å®è§‚æ€»ç»“å·²ç”Ÿæˆ | é¢„è§ˆ: {macro_summary[:50]}...")

            # å²å®˜è®°å½•
            self._task_historian(macro_summary)

    def _task_historian(self, macro_summary: str):
        """å²å®˜æ’°å†™ç« èŠ‚"""
        logger.info("ğŸ–‹ï¸ [åå°] å²å®˜æ­£åœ¨æ’°å†™ç« èŠ‚...")
        
        historian_prompt = get_prompt("historian").format(macro_content=macro_summary)
        saga = self.historian.generate([{"role": "user", "content": historian_prompt}])
        
        self.db.save_saga_entry(saga)
        logger.info("âœ… [å²å®˜] ç« èŠ‚å·²å½’æ¡£")

    # ==========================================
    # ç¤¾ä¼šå­¦åˆ†æä»»åŠ¡
    # ==========================================

    def _task_sociologist(self, user_input: str, narr_output: str):
        """ç¤¾ä¼šå­¦åˆ†æ"""
        if len(narr_output) < 50:
            return
        
        try:
            prompt = get_prompt("sociologist").format(
                current_graph="{}",
                interaction=f"User: {user_input}\nAI: {narr_output}"
            )
            self.sociologist.generate([{"role": "user", "content": prompt}])
        except Exception as e:
            logger.debug(f"[ç¤¾ä¼šå­¦åˆ†æ] {e}")

    # ==========================================
    # å›¾è°±æ›´æ–°ä»»åŠ¡
    # ==========================================

    def _task_update_graph(self, user_input: str, narr_output: str):
        """å›¾è°±ä¸‰å…ƒç»„æå–"""
        text = f"User: {user_input}\nNarrator: {narr_output}"
        if len(text) < 100:
            return

        prompt = PROMPT_GRAPH_EXTRACTOR.format(text=text)

        try:
            raw = self.graph_extractor.generate([{"role": "user", "content": prompt}])
            data = self._clean_json(raw)
            
            if not data:
                return
            
            triplets = data.get("triplets", [])
            
            count = 0
            preview_rels = []
            
            for t in triplets:
                src = t.get("source")
                rel = t.get("relation")
                tgt = t.get("target")
                desc = t.get("desc", "")
                
                if src and rel and tgt:
                    self.graph.add_triplet(src, rel, tgt, desc)
                    count += 1
                    if len(preview_rels) < 3:
                        preview_rels.append(f"({src}--{rel}-->{tgt})")

            if count > 0:
                logger.info(f"ğŸ•¸ï¸ [å›¾è°±æ›´æ–°] æ–°å¢ {count} æ¡å…³ç³»: {', '.join(preview_rels)}")
                
        except Exception as e:
            logger.error(f"âŒ [å›¾è°±æ›´æ–°] å¤±è´¥: {e}")

    # ==========================================
    # ä¸»å…¥å£
    # ==========================================

    def run_background_tasks(self, user_input: str, narr_output: str, 
                             search_query: str, session_id: str):
        """
        è¿è¡Œæ‰€æœ‰åå°ä»»åŠ¡
        """
        # 1. çŠ¶æ€æ›´æ–°ï¼ˆåŒæ­¥æ‰§è¡Œï¼Œè·å–æ—¶é—´æ ‡ç­¾ï¼‰
        timeline_tag = self._task_status_update(user_input, narr_output)

        # 2. å¹¶è¡Œæ‰§è¡Œå…¶ä»–ä»»åŠ¡
        tasks = [
            threading.Thread(
                target=self._task_recursive_summary,
                args=(timeline_tag, session_id),
                daemon=True
            ),
            threading.Thread(
                target=self._task_sociologist,
                args=(user_input, narr_output),
                daemon=True
            ),
            threading.Thread(
                target=self._task_update_graph,
                args=(user_input, narr_output),
                daemon=True
            )
        ]

        for t in tasks:
            t.start()
