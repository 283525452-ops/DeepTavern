Project Directory Structure:
==============================
DeepTavernV0.5/
    config_editor.py
    main.py
    merge_py.py
    monitor.py
    config/
        settings.py
    core/
        __init__.py
        database/
            graph_manager.py
            redis_manager.py
            schema.sql
            schema_rules.sql
            silicon_client.py
            sqlite_manager.py
            vector_store.py
        harvester/
            cleaner.py
            crawler.py
            scheduler.py
        llm/
            api_client.py
            base.py
            local_direct.py
            __init__.py
        utils/
            config_loader.py
            logger.py
            __init__.py
        workflow/
            backend_manager.py
            manager.py
            prompts.py
    data/
    logs/
    Redis/
    scripts/
        check_db.py
        fix_db.py
        ingest_gui.py
        ingest_preset.py
        test_harvester.py
==============================

========================================
File Path: .\config_editor.py
========================================

import sys
import json
import os
from copy import deepcopy

from PyQt6.QtCore import Qt, pyqtSignal, QThread
from PyQt6.QtWidgets import (QApplication, QFrame, QVBoxLayout, QHBoxLayout, 
                             QFileDialog, QWidget, QListWidget, QListWidgetItem,
                             QScrollArea)

from qfluentwidgets import (
    FluentWindow, NavigationItemPosition, FluentIcon as FIF,
    SubtitleLabel, StrongBodyLabel, BodyLabel, CaptionLabel,
    CardWidget, PrimaryPushButton, PushButton, LineEdit, 
    TextEdit, ComboBox, DoubleSpinBox, InfoBar, InfoBarPosition,
    TransparentToolButton
)

# å¼•å…¥æ¸…æ´—åŽç«¯é€»è¾‘
from scripts.ingest_preset import PresetIngester

CONFIG_FILE = "config.json"
TEMPLATE_FILE = "config.json.template"

# ============================================================================
# æ•°æ®ç®¡ç†ç±»
# ============================================================================
class ConfigData:
    """å•ä¾‹æ•°æ®ç®¡ç†"""
    _data = {}
    
    @classmethod
    def load(cls):
        path = CONFIG_FILE if os.path.exists(CONFIG_FILE) else TEMPLATE_FILE
        if not os.path.exists(path):
            cls._data = {"providers": {}, "vector": {}, "roles": []}
            return
            
        try:
            with open(path, 'r', encoding='utf-8') as f:
                cls._data = json.load(f)
        except Exception as e:
            print(f"Error loading config: {e}")

    @classmethod
    def save(cls):
        try:
            with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(cls._data, f, indent=4, ensure_ascii=False)
            return True
        except Exception as e:
            print(f"Error saving config: {e}")
            return False

    @classmethod
    def get_providers(cls):
        return cls._data.get("providers", {})
        
    @classmethod
    def get_provider_keys(cls):
        return list(cls._data.get("providers", {}).keys())

    @classmethod
    def set_providers(cls, providers):
        cls._data["providers"] = providers

    @classmethod
    def get_vector(cls):
        return cls._data.get("vector", {})

    @classmethod
    def set_vector(cls, vector):
        cls._data["vector"] = vector

    @classmethod
    def get_roles(cls):
        return cls._data.get("roles", [])

    @classmethod
    def set_roles(cls, roles):
        cls._data["roles"] = roles

# ============================================================================
# ç•Œé¢ 1: æœåŠ¡å•†é…ç½®
# ============================================================================
class ProviderInterface(QScrollArea):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("ProviderInterface")
        self.setWidgetResizable(True)
        self.setStyleSheet("QScrollArea {background: transparent; border: none;}")
        
        self.scroll_widget = QWidget()
        self.setWidget(self.scroll_widget)
        self.vlayout = QVBoxLayout(self.scroll_widget)
        self.vlayout.setContentsMargins(30, 20, 30, 20)
        self.vlayout.setSpacing(15)

        header = QHBoxLayout()
        header.addWidget(SubtitleLabel("LLM æœåŠ¡å•†é…ç½®", self))
        header.addStretch(1)
        self.add_btn = PrimaryPushButton(FIF.ADD, "æ·»åŠ æœåŠ¡å•†", self)
        self.add_btn.clicked.connect(self.add_provider_card)
        header.addWidget(self.add_btn)
        self.vlayout.addLayout(header)
        
        self.vlayout.addWidget(BodyLabel("é…ç½® API Key å’Œ Base URLã€‚è¿™äº›è®¾ç½®å°†è¢«æ¨¡åž‹å’Œå‘é‡åº“å¼•ç”¨ã€‚", self))
        self.vlayout.addSpacing(10)

        self.cards_layout = QVBoxLayout()
        self.vlayout.addLayout(self.cards_layout)
        self.vlayout.addStretch(1)
        
        self.cards = {}

    def load_data(self):
        while self.cards_layout.count():
            item = self.cards_layout.takeAt(0)
            if item.widget(): item.widget().deleteLater()
        self.cards = {}

        providers = ConfigData.get_providers()
        for key, data in providers.items():
            self._create_card(key, data)

    def _create_card(self, key, data):
        card = CardWidget(self.scroll_widget)
        layout = QVBoxLayout(card)
        
        h_layout = QHBoxLayout()
        key_edit = LineEdit()
        key_edit.setPlaceholderText("å”¯ä¸€æ ‡è¯† (å¦‚: silicon)")
        key_edit.setText(key)
        if key: key_edit.setReadOnly(True)
        
        del_btn = TransparentToolButton(FIF.DELETE, self)
        del_btn.clicked.connect(lambda: self._delete_card(key, card))
        
        h_layout.addWidget(StrongBodyLabel("ID:", self))
        h_layout.addWidget(key_edit)
        h_layout.addStretch(1)
        h_layout.addWidget(del_btn)
        layout.addLayout(h_layout)
        
        layout.addWidget(CaptionLabel("æ˜¾ç¤ºåç§°"))
        name_edit = LineEdit()
        name_edit.setText(data.get("name", ""))
        layout.addWidget(name_edit)

        layout.addWidget(CaptionLabel("Base URL"))
        url_edit = LineEdit()
        url_edit.setText(data.get("base_url", ""))
        url_edit.setPlaceholderText("https://api.example.com/v1")
        layout.addWidget(url_edit)

        layout.addWidget(CaptionLabel("API Key"))
        key_input = LineEdit()
        key_input.setText(data.get("api_key", ""))
        key_input.setEchoMode(LineEdit.EchoMode.Password)
        key_input.setPlaceholderText("sk-...")
        layout.addWidget(key_input)
        
        self.cards_layout.addWidget(card)
        
        self.cards[key] = {
            "widget": card,
            "key_edit": key_edit,
            "name_edit": name_edit,
            "url_edit": url_edit,
            "key_input": key_input
        }

    def add_provider_card(self):
        new_key = f"new_provider_{len(self.cards) + 1}"
        self._create_card(new_key, {"name": "New Provider"})
        self.cards[new_key]["key_edit"].setReadOnly(False)
        QApplication.processEvents()
        self.verticalScrollBar().setValue(self.verticalScrollBar().maximum())

    def _delete_card(self, key, card):
        card.deleteLater()
        if key in self.cards:
            del self.cards[key]

    def save_data(self):
        new_providers = {}
        for original_key, widgets in self.cards.items():
            final_key = widgets["key_edit"].text().strip()
            if not final_key: continue
            
            new_providers[final_key] = {
                "name": widgets["name_edit"].text(),
                "base_url": widgets["url_edit"].text(),
                "api_key": widgets["key_input"].text()
            }
        ConfigData.set_providers(new_providers)

# ============================================================================
# ç•Œé¢ 2: å‘é‡é…ç½®
# ============================================================================
class VectorInterface(QFrame):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("VectorInterface")
        layout = QVBoxLayout(self)
        layout.setContentsMargins(30, 20, 30, 20)
        
        layout.addWidget(SubtitleLabel("RAG & å‘é‡æ•°æ®åº“è®¾ç½®", self))
        layout.addSpacing(10)
        
        self.card = CardWidget(self)
        c_layout = QVBoxLayout(self.card)
        
        c_layout.addWidget(StrongBodyLabel("Embedding æœåŠ¡å•†"))
        self.combo_provider = ComboBox()
        c_layout.addWidget(self.combo_provider)
        c_layout.addSpacing(5)
        
        c_layout.addWidget(StrongBodyLabel("Embedding æ¨¡åž‹åç§°"))
        self.line_embed = LineEdit()
        self.line_embed.setPlaceholderText("ä¾‹å¦‚: BAAI/bge-m3")
        c_layout.addWidget(self.line_embed)
        c_layout.addSpacing(5)
        
        c_layout.addWidget(StrongBodyLabel("Rerank æ¨¡åž‹åç§°"))
        self.line_rerank = LineEdit()
        self.line_rerank.setPlaceholderText("ä¾‹å¦‚: BAAI/bge-reranker-v2-m3")
        c_layout.addWidget(self.line_rerank)
        
        layout.addWidget(self.card)
        layout.addStretch(1)

    def update_providers(self):
        current = self.combo_provider.text()
        self.combo_provider.clear()
        self.combo_provider.addItems(ConfigData.get_provider_keys())
        self.combo_provider.setCurrentText(current)

    def load_data(self):
        self.update_providers()
        vec = ConfigData.get_vector()
        self.combo_provider.setCurrentText(vec.get("provider", ""))
        self.line_embed.setText(vec.get("embedding_model", ""))
        self.line_rerank.setText(vec.get("rerank_model", ""))

    def save_data(self):
        ConfigData.set_vector({
            "provider": self.combo_provider.text(),
            "embedding_model": self.line_embed.text(),
            "rerank_model": self.line_rerank.text()
        })

# ============================================================================
# ç•Œé¢ 3: è§’è‰²é…ç½®
# ============================================================================
class RoleInterface(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("RoleInterface")
        
        layout = QHBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        
        self.list_widget = QListWidget()
        self.list_widget.setFixedWidth(220)
        self.list_widget.itemClicked.connect(self._on_item_clicked)
        self.list_widget.setStyleSheet("""
            QListWidget { background-color: transparent; border: none; outline: none; }
            QListWidget::item { padding: 12px; border-radius: 5px; }
            QListWidget::item:selected { background-color: rgba(255, 255, 255, 0.1); }
        """)
        
        self.edit_area = QScrollArea()
        self.edit_area.setWidgetResizable(True)
        self.edit_area.setStyleSheet("QScrollArea {background: transparent; border: none;}")
        
        self.edit_widget = QWidget()
        self.edit_area.setWidget(self.edit_widget)
        self.form_layout = QVBoxLayout(self.edit_widget)
        self.form_layout.setContentsMargins(20, 20, 20, 20)
        self.form_layout.setSpacing(10)
        
        self.lbl_key = SubtitleLabel("Select a Role")
        self.line_name = LineEdit()
        self.combo_prov = ComboBox()
        self.line_model = LineEdit()
        self.spin_temp = DoubleSpinBox()
        self.spin_temp.setRange(0.0, 2.0)
        self.spin_temp.setSingleStep(0.1)
        self.text_prompt = TextEdit()
        self.text_prompt.setMinimumHeight(300)
        
        self.form_layout.addWidget(self.lbl_key)
        self.form_layout.addSpacing(10)
        self.form_layout.addWidget(CaptionLabel("è§’è‰²æ˜¾ç¤ºåç§°"))
        self.form_layout.addWidget(self.line_name)
        
        h_layout = QHBoxLayout()
        v1 = QVBoxLayout()
        v1.addWidget(CaptionLabel("æœåŠ¡å•†"))
        v1.addWidget(self.combo_prov)
        h_layout.addLayout(v1)
        
        v2 = QVBoxLayout()
        v2.addWidget(CaptionLabel("æ¨¡åž‹ ID"))
        v2.addWidget(self.line_model)
        h_layout.addLayout(v2)
        
        v3 = QVBoxLayout()
        v3.addWidget(CaptionLabel("æ¸©åº¦ (Temperature)"))
        v3.addWidget(self.spin_temp)
        h_layout.addLayout(v3)
        
        self.form_layout.addLayout(h_layout)
        self.form_layout.addWidget(CaptionLabel("ç³»ç»Ÿæç¤ºè¯ (System Prompt)"))
        self.form_layout.addWidget(self.text_prompt)
        self.form_layout.addStretch(1)

        layout.addWidget(self.list_widget)
        layout.addWidget(self.edit_area)
        
        self.current_role_idx = -1
        self.roles_data = []

    def load_data(self):
        self.roles_data = deepcopy(ConfigData.get_roles())
        self.list_widget.clear()
        
        providers = ConfigData.get_provider_keys()
        self.combo_prov.clear()
        self.combo_prov.addItems(providers)
        
        for role in self.roles_data:
            item = QListWidgetItem(f"{role.get('name')} ({role.get('key')})")
            self.list_widget.addItem(item)
            
        if self.roles_data:
            self.list_widget.setCurrentRow(0)
            self._on_item_clicked(self.list_widget.item(0))

    def _save_current_to_memory(self):
        if self.current_role_idx >= 0 and self.current_role_idx < len(self.roles_data):
            role = self.roles_data[self.current_role_idx]
            role['name'] = self.line_name.text()
            role['provider'] = self.combo_prov.text()
            role['model'] = self.line_model.text()
            role['temperature'] = self.spin_temp.value()
            role['prompt'] = self.text_prompt.toPlainText()

    def _on_item_clicked(self, item):
        self._save_current_to_memory()
        idx = self.list_widget.row(item)
        self.current_role_idx = idx
        role = self.roles_data[idx]
        
        self.lbl_key.setText(f"é…ç½®è§’è‰²: {role.get('key')}")
        self.line_name.setText(role.get('name', ''))
        self.combo_prov.setCurrentText(role.get('provider', ''))
        self.line_model.setText(role.get('model', ''))
        self.spin_temp.setValue(role.get('temperature', 0.7))
        self.text_prompt.setPlainText(role.get('prompt', ''))

    def save_data(self):
        self._save_current_to_memory()
        ConfigData.set_roles(self.roles_data)

# ============================================================================
# ç•Œé¢ 4: é¢„è®¾æ¸…æ´— (Ingest)
# ============================================================================
class IngestWorker(QThread):
    log_signal = pyqtSignal(str)
    finished_signal = pyqtSignal()

    def __init__(self, file_path, llm_config):
        super().__init__()
        self.file_path = file_path
        self.llm_config = llm_config

    def run(self):
        try:
            ingester = PresetIngester(
                self.llm_config, 
                log_callback=self.log_signal.emit
            )
            ingester.ingest(self.file_path)
        except Exception as e:
            self.log_signal.emit(f"âŒ è‡´å‘½é”™è¯¯: {str(e)}")
        finally:
            self.finished_signal.emit()

class IngestInterface(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("IngestInterface")
        
        self.layout = QVBoxLayout(self)
        self.layout.setContentsMargins(30, 20, 30, 20)
        self.layout.setSpacing(15)

        self.layout.addWidget(SubtitleLabel("SillyTavern é¢„è®¾æ¸…æ´—å…¥åº“", self))
        self.layout.addWidget(BodyLabel("å°†ä¸–ç•Œä¹¦æˆ–é¢„è®¾æ–‡ä»¶æ¸…æ´—ä¸ºå‘é‡æ•°æ®åº“è§„åˆ™ï¼Œä¾›æ¸¸æˆå†… RAG ä½¿ç”¨ã€‚", self))
        
        # 1. æ–‡ä»¶é€‰æ‹©
        file_card = CardWidget(self)
        file_layout = QHBoxLayout(file_card)
        
        self.path_edit = LineEdit()
        self.path_edit.setPlaceholderText("è¯·é€‰æ‹© .json æ–‡ä»¶...")
        self.browse_btn = PrimaryPushButton("æµè§ˆ", self)
        self.browse_btn.clicked.connect(self.browse_file)
        
        file_layout.addWidget(self.path_edit)
        file_layout.addWidget(self.browse_btn)
        self.layout.addWidget(file_card)

        # 2. LLM é…ç½®
        self.layout.addWidget(StrongBodyLabel("æ¸…æ´—ç”¨ LLM é…ç½® (å»ºè®®ä½¿ç”¨é«˜æ™ºå•†æ¨¡åž‹)", self))
        config_card = CardWidget(self)
        config_layout = QVBoxLayout(config_card)
        
        config_layout.addWidget(CaptionLabel("Base URL"))
        self.url_edit = LineEdit()
        self.url_edit.setText("https://api.siliconflow.cn/v1")
        config_layout.addWidget(self.url_edit)
        
        config_layout.addWidget(CaptionLabel("API Key"))
        self.key_edit = LineEdit()
        self.key_edit.setPlaceholderText("sk-...")
        self.key_edit.setEchoMode(LineEdit.EchoMode.Password)
        config_layout.addWidget(self.key_edit)
        
        config_layout.addWidget(CaptionLabel("æ¨¡åž‹åç§°"))
        self.model_edit = LineEdit()
        self.model_edit.setText("deepseek-ai/DeepSeek-V3")
        config_layout.addWidget(self.model_edit)
        
        self.layout.addWidget(config_card)

        # 3. å¼€å§‹æŒ‰é’®
        action_layout = QHBoxLayout()
        self.start_btn = PrimaryPushButton("å¼€å§‹æ¸…æ´—å…¥åº“", self)
        self.start_btn.isSelectable = False # é˜²æ­¢æŠ¥é”™
        self.start_btn.clicked.connect(self.start_ingest)
        self.start_btn.setFixedWidth(200)
        action_layout.addStretch(1)
        action_layout.addWidget(self.start_btn)
        self.layout.addLayout(action_layout)

        # 4. æ—¥å¿—
        self.layout.addWidget(StrongBodyLabel("æ‰§è¡Œæ—¥å¿—", self))
        self.log_view = TextEdit()
        self.log_view.setReadOnly(True)
        self.layout.addWidget(self.log_view)

    def browse_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©é¢„è®¾æ–‡ä»¶", "", "JSON Files (*.json)"
        )
        if file_path:
            self.path_edit.setText(file_path)

    def start_ingest(self):
        path = self.path_edit.text().strip()
        if not os.path.exists(path):
            InfoBar.error("é”™è¯¯", "æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼", parent=self)
            return

        api_key = self.key_edit.text().strip()
        if not api_key:
            InfoBar.warning("æç¤º", "è¯·è¾“å…¥ API Key", parent=self)
            return

        llm_config = {
            "base_url": self.url_edit.text().strip(),
            "api_key": api_key,
            "model": self.model_edit.text().strip(),
            "temperature": 0.1
        }

        self.start_btn.setEnabled(False)
        self.start_btn.setText("æ­£åœ¨æ¸…æ´—ä¸­...")
        self.log_view.clear()

        self.worker = IngestWorker(path, llm_config)
        self.worker.log_signal.connect(self.append_log)
        self.worker.finished_signal.connect(self.on_finished)
        self.worker.start()

    def append_log(self, text):
        self.log_view.append(text)
        self.log_view.verticalScrollBar().setValue(
            self.log_view.verticalScrollBar().maximum()
        )

    def on_finished(self):
        self.start_btn.setEnabled(True)
        self.start_btn.setText("å¼€å§‹æ¸…æ´—å…¥åº“")
        InfoBar.success("å®Œæˆ", "æ¸…æ´—ä»»åŠ¡å·²ç»“æŸï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚", parent=self)


# ============================================================================
# ä¸»çª—å£
# ============================================================================
class ConfigEditorWindow(FluentWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("DeepTavern æŽ§åˆ¶ä¸­å¿ƒ")
        self.resize(1100, 750)
        self.setWindowIcon(FIF.SETTING.icon())

        ConfigData.load()

        # åˆå§‹åŒ–å­é¡µé¢
        self.provider_interface = ProviderInterface(self)
        self.vector_interface = VectorInterface(self)
        self.role_interface = RoleInterface(self)
        self.ingest_interface = IngestInterface(self)

        # å¯¼èˆªæ 
        self.addSubInterface(self.provider_interface, FIF.ALBUM, "æœåŠ¡å•†é…ç½®")
        self.addSubInterface(self.vector_interface, FIF.SEARCH, "å‘é‡ä¸Ž RAG")
        self.addSubInterface(self.role_interface, FIF.PEOPLE, "è§’è‰²æ¨¡åž‹åˆ†é…")
        self.addSubInterface(self.ingest_interface, FIF.SYNC, "é¢„è®¾æ¸…æ´—å·¥å…·")

        # åº•éƒ¨ä¿å­˜æŒ‰é’®
        self.save_btn = PrimaryPushButton("ä¿å­˜æ‰€æœ‰é…ç½®", self)
        self.save_btn.isSelectable = False
        self.save_btn.clicked.connect(self.save_all)
        self.save_btn.setFixedWidth(200)
        
        self.navigationInterface.addWidget(
            routeKey="save_btn",
            widget=self.save_btn,
            onClick=self.save_all,
            position=NavigationItemPosition.BOTTOM
        )
        
        # åˆå§‹åŠ è½½
        self.provider_interface.load_data()
        self.vector_interface.load_data()
        self.role_interface.load_data()
        
        self.stackedWidget.currentChanged.connect(self.on_tab_changed)

    def on_tab_changed(self, index):
        if self.stackedWidget.currentWidget() == self.provider_interface:
            self.provider_interface.save_data()
        
        self.vector_interface.update_providers()
        
        current_prov = self.role_interface.combo_prov.text()
        self.role_interface.combo_prov.clear()
        self.role_interface.combo_prov.addItems(ConfigData.get_provider_keys())
        self.role_interface.combo_prov.setCurrentText(current_prov)

    def save_all(self):
        self.provider_interface.save_data()
        self.vector_interface.save_data()
        self.role_interface.save_data()
        
        if ConfigData.save():
            InfoBar.success(
                title='ä¿å­˜æˆåŠŸ',
                content=f"é…ç½®å·²å†™å…¥ {CONFIG_FILE}",
                orient=Qt.Orientation.Horizontal,
                isClosable=True,
                position=InfoBarPosition.TOP_RIGHT,
                duration=2000,
                parent=self
            )
        else:
            InfoBar.error(
                title='ä¿å­˜å¤±è´¥',
                content="å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æƒé™ã€‚",
                parent=self
            )

if __name__ == '__main__':
    app = QApplication(sys.argv)
    w = ConfigEditorWindow()
    w.show()
    sys.exit(app.exec())


========================================
File Path: .\main.py
========================================

# main.py
"""
DeepTavern API Server v4.5.0
ä¼˜åŒ–ç‰ˆæœ¬ - ä¿®å¤æµå¼ä¼ è¾“ã€çº¿ç¨‹å®‰å…¨ã€WebSocket ç­‰é—®é¢˜
"""

import uvicorn
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import sys
import os
import logging
import time
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.workflow.manager import WorkflowManager
from core.utils.logger import logger


# ============================================================================
# å…¨å±€é…ç½®
# ============================================================================

# çº¿ç¨‹æ± ï¼Œç”¨äºŽè¿è¡ŒåŒæ­¥é˜»å¡žä»£ç 
executor = ThreadPoolExecutor(max_workers=8)

# å…¨å±€äº‹ä»¶å¾ªçŽ¯å¼•ç”¨ï¼ˆç”¨äºŽè·¨çº¿ç¨‹é€šä¿¡ï¼‰
main_event_loop: Optional[asyncio.AbstractEventLoop] = None


# ============================================================================
# WebSocket è¿žæŽ¥ç®¡ç†å™¨
# ============================================================================

class ConnectionManager:
    """
    WebSocket è¿žæŽ¥ç®¡ç†å™¨
    - ç®¡ç†æ‰€æœ‰æ´»è·ƒçš„ WebSocket è¿žæŽ¥
    - ç»´æŠ¤æ—¥å¿—ç¼“å­˜
    - æ”¯æŒå¹¿æ’­æ¶ˆæ¯
    """
    
    def __init__(self, max_buffer_size: int = 200):
        self.active_connections: List[WebSocket] = []
        self.log_buffer: List[str] = []
        self.max_buffer_size = max_buffer_size
        
        # å¼‚æ­¥é”ï¼ˆç”¨äºŽå¼‚æ­¥ä¸Šä¸‹æ–‡ï¼‰
        self._async_lock: Optional[asyncio.Lock] = None
        # åŒæ­¥é”ï¼ˆç”¨äºŽåŒæ­¥ä¸Šä¸‹æ–‡ï¼Œå¦‚æ—¥å¿—å¤„ç†å™¨ï¼‰
        self._sync_lock = threading.Lock()
    
    @property
    def async_lock(self) -> asyncio.Lock:
        """æ‡’åŠ è½½å¼‚æ­¥é”ï¼Œç¡®ä¿åœ¨äº‹ä»¶å¾ªçŽ¯ä¸­åˆ›å»º"""
        if self._async_lock is None:
            self._async_lock = asyncio.Lock()
        return self._async_lock
    
    async def connect(self, websocket: WebSocket) -> bool:
        """
        æŽ¥å— WebSocket è¿žæŽ¥
        è¿”å›žæ˜¯å¦æˆåŠŸè¿žæŽ¥
        """
        try:
            await websocket.accept()
            
            async with self.async_lock:
                self.active_connections.append(websocket)
                connection_count = len(self.active_connections)
                
                # å‘é€ç¼“å­˜çš„æ—¥å¿—
                buffer_copy = self.log_buffer.copy()
            
            # åœ¨é”å¤–å‘é€ç¼“å­˜ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”
            for log_msg in buffer_copy:
                try:
                    await websocket.send_text(log_msg)
                except Exception:
                    # å‘é€å¤±è´¥ï¼Œè¿žæŽ¥å¯èƒ½å·²æ–­å¼€
                    await self.disconnect(websocket)
                    return False
            
            logger.info(f"[WS] å®¢æˆ·ç«¯å·²è¿žæŽ¥ï¼Œå½“å‰è¿žæŽ¥æ•°: {connection_count}")
            return True
            
        except Exception as e:
            logger.warning(f"[WS] è¿žæŽ¥å¤±è´¥: {e}")
            return False

    async def disconnect(self, websocket: WebSocket):
        """æ–­å¼€ WebSocket è¿žæŽ¥"""
        async with self.async_lock:
            if websocket in self.active_connections:
                self.active_connections.remove(websocket)
                logger.info(f"[WS] å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œå½“å‰è¿žæŽ¥æ•°: {len(self.active_connections)}")

    async def broadcast(self, message: str):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰è¿žæŽ¥çš„å®¢æˆ·ç«¯"""
        async with self.async_lock:
            # æ·»åŠ åˆ°ç¼“å­˜
            self.log_buffer.append(message)
            while len(self.log_buffer) > self.max_buffer_size:
                self.log_buffer.pop(0)
            
            # è®°å½•éœ€è¦ç§»é™¤çš„æ­»è¿žæŽ¥
            dead_connections: List[WebSocket] = []
            
            # å¹¿æ’­ç»™æ‰€æœ‰å®¢æˆ·ç«¯
            for connection in self.active_connections:
                try:
                    await connection.send_text(message)
                except Exception:
                    dead_connections.append(connection)
            
            # ç§»é™¤æ­»è¿žæŽ¥
            for conn in dead_connections:
                if conn in self.active_connections:
                    self.active_connections.remove(conn)

    def sync_add_to_buffer(self, message: str):
        """
        çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å­˜
        ç”¨äºŽåŒæ­¥ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ—¥å¿—å¤„ç†å™¨åœ¨å…¶ä»–çº¿ç¨‹ä¸­è°ƒç”¨ï¼‰
        """
        with self._sync_lock:
            self.log_buffer.append(message)
            while len(self.log_buffer) > self.max_buffer_size:
                self.log_buffer.pop(0)

    def broadcast_threadsafe(self, message: str):
        """
        çº¿ç¨‹å®‰å…¨çš„å¹¿æ’­æ–¹æ³•
        å¯ä»Žä»»ä½•çº¿ç¨‹è°ƒç”¨
        """
        global main_event_loop
        
        if main_event_loop and main_event_loop.is_running():
            # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼è°ƒåº¦åç¨‹
            asyncio.run_coroutine_threadsafe(
                self.broadcast(message),
                main_event_loop
            )
        else:
            # äº‹ä»¶å¾ªçŽ¯ä¸å¯ç”¨ï¼Œåªæ·»åŠ åˆ°ç¼“å­˜
            self.sync_add_to_buffer(message)

    @property
    def connection_count(self) -> int:
        """å½“å‰è¿žæŽ¥æ•°"""
        return len(self.active_connections)


# å…¨å±€è¿žæŽ¥ç®¡ç†å™¨å®žä¾‹
manager = ConnectionManager()


# ============================================================================
# WebSocket æ—¥å¿—å¤„ç†å™¨
# ============================================================================

class WebSocketLogHandler(logging.Handler):
    """
    è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨
    å°†æ—¥å¿—æ¶ˆæ¯é€šè¿‡ WebSocket å¹¿æ’­ç»™æ‰€æœ‰è¿žæŽ¥çš„å®¢æˆ·ç«¯
    """
    
    def __init__(self, connection_manager: ConnectionManager):
        super().__init__()
        self.connection_manager = connection_manager
    
    def emit(self, record: logging.LogRecord):
        try:
            # æ ¼å¼åŒ–æ—¥å¿—æ¶ˆæ¯
            log_entry = self.format(record)
            
            # æž„å»º JSON è´Ÿè½½
            payload = json.dumps({
                "type": "log",
                "level": record.levelname,
                "msg": log_entry,
                "timestamp": time.time()
            }, ensure_ascii=False)
            
            # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„å¹¿æ’­æ–¹æ³•
            self.connection_manager.broadcast_threadsafe(payload)
            
        except Exception:
            # æ—¥å¿—å¤„ç†å™¨ä¸­çš„å¼‚å¸¸ä¸åº”è¯¥å½±å“ä¸»ç¨‹åº
            self.handleError(record)


# é…ç½®æ—¥å¿—å¤„ç†å™¨
def setup_websocket_logger():
    """è®¾ç½® WebSocket æ—¥å¿—å¤„ç†å™¨"""
    # ç§»é™¤å·²å­˜åœ¨çš„ WebSocket å¤„ç†å™¨
    handlers_to_remove = [
        h for h in logger.handlers 
        if isinstance(h, WebSocketLogHandler)
    ]
    for h in handlers_to_remove:
        logger.removeHandler(h)
    
    # æ·»åŠ æ–°çš„å¤„ç†å™¨
    ws_handler = WebSocketLogHandler(manager)
    ws_handler.setFormatter(
        logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')
    )
    ws_handler.setLevel(logging.INFO)
    logger.addHandler(ws_handler)

setup_websocket_logger()


# ============================================================================
# å·¥ä½œæµç®¡ç†å™¨
# ============================================================================

# å…¨å±€å·¥ä½œæµå®žä¾‹
# æ³¨æ„ï¼šåœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­ï¼Œå»ºè®®ä½¿ç”¨ä¼šè¯çº§åˆ«çš„å·¥ä½œæµç®¡ç†
workflow = WorkflowManager()


# ============================================================================
# FastAPI åº”ç”¨
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global main_event_loop
    
    # å¯åŠ¨æ—¶
    main_event_loop = asyncio.get_running_loop()
    logger.info("ðŸš€ DeepTavern API Server å·²å¯åŠ¨")
    logger.info(f"ðŸ“¡ API æ–‡æ¡£: http://localhost:8000/docs")
    logger.info(f"ðŸ”Œ WebSocket: ws://localhost:8000/ws/logs")
    
    yield
    
    # å…³é—­æ—¶
    logger.info("ðŸ‘‹ DeepTavern API Server æ­£åœ¨å…³é—­...")
    executor.shutdown(wait=False)
    main_event_loop = None


app = FastAPI(
    title="DeepTavern API",
    version="4.5.0",
    description="DeepTavern æ ¸å¿ƒ API æœåŠ¡",
    lifespan=lifespan
)

# CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# æ•°æ®æ¨¡åž‹
# ============================================================================

class CreateSessionRequest(BaseModel):
    user_name: str = "Player"
    char_name: str = "AI Assistant"
    char_persona: Optional[str] = None

class LoadSessionRequest(BaseModel):
    uuid: str

class DeleteSessionRequest(BaseModel):
    uuid: str

class RollbackRequest(BaseModel):
    message_id: int

class ChatRequest(BaseModel):
    messages: Optional[List[Dict[str, Any]]] = None
    model: Optional[str] = "default"
    stream: bool = True
    temperature: Optional[float] = 0.7
    top_p: Optional[float] = 1.0
    input: Optional[str] = None
    lite_mode: bool = False
    deep_mode: bool = False


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def extract_user_input(req: ChatRequest) -> str:
    """ä»Žè¯·æ±‚ä¸­æå–ç”¨æˆ·è¾“å…¥"""
    if req.input:
        return req.input
    
    if req.messages:
        for msg in reversed(req.messages):
            if msg.get('role') == 'user':
                content = msg.get('content', '')
                
                # å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼ˆå¦‚å›¾æ–‡æ··åˆï¼‰
                if isinstance(content, list):
                    text_parts = [
                        item.get('text', '') 
                        for item in content 
                        if item.get('type') == 'text'
                    ]
                    return " ".join(text_parts)
                
                return str(content)
    
    return ""


async def run_sync_generator_async(sync_gen_func, *args, **kwargs):
    """
    å°†åŒæ­¥ç”Ÿæˆå™¨è½¬æ¢ä¸ºå¼‚æ­¥ç”Ÿæˆå™¨
    ä½¿ç”¨é˜Ÿåˆ—åœ¨çº¿ç¨‹æ± å’Œäº‹ä»¶å¾ªçŽ¯ä¹‹é—´ä¼ é€’æ•°æ®
    """
    loop = asyncio.get_running_loop()
    queue: asyncio.Queue = asyncio.Queue()
    
    def producer():
        """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œçš„ç”Ÿäº§è€…"""
        try:
            for item in sync_gen_func(*args, **kwargs):
                asyncio.run_coroutine_threadsafe(
                    queue.put(("data", item)), 
                    loop
                )
            asyncio.run_coroutine_threadsafe(
                queue.put(("done", None)), 
                loop
            )
        except Exception as e:
            asyncio.run_coroutine_threadsafe(
                queue.put(("error", e)), 
                loop
            )
    
    # åœ¨çº¿ç¨‹æ± ä¸­å¯åŠ¨ç”Ÿäº§è€…
    loop.run_in_executor(executor, producer)
    
    # å¼‚æ­¥æ¶ˆè´¹é˜Ÿåˆ—
    while True:
        try:
            msg_type, data = await asyncio.wait_for(
                queue.get(), 
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            if msg_type == "done":
                break
            elif msg_type == "error":
                raise data
            elif msg_type == "data":
                yield data
                
        except asyncio.TimeoutError:
            raise TimeoutError("ç”Ÿæˆå™¨æ‰§è¡Œè¶…æ—¶")


# ============================================================================
# WebSocket è·¯ç”±
# ============================================================================

@app.websocket("/ws/logs")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket ç«¯ç‚¹ï¼Œç”¨äºŽå®žæ—¶æ—¥å¿—æŽ¨é€
    """
    connected = await manager.connect(websocket)
    if not connected:
        return
    
    try:
        while True:
            # ç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯ï¼ˆå¿ƒè·³æˆ–å‘½ä»¤ï¼‰
            data = await websocket.receive_text()
            
            # å¤„ç†å¿ƒè·³
            if data == "ping":
                await websocket.send_text(json.dumps({
                    "type": "pong",
                    "timestamp": time.time()
                }))
            
            # å¯æ‰©å±•ï¼šå¤„ç†å…¶ä»–å‘½ä»¤
            elif data.startswith("{"):
                try:
                    cmd = json.loads(data)
                    cmd_type = cmd.get("type")
                    
                    if cmd_type == "get_status":
                        await websocket.send_text(json.dumps({
                            "type": "status",
                            "connections": manager.connection_count,
                            "session": workflow.current_session_uuid
                        }))
                except json.JSONDecodeError:
                    pass
                    
    except WebSocketDisconnect:
        await manager.disconnect(websocket)
    except RuntimeError as e:
        # "WebSocket is not connected" ç­‰è¿è¡Œæ—¶é”™è¯¯
        logger.debug(f"[WS] RuntimeError: {e}")
        await manager.disconnect(websocket)
    except Exception as e:
        logger.warning(f"[WS] æœªé¢„æœŸçš„é”™è¯¯: {e}")
        await manager.disconnect(websocket)


# ============================================================================
# REST API è·¯ç”±
# ============================================================================

@app.get("/")
async def root():
    """æ ¹è·¯ç”±ï¼Œè¿”å›žæœåŠ¡çŠ¶æ€"""
    return {
        "status": "running",
        "name": "DeepTavern Core",
        "version": "4.5.0",
        "docs": "/docs",
        "websocket": "/ws/logs"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "websocket_connections": manager.connection_count,
        "active_session": workflow.current_session_uuid
    }


# === ä¼šè¯ç®¡ç† ===

@app.get("/v1/sessions")
async def list_sessions():
    """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
    try:
        sessions = workflow.list_all_sessions()
        return {
            "success": True,
            "data": sessions,
            "count": len(sessions) if sessions else 0
        }
    except Exception as e:
        logger.error(f"åˆ—å‡ºä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/sessions/new")
async def create_session(req: CreateSessionRequest):
    """åˆ›å»ºæ–°ä¼šè¯"""
    try:
        uuid = workflow.start_new_session(
            req.user_name, 
            req.char_name, 
            req.char_persona
        )
        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {uuid}")
        return {
            "success": True,
            "uuid": uuid,
            "message": "ä¼šè¯å·²åˆ›å»º"
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/sessions/load")
async def load_session(req: LoadSessionRequest):
    """åŠ è½½å·²æœ‰ä¼šè¯"""
    try:
        if workflow.load_session(req.uuid):
            logger.info(f"åŠ è½½ä¼šè¯: {req.uuid}")
            return {
                "success": True,
                "uuid": req.uuid,
                "message": "ä¼šè¯å·²åŠ è½½",
                "char_name": getattr(workflow, 'char_name', None)
            }
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åŠ è½½ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/sessions/delete")
async def delete_session(req: DeleteSessionRequest):
    """åˆ é™¤ä¼šè¯"""
    try:
        if workflow.delete_session(req.uuid):
            logger.info(f"åˆ é™¤ä¼šè¯: {req.uuid}")
            return {
                "success": True,
                "message": f"ä¼šè¯ {req.uuid} å·²åˆ é™¤"
            }
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# === èŠå¤©æŽ¥å£ ===

@app.post("/v1/chat/completions")
async def chat_completions(req: ChatRequest):
    """
    èŠå¤©å®ŒæˆæŽ¥å£
    å…¼å®¹ OpenAI API æ ¼å¼
    æ”¯æŒæµå¼å’Œéžæµå¼å“åº”
    """
    # ç¡®ä¿æœ‰æ´»è·ƒä¼šè¯
    if not workflow.current_session_uuid:
        workflow.start_new_session()
        logger.info("è‡ªåŠ¨åˆ›å»ºæ–°ä¼šè¯")
    
    # æå–ç”¨æˆ·è¾“å…¥
    user_input = extract_user_input(req)
    if not user_input:
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°ç”¨æˆ·è¾“å…¥")
    
    logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {user_input[:50]}...")
    
    if req.stream:
        # æµå¼å“åº”
        return StreamingResponse(
            stream_chat_response(user_input, req),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",  # ç¦ç”¨ Nginx ç¼“å†²
            }
        )
    else:
        # éžæµå¼å“åº”
        return await non_stream_chat_response(user_input, req)


async def stream_chat_response(user_input: str, req: ChatRequest):
    """
    æµå¼èŠå¤©å“åº”ç”Ÿæˆå™¨
    ä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—å®žçŽ°çœŸæ­£çš„æµå¼ä¼ è¾“
    """
    chunk_id = f"chatcmpl-{int(time.time() * 1000)}"
    created = int(time.time())
    full_response = ""
    
    try:
        # ä½¿ç”¨å¼‚æ­¥åŒ…è£…å™¨å¤„ç†åŒæ­¥ç”Ÿæˆå™¨
        async for chunk in run_sync_generator_async(
            workflow.chat,
            user_input,
            req.deep_mode,
            req.lite_mode
        ):
            full_response += chunk
            
            # å¹¿æ’­å¯¼æ¼”æ€ç»´é“¾ï¼ˆå¦‚æžœæœ‰ï¼‰
            if "[å¯¼æ¼”]:" in chunk or "[Director]:" in chunk:
                try:
                    asyncio.create_task(
                        manager.broadcast(json.dumps({
                            "type": "director",
                            "content": chunk,
                            "timestamp": time.time()
                        }, ensure_ascii=False))
                    )
                except Exception:
                    pass
            
            # æž„å»º SSE æ•°æ®åŒ…
            data = {
                "id": chunk_id,
                "object": "chat.completion.chunk",
                "created": created,
                "model": "deep-tavern",
                "choices": [{
                    "index": 0,
                    "delta": {"content": chunk},
                    "finish_reason": None
                }]
            }
            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        finish_data = {
            "id": chunk_id,
            "object": "chat.completion.chunk",
            "created": created,
            "model": "deep-tavern",
            "choices": [{
                "index": 0,
                "delta": {},
                "finish_reason": "stop"
            }]
        }
        yield f"data: {json.dumps(finish_data)}\n\n"
        yield "data: [DONE]\n\n"
        
        logger.info(f"æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)}")
        
    except TimeoutError:
        logger.error("èŠå¤©å“åº”è¶…æ—¶")
        error_data = {"error": {"message": "å“åº”è¶…æ—¶", "type": "timeout"}}
        yield f"data: {json.dumps(error_data)}\n\n"
        
    except Exception as e:
        logger.error(f"èŠå¤©é”™è¯¯: {e}")
        error_data = {"error": {"message": str(e), "type": "internal_error"}}
        yield f"data: {json.dumps(error_data)}\n\n"


async def non_stream_chat_response(user_input: str, req: ChatRequest) -> Dict:
    """éžæµå¼èŠå¤©å“åº”"""
    try:
        full_response = ""
        
        async for chunk in run_sync_generator_async(
            workflow.chat,
            user_input,
            req.deep_mode,
            req.lite_mode
        ):
            full_response += chunk
        
        return {
            "id": f"chatcmpl-{int(time.time() * 1000)}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": "deep-tavern",
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": full_response
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": len(user_input),
                "completion_tokens": len(full_response),
                "total_tokens": len(user_input) + len(full_response)
            }
        }
        
    except Exception as e:
        logger.error(f"éžæµå¼èŠå¤©é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# === åŽ†å²è®°å½• ===

@app.get("/v1/history")
async def get_history(page: int = 1, size: int = 50):
    """èŽ·å–èŠå¤©åŽ†å²"""
    if not workflow.current_session_uuid:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰åŠ è½½çš„ä¼šè¯")
    
    try:
        history = workflow.get_full_history(page, size)
        return {
            "success": True,
            "data": history,
            "page": page,
            "size": size
        }
    except Exception as e:
        logger.error(f"èŽ·å–åŽ†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/rollback")
async def rollback(req: RollbackRequest):
    """å›žæ»šåˆ°æŒ‡å®šæ¶ˆæ¯"""
    if not workflow.current_session_uuid:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰åŠ è½½çš„ä¼šè¯")
    
    try:
        if workflow.rollback(req.message_id):
            logger.info(f"å›žæ»šåˆ°æ¶ˆæ¯ ID: {req.message_id}")
            return {
                "success": True,
                "message": f"å·²å›žæ»šåˆ°æ¶ˆæ¯ {req.message_id}"
            }
        raise HTTPException(status_code=500, detail="å›žæ»šå¤±è´¥")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å›žæ»šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# è°ƒè¯•æŽ¥å£ï¼ˆå¯é€‰ï¼Œç”Ÿäº§çŽ¯å¢ƒå»ºè®®ç¦ç”¨ï¼‰
# ============================================================================

@app.get("/debug/connections")
async def debug_connections():
    """è°ƒè¯•ï¼šæŸ¥çœ‹å½“å‰ WebSocket è¿žæŽ¥"""
    return {
        "active_connections": manager.connection_count,
        "buffer_size": len(manager.log_buffer),
        "max_buffer_size": manager.max_buffer_size
    }


@app.post("/debug/broadcast")
async def debug_broadcast(message: str = "Test broadcast"):
    """è°ƒè¯•ï¼šå‘é€æµ‹è¯•å¹¿æ’­"""
    await manager.broadcast(json.dumps({
        "type": "debug",
        "message": message,
        "timestamp": time.time()
    }))
    return {"success": True, "message": "å¹¿æ’­å·²å‘é€"}


# ============================================================================
# å¯åŠ¨å…¥å£
# ============================================================================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                          â•‘
    â•‘   ðŸ° DeepTavern API Server v4.5.0                        â•‘
    â•‘                                                          â•‘
    â•‘   API Docs:  http://localhost:8000/docs                  â•‘
    â•‘   WebSocket: ws://localhost:8000/ws/logs                 â•‘
    â•‘                                                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        # WebSocket å¿ƒè·³é…ç½®
        ws_ping_interval=20,
        ws_ping_timeout=20,
        # æ—¥å¿—é…ç½®
        access_log=True,
        log_level="info",
        # æ€§èƒ½é…ç½®
        loop="auto",
        http="auto",
    )


========================================
File Path: .\monitor.py
========================================

import sys
import json
import markdown
import asyncio
import websockets
import traceback
import requests
import threading
from typing import Optional, List, Tuple, Deque, Any
from collections import deque

from PyQt6.QtCore import Qt, QThread, pyqtSignal, QSize, QTimer
from PyQt6.QtWidgets import (QApplication, QFrame, QVBoxLayout, QHBoxLayout,
                             QTextBrowser, QLabel, QWidget, QListWidget,
                             QListWidgetItem, QMessageBox)
from PyQt6.QtGui import QIcon, QColor, QTextCursor

from qfluentwidgets import (
    FluentWindow,
    NavigationItemPosition,
    FluentIcon as FIF,
    InfoBar,
    InfoBarPosition,
    StateToolTip,
    Theme,
    setTheme,
    isDarkTheme,
    LineEdit,
    PrimaryPushButton,
    StrongBodyLabel,
    CaptionLabel,
    BodyLabel,
    CardWidget,
    SwitchButton,
    ToggleToolButton,
    Flyout,
    FlyoutAnimationType,
    SubtitleLabel,
    PushButton,
    TransparentToolButton
)


# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
class Config:
    """åº”ç”¨é…ç½®å¸¸é‡"""
    DEFAULT_IP = "127.0.0.1"
    DEFAULT_PORT = "8000"
    WS_PING_INTERVAL = 20
    WS_OPEN_TIMEOUT = 5
    API_TIMEOUT = 5
    LOG_CACHE_SIZE = 2000
    LOG_DISPLAY_LIMIT = 1000  # QTextBrowser æ˜¾ç¤ºä¸Šé™
    LOG_TRIM_COUNT = 100      # è¶…é™æ—¶åˆ é™¤çš„æ¡æ•°
    RECONNECT_DELAY = 3
    RENDER_DEBOUNCE_MS = 100  # Markdown æ¸²æŸ“é˜²æŠ–


# ==========================================
# 1. åŽå°çº¿ç¨‹ï¼šWebSocket æ—¥å¿—ç›‘å¬
# ==========================================
class WebSocketWorker(QThread):
    log_received = pyqtSignal(str, str)
    director_received = pyqtSignal(str)
    status_changed = pyqtSignal(str)

    def __init__(self, ip: str = Config.DEFAULT_IP, port: str = Config.DEFAULT_PORT):
        super().__init__()
        self._lock = threading.Lock()
        self._ip = ip
        self._port = port
        self._running = True
        self.loop: Optional[asyncio.AbstractEventLoop] = None

    @property
    def ip(self) -> str:
        with self._lock:
            return self._ip

    @property
    def port(self) -> str:
        with self._lock:
            return self._port

    @property
    def running(self) -> bool:
        with self._lock:
            return self._running

    @running.setter
    def running(self, value: bool):
        with self._lock:
            self._running = value

    def update_address(self, ip: str, port: str) -> None:
        """æ›´æ–°è¿žæŽ¥åœ°å€å¹¶é‡è¿ž"""
        with self._lock:
            self._ip = ip
            self._port = port
        self.stop()
        self.running = True
        self.start()

    def run(self) -> None:
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)

        try:
            self.loop.run_until_complete(self.connect_loop())
        except asyncio.CancelledError:
            pass  # æ­£å¸¸å–æ¶ˆ
        except Exception as e:
            print(f"Worker Thread Crash: {e}\n{traceback.format_exc()}")
        finally:
            self._cleanup_loop()

    def _cleanup_loop(self) -> None:
        """æ¸…ç†äº‹ä»¶å¾ªçŽ¯"""
        if not self.loop:
            return
        try:
            # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
            pending = asyncio.all_tasks(self.loop)
            for task in pending:
                task.cancel()
            
            if pending:
                self.loop.run_until_complete(
                    asyncio.gather(*pending, return_exceptions=True)
                )
            
            self.loop.run_until_complete(self.loop.shutdown_asyncgens())
            self.loop.close()
        except Exception as e:
            print(f"Loop cleanup error: {e}")
        finally:
            self.loop = None

    async def connect_loop(self) -> None:
        while self.running:
            # èŽ·å–å½“å‰é…ç½®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            with self._lock:
                ip, port = self._ip, self._port
            
            uri = f"ws://{ip}:{port}/ws/logs"
            
            try:
                self.status_changed.emit(f"æ­£åœ¨è¿žæŽ¥: {uri}")
                async with websockets.connect(
                    uri,
                    ping_interval=Config.WS_PING_INTERVAL,
                    open_timeout=Config.WS_OPEN_TIMEOUT
                ) as websocket:
                    self.status_changed.emit(f"å·²è¿žæŽ¥åˆ° {uri}")
                    await self._handle_messages(websocket)
                    
            except asyncio.CancelledError:
                self.status_changed.emit("è¿žæŽ¥å·²å–æ¶ˆ")
                break
            except (OSError, ConnectionRefusedError):
                self.status_changed.emit(f"è¿žæŽ¥å¤±è´¥ (åŽç«¯æœªå¯åŠ¨?)ï¼Œ{Config.RECONNECT_DELAY}ç§’åŽé‡è¯•...")
                await self._safe_sleep(Config.RECONNECT_DELAY)
            except websockets.exceptions.InvalidURI as e:
                self.status_changed.emit(f"æ— æ•ˆçš„URI: {e}")
                await self._safe_sleep(Config.RECONNECT_DELAY)
            except Exception as e:
                self.status_changed.emit(f"å‘ç”Ÿé”™è¯¯: {type(e).__name__}ï¼Œ{Config.RECONNECT_DELAY}ç§’åŽé‡è¯•...")
                print(f"WebSocket Error: {traceback.format_exc()}")
                await self._safe_sleep(Config.RECONNECT_DELAY)

    async def _handle_messages(self, websocket) -> None:
        """å¤„ç† WebSocket æ¶ˆæ¯"""
        while self.running:
            try:
                message = await asyncio.wait_for(
                    websocket.recv(),
                    timeout=30  # 30ç§’è¶…æ—¶ï¼Œç”¨äºŽæ£€æŸ¥ running çŠ¶æ€
                )
                data = json.loads(message)
                
                if data.get('type') == 'log':
                    self.log_received.emit(data.get('level', 'INFO'), data.get('msg', ''))
                elif data.get('type') == 'director':
                    self.director_received.emit(data.get('content', ''))
                    
            except asyncio.TimeoutError:
                continue  # è¶…æ—¶åŽç»§ç»­æ£€æŸ¥ running çŠ¶æ€
            except websockets.exceptions.ConnectionClosed:
                self.status_changed.emit("è¿žæŽ¥æ–­å¼€ï¼Œå‡†å¤‡é‡è¿ž...")
                break
            except json.JSONDecodeError as e:
                print(f"JSON decode error: {e}")
            except asyncio.CancelledError:
                break

    async def _safe_sleep(self, seconds: float) -> None:
        """å¯ä¸­æ–­çš„ç¡çœ """
        try:
            await asyncio.sleep(seconds)
        except asyncio.CancelledError:
            pass

    def stop(self) -> None:
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        self.running = False
        
        if self.loop and self.loop.is_running():
            # åœ¨äº‹ä»¶å¾ªçŽ¯ä¸­å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
            self.loop.call_soon_threadsafe(self._cancel_tasks)
        
        self.quit()
        if not self.wait(3000):  # æœ€å¤šç­‰å¾…3ç§’
            print("Warning: Worker thread did not stop gracefully, terminating...")
            self.terminate()
            self.wait()

    def _cancel_tasks(self) -> None:
        """å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¹¶åœæ­¢å¾ªçŽ¯"""
        if not self.loop:
            return
        for task in asyncio.all_tasks(self.loop):
            task.cancel()
        self.loop.stop()


# ==========================================
# 2. åŽå°çº¿ç¨‹ï¼šAPI è¯·æ±‚ (å­˜æ¡£ç®¡ç†)
# ==========================================
class ApiWorker(QThread):
    finished = pyqtSignal(dict)
    error = pyqtSignal(str)

    def __init__(self, ip: str, port: str, action: str, payload: Optional[dict] = None):
        super().__init__()
        self.base_url = f"http://{ip}:{port}/v1"
        self.action = action
        self.payload = payload
        self._is_cancelled = False

    def run(self) -> None:
        try:
            resp = self._make_request()
            
            if self._is_cancelled:
                return
                
            if resp and resp.status_code == 200:
                self.finished.emit(resp.json())
            elif resp:
                self.error.emit(f"API Error {resp.status_code}: {resp.text[:200]}")
                
        except requests.Timeout:
            if not self._is_cancelled:
                self.error.emit("è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥åŽç«¯æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        except requests.ConnectionError:
            if not self._is_cancelled:
                self.error.emit("è¿žæŽ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥åŽç«¯åœ°å€æ˜¯å¦æ­£ç¡®")
        except Exception as e:
            if not self._is_cancelled:
                self.error.emit(f"è¯·æ±‚é”™è¯¯: {str(e)}")

    def _make_request(self) -> Optional[requests.Response]:
        """æ‰§è¡Œ HTTP è¯·æ±‚"""
        timeout = Config.API_TIMEOUT
        
        if self.action == 'list':
            return requests.get(f"{self.base_url}/sessions", timeout=timeout)
        elif self.action == 'load':
            return requests.post(f"{self.base_url}/sessions/load", json=self.payload, timeout=timeout)
        elif self.action == 'delete':
            return requests.post(f"{self.base_url}/sessions/delete", json=self.payload, timeout=timeout)
        return None

    def cancel(self) -> None:
        """å–æ¶ˆè¯·æ±‚ï¼ˆæ ‡è®°ï¼Œä¸ä¼šä¸­æ–­æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ï¼‰"""
        self._is_cancelled = True


# ==========================================
# 3. çº¿ç¨‹ç®¡ç†å™¨
# ==========================================
class ThreadManager:
    """ç®¡ç† API çº¿ç¨‹çš„ç”Ÿå‘½å‘¨æœŸï¼Œé˜²æ­¢æ³„æ¼"""
    
    def __init__(self):
        self._threads: List[QThread] = []
        self._lock = threading.Lock()

    def add(self, thread: QThread) -> None:
        with self._lock:
            # æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹
            self._threads = [t for t in self._threads if t.isRunning()]
            self._threads.append(thread)

    def remove(self, thread: QThread) -> None:
        with self._lock:
            if thread in self._threads:
                self._threads.remove(thread)
        
        # å®‰æŽ’å»¶è¿Ÿåˆ é™¤
        QTimer.singleShot(0, lambda: self._safe_delete(thread))

    def _safe_delete(self, thread: QThread) -> None:
        try:
            if not thread.isRunning():
                thread.deleteLater()
        except RuntimeError:
            pass  # å¯¹è±¡å·²è¢«åˆ é™¤

    def cancel_all(self) -> None:
        """å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿è¡Œçš„çº¿ç¨‹"""
        with self._lock:
            for thread in self._threads:
                if hasattr(thread, 'cancel'):
                    thread.cancel()
                if thread.isRunning():
                    thread.quit()
                    thread.wait(1000)
            self._threads.clear()


# ==========================================
# 4. ç•Œé¢ç»„ä»¶ï¼šè¿žæŽ¥æŒ‡å¼•
# ==========================================
class ConnectionGuideWidget(QWidget):
    def __init__(self, ip: str, port: str, parent=None):
        super().__init__(parent)
        layout = QVBoxLayout(self)
        layout.setSpacing(12)

        intro = BodyLabel("åœ¨ SillyTavern / RisuAI ä¸­é€‰æ‹© OpenAI (Chat Completion) å¹¶å¡«å†™ä»¥ä¸‹å‚æ•°ï¼š", self)
        intro.setWordWrap(True)
        layout.addWidget(intro)

        param_style = """
            QLabel { 
                background-color: rgba(128, 128, 128, 0.1); 
                padding: 8px; 
                border-radius: 5px; 
                font-family: 'Consolas', 'Monaco', monospace; 
            }
        """

        layout.addWidget(CaptionLabel("API åœ°å€ (Base URL):"))
        lbl_url = QLabel(f"http://{ip}:{port}/v1", self)
        lbl_url.setTextInteractionFlags(Qt.TextInteractionFlag.TextSelectableByMouse)
        lbl_url.setStyleSheet(param_style)
        layout.addWidget(lbl_url)

        layout.addWidget(CaptionLabel("API Key:"))
        lbl_key = QLabel("sk-deep-tavern", self)
        lbl_key.setTextInteractionFlags(Qt.TextInteractionFlag.TextSelectableByMouse)
        lbl_key.setStyleSheet(param_style)
        layout.addWidget(lbl_key)


# ==========================================
# 5. ç•Œé¢ï¼šç³»ç»Ÿæ—¥å¿—
# ==========================================
class LogInterface(QFrame):
    def __init__(self, parent=None):
        super().__init__(parent=parent)
        self.setObjectName("LogInterface")
        self.log_cache: Deque[Tuple[str, str]] = deque(maxlen=Config.LOG_CACHE_SIZE)

        layout = QVBoxLayout(self)

        # å·¥å…·æ 
        tool_layout = QHBoxLayout()
        title = StrongBodyLabel("å®žæ—¶ç³»ç»Ÿæ—¥å¿—", self)

        self.help_btn = ToggleToolButton(FIF.HELP, self)
        self.help_btn.clicked.connect(self.show_help)

        self.clear_btn = ToggleToolButton(FIF.DELETE, self)
        self.clear_btn.clicked.connect(self.clear_logs)

        tool_layout.addWidget(title)
        tool_layout.addStretch(1)
        tool_layout.addWidget(self.help_btn)
        tool_layout.addSpacing(5)
        tool_layout.addWidget(self.clear_btn)

        layout.addLayout(tool_layout)

        # æ—¥å¿—è§†å›¾
        self.log_view = QTextBrowser()
        self.log_view.setOpenExternalLinks(True)
        self.log_view.setStyleSheet("""
            QTextBrowser { 
                background-color: transparent; 
                border: none; 
                font-family: 'Consolas', 'Monaco', 'Courier New', monospace; 
                font-size: 13px; 
            }
        """)
        layout.addWidget(self.log_view)

    def show_help(self) -> None:
        worker = self.window().worker
        content = ConnectionGuideWidget(worker.ip, worker.port, self)
        Flyout.make(
            content,
            target=self.help_btn,
            parent=self.window(),
            aniType=FlyoutAnimationType.PULL_UP,
            isDeleteOnClose=True
        )

    def clear_logs(self) -> None:
        self.log_cache.clear()
        self.log_view.clear()

    def append_log(self, level: str, msg: str) -> None:
        self.log_cache.append((level, msg))
        self._render_single_log(level, msg)
        self._trim_display()

    def _trim_display(self) -> None:
        """é™åˆ¶ QTextBrowser çš„å†…å®¹é‡ï¼Œé˜²æ­¢å†…å­˜æ— é™å¢žé•¿"""
        doc = self.log_view.document()
        if doc.blockCount() > Config.LOG_DISPLAY_LIMIT:
            cursor = self.log_view.textCursor()
            cursor.movePosition(QTextCursor.MoveOperation.Start)
            cursor.movePosition(
                QTextCursor.MoveOperation.Down,
                QTextCursor.MoveMode.KeepAnchor,
                Config.LOG_TRIM_COUNT
            )
            cursor.removeSelectedText()

    def _render_single_log(self, level: str, msg: str) -> None:
        is_dark = isDarkTheme()
        base_color = "#e0e0e0" if is_dark else "#333333"

        colors = {
            "INFO": "#98c379" if is_dark else "#2e7d32",
            "WARNING": "#e5c07b" if is_dark else "#ef6c00",
            "ERROR": "#e06c75" if is_dark else "#c62828",
            "DEBUG": "#61afef" if is_dark else "#1565c0"
        }
        c = colors.get(level, base_color)

        # è½¬ä¹‰ HTML ç‰¹æ®Šå­—ç¬¦
        import html
        safe_msg = html.escape(msg)

        html_content = f"""<div style="margin-bottom: 2px;">
            <span style="color: {c}; font-weight: bold;">[{level}]</span> 
            <span style="color: {base_color};">{safe_msg}</span>
        </div>"""
        
        self.log_view.append(html_content)
        self.log_view.moveCursor(QTextCursor.MoveOperation.End)

    def rerender(self) -> None:
        """ä¸»é¢˜åˆ‡æ¢æ—¶é‡æ–°æ¸²æŸ“æ‰€æœ‰æ—¥å¿—"""
        self.log_view.clear()
        for level, msg in self.log_cache:
            self._render_single_log(level, msg)


# ==========================================
# 6. ç•Œé¢ï¼šå¯¼æ¼”æ€ç»´é“¾
# ==========================================
class DirectorInterface(QFrame):
    def __init__(self, parent=None):
        super().__init__(parent=parent)
        self.setObjectName("DirectorInterface")
        
        layout = QVBoxLayout(self)
        
        # å·¥å…·æ 
        tool_layout = QHBoxLayout()
        title = StrongBodyLabel("å¯¼æ¼”æ€ç»´é“¾", self)
        
        self.clear_btn = TransparentToolButton(FIF.DELETE, self)
        self.clear_btn.clicked.connect(self.clear_content)
        
        tool_layout.addWidget(title)
        tool_layout.addStretch(1)
        tool_layout.addWidget(self.clear_btn)
        layout.addLayout(tool_layout)
        
        # å†…å®¹è§†å›¾
        self.director_view = QTextBrowser()
        self.director_view.setOpenExternalLinks(True)
        self.director_view.setStyleSheet("""
            QTextBrowser { 
                background-color: transparent; 
                border: none; 
                font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif; 
                padding: 10px; 
            }
        """)
        layout.addWidget(self.director_view)
        
        self.buffer = ""
        self._pending_render = False

    def clear_content(self) -> None:
        self.buffer = ""
        self.director_view.clear()

    def update_content(self, content: str) -> None:
        self.buffer += content
        self._schedule_render()

    def _schedule_render(self) -> None:
        """é˜²æŠ–ï¼šåˆå¹¶çŸ­æ—¶é—´å†…çš„å¤šæ¬¡æ›´æ–°"""
        if self._pending_render:
            return
        self._pending_render = True
        QTimer.singleShot(Config.RENDER_DEBOUNCE_MS, self._do_render)

    def _do_render(self) -> None:
        self._pending_render = False
        self._render_markdown()

    def _render_markdown(self) -> None:
        clean_content = self.buffer.replace("[å¯¼æ¼”]:", "").replace("[Director]:", "")
        
        try:
            html_content = markdown.markdown(
                clean_content,
                extensions=['fenced_code', 'tables', 'nl2br']
            )
        except Exception as e:
            print(f"Markdown render error: {e}")
            html_content = f"<pre>{clean_content}</pre>"

        is_dark = isDarkTheme()
        text_color = "#d4d4d4" if is_dark else "#24292f"
        code_bg = "#2d2d2d" if is_dark else "#f6f8fa"
        link_color = "#40a9ff" if is_dark else "#0969da"

        css = f"""<style>
            body {{ color: {text_color}; line-height: 1.6; font-size: 14px; }} 
            h1, h2, h3 {{ color: {link_color}; margin-top: 1em; }} 
            pre {{ background-color: {code_bg}; padding: 10px; border-radius: 5px; overflow-x: auto; }} 
            code {{ background-color: {code_bg}; padding: 2px 4px; border-radius: 3px; font-family: Consolas, Monaco, monospace; }}
            blockquote {{ border-left: 4px solid {link_color}; padding-left: 10px; color: #888; margin: 10px 0; }}
            hr {{ border: 0; border-top: 1px solid #555; }}
            table {{ border-collapse: collapse; width: 100%; }}
            th, td {{ border: 1px solid #555; padding: 8px; text-align: left; }}
        </style>"""

        self.director_view.setHtml(css + html_content)
        self.director_view.moveCursor(QTextCursor.MoveOperation.End)

    def rerender(self) -> None:
        """ä¸»é¢˜åˆ‡æ¢æ—¶é‡æ–°æ¸²æŸ“"""
        self._render_markdown()


# ==========================================
# 7. ç•Œé¢ï¼šå­˜æ¡£ç®¡ç†
# ==========================================
class SessionInterface(QFrame):
    def __init__(self, parent=None):
        super().__init__(parent=parent)
        self.setObjectName("SessionInterface")
        self.parent_window = parent
        self.thread_manager = ThreadManager()

        layout = QVBoxLayout(self)
        layout.setContentsMargins(30, 30, 30, 30)

        # æ ‡é¢˜æ 
        header_layout = QHBoxLayout()
        header_layout.addWidget(StrongBodyLabel("å­˜æ¡£ç®¡ç†", self))
        header_layout.addStretch(1)

        self.refresh_btn = TransparentToolButton(FIF.SYNC, self)
        self.refresh_btn.clicked.connect(self.load_sessions)
        header_layout.addWidget(self.refresh_btn)
        layout.addLayout(header_layout)

        layout.addSpacing(10)

        # åˆ—è¡¨å®¹å™¨
        self.list_card = CardWidget(self)
        list_layout = QVBoxLayout(self.list_card)
        list_layout.setContentsMargins(0, 0, 0, 0)

        self.session_list = QListWidget()
        self.session_list.setStyleSheet("""
            QListWidget { 
                background: transparent; 
                border: none; 
                outline: none; 
            } 
            QListWidget::item { 
                padding: 10px; 
                border-bottom: 1px solid #333; 
            } 
            QListWidget::item:selected { 
                background: rgba(255, 255, 255, 0.1); 
            }
            QListWidget::item:hover { 
                background: rgba(255, 255, 255, 0.05); 
            }
        """)
        list_layout.addWidget(self.session_list)

        layout.addWidget(self.list_card)

        # æ“ä½œæŒ‰é’®
        btn_layout = QHBoxLayout()
        self.load_btn = PrimaryPushButton("åŠ è½½é€‰ä¸­å­˜æ¡£", self)
        self.load_btn.clicked.connect(self.do_load)

        self.del_btn = PushButton("åˆ é™¤å­˜æ¡£", self)
        self.del_btn.clicked.connect(self.do_delete)

        btn_layout.addStretch(1)
        btn_layout.addWidget(self.del_btn)
        btn_layout.addWidget(self.load_btn)
        layout.addLayout(btn_layout)

    def load_sessions(self) -> None:
        self.session_list.clear()
        self._set_loading(True)

        worker = self.parent_window.worker
        api_thread = ApiWorker(worker.ip, worker.port, 'list')
        
        api_thread.finished.connect(self._on_list_success)
        api_thread.error.connect(self._on_error)
        api_thread.finished.connect(lambda: self._cleanup_thread(api_thread))
        api_thread.error.connect(lambda: self._cleanup_thread(api_thread))
        
        self.thread_manager.add(api_thread)
        api_thread.start()

    def _on_list_success(self, data: dict) -> None:
        self._set_loading(False)
        sessions = data.get('data', [])

        if not sessions:
            item = QListWidgetItem("æš‚æ— å­˜æ¡£")
            item.setFlags(Qt.ItemFlag.NoItemFlags)
            self.session_list.addItem(item)
            return

        for s in sessions:
            char_name = s.get('character_name', 'Unknown')
            uuid = s.get('uuid', 'N/A')
            created_at = s.get('created_at', '')
            
            text = f"[{char_name}]  {uuid}  \nðŸ“… {created_at}"
            item = QListWidgetItem(text)
            item.setData(Qt.ItemDataRole.UserRole, uuid)
            self.session_list.addItem(item)

    def do_load(self) -> None:
        item = self.session_list.currentItem()
        if not item:
            InfoBar.warning("æç¤º", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªå­˜æ¡£", parent=self.parent_window)
            return

        uuid = item.data(Qt.ItemDataRole.UserRole)
        if not uuid:
            return

        self.load_btn.setEnabled(False)
        self.load_btn.setText("åŠ è½½ä¸­...")

        worker = self.parent_window.worker
        api_thread = ApiWorker(worker.ip, worker.port, 'load', {'uuid': uuid})
        
        api_thread.finished.connect(self._on_load_success)
        api_thread.error.connect(self._on_error)
        api_thread.finished.connect(lambda: self._cleanup_thread(api_thread))
        api_thread.error.connect(lambda: self._cleanup_thread(api_thread))
        
        self.thread_manager.add(api_thread)
        api_thread.start()

    def _on_load_success(self, data: dict) -> None:
        self._reset_load_btn()
        char_name = data.get('char', 'æœªçŸ¥')
        InfoBar.success("æˆåŠŸ", f"å·²åŠ è½½å­˜æ¡£: {char_name}", parent=self.parent_window)

    def do_delete(self) -> None:
        item = self.session_list.currentItem()
        if not item:
            InfoBar.warning("æç¤º", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªå­˜æ¡£", parent=self.parent_window)
            return

        uuid = item.data(Qt.ItemDataRole.UserRole)
        if not uuid:
            return

        reply = QMessageBox.question(
            self,
            'ç¡®è®¤åˆ é™¤',
            f'ç¡®å®šè¦å½»åº•åˆ é™¤å­˜æ¡£ {uuid} å—ï¼Ÿ\næ­¤æ“ä½œä¸å¯æ¢å¤ï¼',
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            self._do_delete_confirmed(uuid)

    def _do_delete_confirmed(self, uuid: str) -> None:
        worker = self.parent_window.worker
        api_thread = ApiWorker(worker.ip, worker.port, 'delete', {'uuid': uuid})
        
        api_thread.finished.connect(self._on_delete_success)
        api_thread.error.connect(self._on_error)
        api_thread.finished.connect(lambda: self._cleanup_thread(api_thread))
        api_thread.error.connect(lambda: self._cleanup_thread(api_thread))
        
        self.thread_manager.add(api_thread)
        api_thread.start()

    def _on_delete_success(self, data: dict) -> None:
        InfoBar.success("åˆ é™¤æˆåŠŸ", "å­˜æ¡£å·²ç§»é™¤", parent=self.parent_window)
        self.load_sessions()

    def _on_error(self, msg: str) -> None:
        self._set_loading(False)
        self._reset_load_btn()
        InfoBar.error("é”™è¯¯", msg, parent=self.parent_window)

    def _set_loading(self, loading: bool) -> None:
        self.refresh_btn.setEnabled(not loading)

    def _reset_load_btn(self) -> None:
        self.load_btn.setEnabled(True)
        self.load_btn.setText("åŠ è½½é€‰ä¸­å­˜æ¡£")

    def _cleanup_thread(self, thread: ApiWorker) -> None:
        self.thread_manager.remove(thread)

    def cleanup(self) -> None:
        """æ¸…ç†æ‰€æœ‰çº¿ç¨‹"""
        self.thread_manager.cancel_all()


# ==========================================
# 8. ç•Œé¢ï¼šè®¾ç½®é¡µé¢
# ==========================================
class SettingInterface(QFrame):
    def __init__(self, parent=None):
        super().__init__(parent=parent)
        self.setObjectName("SettingInterface")
        self.parent_window = parent
        
        layout = QVBoxLayout(self)
        layout.setContentsMargins(30, 30, 30, 30)

        # è¿žæŽ¥è®¾ç½®
        layout.addWidget(StrongBodyLabel("è¿žæŽ¥è®¾ç½®", self))
        layout.addSpacing(10)
        
        self.conn_card = CardWidget(self)
        card_layout = QVBoxLayout(self.conn_card)

        self.ip_input = LineEdit(self)
        self.ip_input.setText(Config.DEFAULT_IP)
        self.ip_input.setPlaceholderText("ä¾‹å¦‚: 127.0.0.1")
        
        self.port_input = LineEdit(self)
        self.port_input.setText(Config.DEFAULT_PORT)
        self.port_input.setPlaceholderText("ä¾‹å¦‚: 8000")
        
        self.save_btn = PrimaryPushButton("ä¿å­˜å¹¶é‡è¿ž", self)
        self.save_btn.clicked.connect(self.apply_settings)

        card_layout.addWidget(CaptionLabel("åŽç«¯ IP åœ°å€"))
        card_layout.addWidget(self.ip_input)
        card_layout.addSpacing(10)
        card_layout.addWidget(CaptionLabel("åŽç«¯ç«¯å£ (Port)"))
        card_layout.addWidget(self.port_input)
        card_layout.addSpacing(15)
        card_layout.addWidget(self.save_btn)
        layout.addWidget(self.conn_card)

        # ä¸ªæ€§åŒ–è®¾ç½®
        layout.addSpacing(30)
        layout.addWidget(StrongBodyLabel("ä¸ªæ€§åŒ–", self))
        layout.addSpacing(10)
        
        self.theme_card = CardWidget(self)
        theme_layout = QHBoxLayout(self.theme_card)
        theme_layout.addWidget(StrongBodyLabel("æ·±è‰²æ¨¡å¼", self))
        theme_layout.addStretch(1)
        
        self.theme_switch = SwitchButton(parent=self.theme_card)
        self.theme_switch.setOnText("å¼€")
        self.theme_switch.setOffText("å…³")
        self.theme_switch.setChecked(True)
        self.theme_switch.checkedChanged.connect(self.toggle_theme)
        theme_layout.addWidget(self.theme_switch)
        layout.addWidget(self.theme_card)

        # å…³äºŽä¿¡æ¯
        layout.addSpacing(30)
        layout.addWidget(StrongBodyLabel("å…³äºŽ", self))
        layout.addSpacing(10)
        
        about_card = CardWidget(self)
        about_layout = QVBoxLayout(about_card)
        about_layout.addWidget(CaptionLabel("DeepTavern æŽ§åˆ¶å° v1.0.0"))
        about_layout.addWidget(CaptionLabel("åŸºäºŽ PyQt6 + qfluentwidgets æž„å»º"))
        layout.addWidget(about_card)

        layout.addStretch(1)

    def apply_settings(self) -> None:
        ip = self.ip_input.text().strip()
        port = self.port_input.text().strip()

        # ç®€å•éªŒè¯
        if not ip:
            InfoBar.warning("è­¦å‘Š", "IP åœ°å€ä¸èƒ½ä¸ºç©º", parent=self.parent_window)
            return
        if not port or not port.isdigit():
            InfoBar.warning("è­¦å‘Š", "ç«¯å£å¿…é¡»æ˜¯æ•°å­—", parent=self.parent_window)
            return

        self.parent_window.update_worker_config(ip, port)
        InfoBar.success(
            title='è®¾ç½®å·²åº”ç”¨',
            content=f'æ­£åœ¨è¿žæŽ¥åˆ° {ip}:{port}...',
            parent=self.parent_window,
            position=InfoBarPosition.TOP_RIGHT
        )

    def toggle_theme(self, is_dark: bool) -> None:
        theme = Theme.DARK if is_dark else Theme.LIGHT
        setTheme(theme)

        # åˆ·æ–°ç•Œé¢
        self.parent_window.log_interface.rerender()
        self.parent_window.director_interface.rerender()

        InfoBar.info("ä¸»é¢˜åˆ‡æ¢", "ç•Œé¢å·²åˆ·æ–°", parent=self.parent_window)


# ==========================================
# 9. ä¸»çª—å£
# ==========================================
class DeepTavernWindow(FluentWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("DeepTavern æŽ§åˆ¶å° - [æœªè¿žæŽ¥]")
        self.resize(1100, 750)
        self.setWindowIcon(FIF.COMMAND_PROMPT.icon())

        setTheme(Theme.DARK)

        # åˆå§‹åŒ– Workerï¼ˆå¿…é¡»åœ¨ç•Œé¢ä¹‹å‰ï¼‰
        self.worker = WebSocketWorker(Config.DEFAULT_IP, Config.DEFAULT_PORT)

        # åˆå§‹åŒ–ç•Œé¢
        self.log_interface = LogInterface(self)
        self.director_interface = DirectorInterface(self)
        self.session_interface = SessionInterface(self)
        self.setting_interface = SettingInterface(self)

        self.init_navigation()
        self.stateTooltip: Optional[StateToolTip] = None

        # è¿žæŽ¥ä¿¡å·
        self.worker.log_received.connect(self.log_interface.append_log)
        self.worker.director_received.connect(self.director_interface.update_content)
        self.worker.status_changed.connect(self.handle_status_change)

        # å¯åŠ¨ Worker
        self.worker.start()

    def init_navigation(self) -> None:
        self.addSubInterface(self.log_interface, FIF.COMMAND_PROMPT, "ç³»ç»Ÿç»ˆç«¯")
        self.addSubInterface(self.director_interface, FIF.MOVIE, "å¯¼æ¼”æ€ç»´é“¾")
        self.addSubInterface(self.session_interface, FIF.SAVE, "å­˜æ¡£ç®¡ç†")
        self.addSubInterface(
            self.setting_interface, 
            FIF.SETTING, 
            "è®¾ç½®", 
            NavigationItemPosition.BOTTOM
        )

    def update_worker_config(self, ip: str, port: str) -> None:
        self.worker.update_address(ip, port)

    def handle_status_change(self, msg: str) -> None:
        if "å·²è¿žæŽ¥" in msg:
            self.setWindowTitle(f"DeepTavern æŽ§åˆ¶å° - [{self.worker.ip}:{self.worker.port}]")
            self._close_state_tooltip()
            InfoBar.success(
                title='è¿žæŽ¥æˆåŠŸ',
                content=msg,
                parent=self,
                position=InfoBarPosition.TOP_RIGHT
            )
            # è¿žæŽ¥æˆåŠŸåŽè‡ªåŠ¨åˆ·æ–°å­˜æ¡£åˆ—è¡¨
            QTimer.singleShot(100, self.session_interface.load_sessions)
            
        elif "æ­£åœ¨è¿žæŽ¥" in msg:
            self.setWindowTitle("DeepTavern æŽ§åˆ¶å° - [è¿žæŽ¥ä¸­...]")
            self._show_state_tooltip()
            
        else:
            self.setWindowTitle("DeepTavern æŽ§åˆ¶å° - [æ–­å¼€]")
            self._update_state_tooltip_error()

    def _show_state_tooltip(self) -> None:
        if not self.stateTooltip:
            self.stateTooltip = StateToolTip("è¿žæŽ¥ä¸­", "æ­£åœ¨å¯»æ‰¾åŽç«¯æœåŠ¡...", self)
            self.stateTooltip.move(self.stateTooltip.getSuitablePos())
            self.stateTooltip.show()

    def _close_state_tooltip(self) -> None:
        if self.stateTooltip:
            try:
                self.stateTooltip.close()
            except RuntimeError:
                pass
            self.stateTooltip = None

    def _update_state_tooltip_error(self) -> None:
        if self.stateTooltip:
            try:
                if self.stateTooltip.isVisible():
                    self.stateTooltip.setContent("è¿žæŽ¥æ–­å¼€ï¼Œé‡è¯•ä¸­...")
                    self.stateTooltip.setState(True)
            except RuntimeError:
                self.stateTooltip = None

    def closeEvent(self, event) -> None:
        # æ¸…ç†æ‰€æœ‰èµ„æº
        self.session_interface.cleanup()
        self.worker.stop()
        super().closeEvent(event)


# ==========================================
# 10. å…¥å£
# ==========================================
def main():
    # PyQt6 é»˜è®¤å¯ç”¨é«˜ DPI æ”¯æŒï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨ä¿¡æ¯
    app.setApplicationName("DeepTavern Console")
    app.setApplicationVersion("1.0.0")
    
    window = DeepTavernWindow()
    window.show()
    
    sys.exit(app.exec())


if __name__ == '__main__':
    main()


========================================
File Path: .\config\settings.py
========================================

# config/settings.py
import json
import os
import re

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CONFIG_JSON_PATH = os.path.join(BASE_DIR, "config.json")

# --- é»˜è®¤å€¼ ---
DEFAULT_HISTORY_LIMIT = 20
SYSTEM_MAX_HISTORY_CHARS = 30000
LOCAL_MODEL_PATH = "" 
MODEL_CONFIG = {}

# API å ä½ç¬¦
EMBEDDING_MODEL = "BAAI/bge-m3"
RERANK_MODEL = "BAAI/bge-reranker-v2-m3"
VECTOR_API_KEY = ""
VECTOR_BASE_URL = ""

# --- Redis é…ç½® (çƒ­æ•°æ®åº“) ---
# å¦‚æžœæ²¡æœ‰å®‰è£… Redisï¼Œè¯·å°† USE_REDIS è®¾ä¸º Falseï¼Œä»£ç ä¼šè‡ªåŠ¨é™çº§ä¸ºçº¯ SQLite æ¨¡å¼
USE_REDIS = True
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_DB = 0
REDIS_PASSWORD = None
REDIS_TTL = 3600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ (ç§’)

def clean_prompt_content(text):
    if not text: return ""
    match = re.search(r'"""(.*?)"""', text, re.DOTALL)
    if match: return match.group(1).strip()
    return text.strip()

if os.path.exists(CONFIG_JSON_PATH):
    try:
        with open(CONFIG_JSON_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
            
            providers = data.get("providers", {})
            vec_conf = data.get("vector", {})
            vec_provider_key = vec_conf.get("provider", "silicon")
            vec_provider = providers.get(vec_provider_key, {})
            
            EMBEDDING_MODEL = vec_conf.get("embedding_model", EMBEDDING_MODEL)
            RERANK_MODEL = vec_conf.get("rerank_model", RERANK_MODEL)
            VECTOR_API_KEY = vec_provider.get("api_key", "")
            VECTOR_BASE_URL = vec_provider.get("base_url", "")

            # æ³¨å…¥å…¨å±€å˜é‡
            for key, value in data.items():
                if key.isupper():
                    globals()[key] = value

            raw_roles = data.get("roles", [])
            for role in raw_roles:
                key = role.get("key")
                provider_key = role.get("provider")
                provider_info = providers.get(provider_key, {})
                raw_prompt = role.get("prompt", "")
                
                MODEL_CONFIG[key] = {
                    "model": role.get("model"),
                    "api_key": provider_info.get("api_key"),
                    "base_url": provider_info.get("base_url"),
                    "temperature": role.get("temperature", 0.7),
                    "max_tokens": role.get("max_tokens", 8192),
                    "prompt": clean_prompt_content(raw_prompt),
                    "n_ctx": role.get("n_ctx", 32768),       # é»˜è®¤ç»™å¤§ç‚¹
                    "n_gpu_layers": role.get("n_gpu_layers", -1) # é»˜è®¤å…¨GPU
                }

    except Exception as e:
        print(f"[Config] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
else:
    print(f"[Config] è­¦å‘Š: æ‰¾ä¸åˆ° {CONFIG_JSON_PATH}")


========================================
File Path: .\core\__init__.py
========================================



========================================
File Path: .\core\database\graph_manager.py
========================================

# core/database/graph_manager.py
"""
DeepTavern çŸ¥è¯†å›¾è°±ç®¡ç†å™¨ v2.0

æ”¹è¿›å†…å®¹ï¼š
1. [ä¿®æ”¹] æ— å‘å›¾ â†’ æœ‰å‘å›¾ (DiGraph)ï¼ŒåŒºåˆ†å…³ç³»æ–¹å‘
2. [æ–°å¢ž] èŠ‚ç‚¹å‘é‡åŒ–ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢
3. [æ–°å¢ž] è¾¹çš„ç½®ä¿¡åº¦/æƒé‡ï¼Œå¤šæ¬¡æåŠçš„å…³ç³»æƒé‡æ›´é«˜
4. [æ–°å¢ž] å…³ç³»åˆå¹¶ï¼Œç›¸åŒå®žä½“å¯¹çš„å…³ç³»ä¼šç´¯ç§¯è€Œéžè¦†ç›–
5. [æ–°å¢ž] å®žä½“åˆ«åæ”¯æŒï¼Œ"çˆ±ä¸½ä¸" å’Œ "Alice" å¯ä»¥æŒ‡å‘åŒä¸€èŠ‚ç‚¹
6. [æ–°å¢ž] æ‰¹é‡æ“ä½œå’Œå»¶è¿Ÿä¿å­˜ï¼Œæå‡æ€§èƒ½
7. [ä¼˜åŒ–] å‘é‡ç¼“å­˜æŒä¹…åŒ–ï¼Œé‡å¯åŽä¸éœ€è¦é‡æ–°è®¡ç®—
"""

import networkx as nx
import numpy as np
import os
import json
import threading
import time
from typing import List, Dict, Tuple, Optional, Set
from core.utils.logger import logger

# å°è¯•å¯¼å…¥å‘é‡åŒ–ä¾èµ–
try:
    from core.database.silicon_client import SiliconFlowEmbedding
    EMBEDDING_AVAILABLE = True
except ImportError:
    EMBEDDING_AVAILABLE = False
    logger.warning("[Graph] SiliconFlowEmbedding not available, falling back to keyword matching")


GRAPH_DIR = "data/graphs"
VECTOR_CACHE_DIR = "data/graphs/vectors"


class GraphManager:
    """
    çŸ¥è¯†å›¾è°±ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    åŠŸèƒ½ï¼š
    - å­˜å‚¨å®žä½“å…³ç³»ä¸‰å…ƒç»„
    - æ”¯æŒè¯­ä¹‰æœç´¢ï¼ˆèŠ‚ç‚¹å‘é‡åŒ–ï¼‰
    - å…³ç³»æƒé‡ç´¯ç§¯
    - å®žä½“åˆ«åç®¡ç†
    """
    
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(GraphManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._init_graph()
        self._initialized = True

    def _init_graph(self):
        """åˆå§‹åŒ–å›¾è°±"""
        # [ä¿®æ”¹] ä½¿ç”¨æœ‰å‘å›¾
        self.graph = nx.DiGraph()
        self.current_file_path = None
        self.current_session_uuid = None
        
        # èŠ‚ç‚¹å‘é‡ç¼“å­˜ {node_name: embedding_vector}
        self.node_vectors: Dict[str, np.ndarray] = {}
        self.vector_cache_path = None
        
        # å®žä½“åˆ«åæ˜ å°„ {alias: canonical_name}
        self.aliases: Dict[str, str] = {}
        
        # å»¶è¿Ÿä¿å­˜æŽ§åˆ¶
        self._dirty = False
        self._save_lock = threading.Lock()
        self._last_save_time = 0
        self._save_interval = 30  # æœ€å°‘ 30 ç§’ä¿å­˜ä¸€æ¬¡
        
        # å‘é‡åŒ–å·¥å…·
        self.embedding_fn = None
        if EMBEDDING_AVAILABLE:
            try:
                self.embedding_fn = SiliconFlowEmbedding()
                logger.info("[Graph] Embedding function initialized")
            except Exception as e:
                logger.warning(f"[Graph] Failed to init embedding: {e}")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for dir_path in [GRAPH_DIR, VECTOR_CACHE_DIR]:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)

    # ==========================================
    # ä¼šè¯ç®¡ç†
    # ==========================================

    def switch_session(self, session_uuid: str):
        """åˆ‡æ¢åˆ°æŒ‡å®šä¼šè¯çš„å›¾è°±"""
        # ä¿å­˜å½“å‰ä¼šè¯
        if self.current_file_path and self._dirty:
            self._save_now()
        
        self.current_session_uuid = session_uuid
        self.current_file_path = os.path.join(GRAPH_DIR, f"graph_{session_uuid}.gml")
        self.vector_cache_path = os.path.join(VECTOR_CACHE_DIR, f"vectors_{session_uuid}.json")
        
        # é‡ç½®
        self.graph = nx.DiGraph()
        self.node_vectors = {}
        self.aliases = {}
        self._dirty = False
        
        # åŠ è½½
        self._load_graph()
        self._load_vectors()
        self._load_aliases()
        
        logger.info(f"[Graph] Switched to session: {session_uuid} | "
                   f"Nodes: {self.graph.number_of_nodes()}, Edges: {self.graph.number_of_edges()}")

    def _load_graph(self):
        """åŠ è½½å›¾è°±æ–‡ä»¶"""
        if not self.current_file_path or not os.path.exists(self.current_file_path):
            logger.info("[Graph] New graph initialized")
            return
        
        try:
            # NetworkX çš„ GML è¯»å–é»˜è®¤æ˜¯æ— å‘å›¾ï¼Œéœ€è¦æŒ‡å®š
            self.graph = nx.read_gml(self.current_file_path)
            
            # å¦‚æžœåŠ è½½çš„æ˜¯æ—§çš„æ— å‘å›¾ï¼Œè½¬æ¢ä¸ºæœ‰å‘å›¾
            if not self.graph.is_directed():
                logger.info("[Graph] Converting undirected graph to directed")
                self.graph = self.graph.to_directed()
            
            logger.info(f"[Graph] Loaded: {os.path.basename(self.current_file_path)}")
        except Exception as e:
            logger.error(f"[Graph] Load failed: {e}")
            self.graph = nx.DiGraph()

    def _load_vectors(self):
        """åŠ è½½å‘é‡ç¼“å­˜"""
        if not self.vector_cache_path or not os.path.exists(self.vector_cache_path):
            return
        
        try:
            with open(self.vector_cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.node_vectors = {
                k: np.array(v) for k, v in data.get('vectors', {}).items()
            }
            logger.info(f"[Graph] Loaded {len(self.node_vectors)} node vectors from cache")
        except Exception as e:
            logger.warning(f"[Graph] Vector cache load failed: {e}")

    def _load_aliases(self):
        """åŠ è½½å®žä½“åˆ«å"""
        alias_path = self.current_file_path.replace('.gml', '_aliases.json') if self.current_file_path else None
        if not alias_path or not os.path.exists(alias_path):
            return
        
        try:
            with open(alias_path, 'r', encoding='utf-8') as f:
                self.aliases = json.load(f)
            logger.info(f"[Graph] Loaded {len(self.aliases)} entity aliases")
        except Exception as e:
            logger.warning(f"[Graph] Alias load failed: {e}")

    # ==========================================
    # ä¿å­˜é€»è¾‘
    # ==========================================

    def save(self):
        """æ ‡è®°éœ€è¦ä¿å­˜ï¼ˆå»¶è¿Ÿä¿å­˜ï¼‰"""
        self._dirty = True
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³ä¿å­˜
        current_time = time.time()
        if current_time - self._last_save_time > self._save_interval:
            self._save_now()

    def _save_now(self):
        """ç«‹å³ä¿å­˜æ‰€æœ‰æ•°æ®"""
        with self._save_lock:
            if not self.current_file_path:
                return
            
            try:
                # ä¿å­˜å›¾è°±
                nx.write_gml(self.graph, self.current_file_path)
                
                # ä¿å­˜å‘é‡ç¼“å­˜
                if self.vector_cache_path and self.node_vectors:
                    vector_data = {
                        'vectors': {k: v.tolist() for k, v in self.node_vectors.items()}
                    }
                    with open(self.vector_cache_path, 'w', encoding='utf-8') as f:
                        json.dump(vector_data, f)
                
                # ä¿å­˜åˆ«å
                if self.aliases:
                    alias_path = self.current_file_path.replace('.gml', '_aliases.json')
                    with open(alias_path, 'w', encoding='utf-8') as f:
                        json.dump(self.aliases, f, ensure_ascii=False)
                
                self._dirty = False
                self._last_save_time = time.time()
                
            except Exception as e:
                logger.error(f"[Graph] Save failed: {e}")

    def flush(self):
        """å¼ºåˆ¶ä¿å­˜ï¼ˆå…³é—­æ—¶è°ƒç”¨ï¼‰"""
        if self._dirty:
            self._save_now()

    # ==========================================
    # å‘é‡åŒ–åŠŸèƒ½
    # ==========================================

    def _get_embedding(self, text: str) -> Optional[np.ndarray]:
        """èŽ·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        if not self.embedding_fn:
            return None
        
        try:
            # SiliconFlowEmbedding çš„ __call__ æŽ¥å—åˆ—è¡¨
            embeddings = self.embedding_fn([text])
            if embeddings and len(embeddings) > 0:
                return np.array(embeddings[0])
        except Exception as e:
            logger.debug(f"[Graph] Embedding failed for '{text[:20]}...': {e}")
        
        return None

    def _ensure_node_vector(self, node_name: str):
        """ç¡®ä¿èŠ‚ç‚¹æœ‰å‘é‡è¡¨ç¤º"""
        if node_name in self.node_vectors:
            return
        
        vec = self._get_embedding(node_name)
        if vec is not None:
            self.node_vectors[node_name] = vec

    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if vec1 is None or vec2 is None:
            return 0.0
        
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return float(np.dot(vec1, vec2) / (norm1 * norm2))

    # ==========================================
    # å®žä½“åˆ«åç®¡ç†
    # ==========================================

    def add_alias(self, alias: str, canonical_name: str):
        """æ·»åŠ å®žä½“åˆ«å"""
        if not alias or not canonical_name:
            return
        
        alias_lower = alias.lower().strip()
        canonical_lower = canonical_name.lower().strip()
        
        if alias_lower != canonical_lower:
            self.aliases[alias_lower] = canonical_name
            self._dirty = True

    def resolve_entity(self, name: str) -> str:
        """è§£æžå®žä½“åç§°ï¼ˆå¤„ç†åˆ«åï¼‰"""
        if not name:
            return name
        
        name_lower = name.lower().strip()
        return self.aliases.get(name_lower, name)

    # ==========================================
    # ä¸‰å…ƒç»„æ“ä½œ
    # ==========================================

    def add_triplet(self, source: str, relation: str, target: str, 
                    description: str = "", confidence: float = 1.0):
        """
        æ·»åŠ ä¸‰å…ƒç»„: (Source) --[Relation]--> (Target)
        
        [æ”¹è¿›] 
        - ç›¸åŒè¾¹å¤šæ¬¡æ·»åŠ ä¼šç´¯ç§¯æƒé‡
        - è‡ªåŠ¨å‘é‡åŒ–æ–°èŠ‚ç‚¹
        - æ”¯æŒåˆ«åè§£æž
        """
        if not source or not target or not relation:
            return
        
        # è§£æžåˆ«å
        source = self.resolve_entity(source.strip())
        target = self.resolve_entity(target.strip())
        relation = relation.strip()
        
        # æ·»åŠ /æ›´æ–°èŠ‚ç‚¹
        if not self.graph.has_node(source):
            self.graph.add_node(source, type="entity", first_seen=time.time())
            self._ensure_node_vector(source)
        
        if not self.graph.has_node(target):
            self.graph.add_node(target, type="entity", first_seen=time.time())
            self._ensure_node_vector(target)
        
        # æ·»åŠ /æ›´æ–°è¾¹
        if self.graph.has_edge(source, target):
            # è¾¹å·²å­˜åœ¨ï¼Œç´¯ç§¯æƒé‡å’Œè¡¥å……æè¿°
            edge_data = self.graph[source][target]
            old_weight = edge_data.get('weight', 1.0)
            old_relations = edge_data.get('relations', [edge_data.get('relation', '')])
            old_descs = edge_data.get('descriptions', [edge_data.get('desc', '')])
            
            # ç´¯ç§¯æƒé‡
            new_weight = old_weight + confidence
            
            # åˆå¹¶å…³ç³»ï¼ˆåŽ»é‡ï¼‰
            if relation not in old_relations:
                old_relations.append(relation)
            
            # åˆå¹¶æè¿°ï¼ˆåŽ»é‡ï¼‰
            if description and description not in old_descs:
                old_descs.append(description)
            
            self.graph[source][target].update({
                'weight': new_weight,
                'relation': old_relations[0],  # ä¸»å…³ç³»
                'relations': old_relations,     # æ‰€æœ‰å…³ç³»
                'desc': old_descs[0] if old_descs else '',
                'descriptions': old_descs,
                'last_updated': time.time()
            })
        else:
            # æ–°è¾¹
            self.graph.add_edge(
                source, target,
                relation=relation,
                relations=[relation],
                desc=description,
                descriptions=[description] if description else [],
                weight=confidence,
                first_seen=time.time(),
                last_updated=time.time()
            )
        
        self.save()

    def add_triplets_batch(self, triplets: List[Dict]):
        """
        æ‰¹é‡æ·»åŠ ä¸‰å…ƒç»„
        
        :param triplets: [{"source": "", "relation": "", "target": "", "desc": "", "confidence": 1.0}, ...]
        """
        for t in triplets:
            self.add_triplet(
                source=t.get('source', ''),
                relation=t.get('relation', ''),
                target=t.get('target', ''),
                description=t.get('desc', t.get('description', '')),
                confidence=t.get('confidence', 1.0)
            )
        
        # æ‰¹é‡æ“ä½œåŽå¼ºåˆ¶ä¿å­˜
        self._save_now()

    # ==========================================
    # æœç´¢åŠŸèƒ½
    # ==========================================

    def search_subgraph(self, query: str, top_k: int = 5, depth: int = 1, 
                        min_weight: float = 0.0) -> str:
        """
        æœç´¢ç›¸å…³å­å›¾
        
        [æ”¹è¿›]
        - æ”¯æŒè¯­ä¹‰æœç´¢ï¼ˆå‘é‡åŒ¹é…ï¼‰
        - ç»“æžœæŒ‰æƒé‡æŽ’åº
        - æ”¯æŒæœ€å°æƒé‡è¿‡æ»¤
        
        :param query: æœç´¢æŸ¥è¯¢ï¼ˆå¯ä»¥æ˜¯å…³é”®è¯æˆ–å¥å­ï¼‰
        :param top_k: è¿”å›žæœ€ç›¸å…³çš„ top_k ä¸ªèµ·å§‹èŠ‚ç‚¹
        :param depth: å›¾éåŽ†æ·±åº¦
        :param min_weight: æœ€å°è¾¹æƒé‡è¿‡æ»¤
        :return: æ ¼å¼åŒ–çš„å…³ç³»æ–‡æœ¬
        """
        if self.graph.number_of_nodes() == 0:
            return ""
        
        # æ‰¾åˆ°ç›¸å…³èŠ‚ç‚¹
        relevant_nodes = self._find_relevant_nodes(query, top_k)
        
        if not relevant_nodes:
            return ""
        
        # ä»Žç›¸å…³èŠ‚ç‚¹å‡ºå‘ï¼Œæ”¶é›†å­å›¾
        result_edges = []
        visited_edges: Set[Tuple[str, str, str]] = set()
        
        for start_node, node_score in relevant_nodes:
            try:
                # èŽ·å–ä»¥è¯¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„å­å›¾
                subgraph = nx.ego_graph(self.graph, start_node, radius=depth)
                
                for u, v, data in subgraph.edges(data=True):
                    edge_weight = data.get('weight', 1.0)
                    
                    # æƒé‡è¿‡æ»¤
                    if edge_weight < min_weight:
                        continue
                    
                    relation = data.get('relation', 'related_to')
                    edge_key = (u, relation, v)
                    
                    if edge_key in visited_edges:
                        continue
                    visited_edges.add(edge_key)
                    
                    # è®¡ç®—è¾¹çš„ç»¼åˆå¾—åˆ†
                    edge_score = node_score * edge_weight
                    
                    desc = data.get('desc', '')
                    all_relations = data.get('relations', [relation])
                    
                    result_edges.append({
                        'source': u,
                        'target': v,
                        'relation': relation,
                        'all_relations': all_relations,
                        'desc': desc,
                        'weight': edge_weight,
                        'score': edge_score
                    })
                    
            except nx.NetworkXError:
                # èŠ‚ç‚¹ä¸å­˜åœ¨ç­‰é”™è¯¯
                continue
        
        # æŒ‰å¾—åˆ†æŽ’åº
        result_edges.sort(key=lambda x: x['score'], reverse=True)
        
        # æ ¼å¼åŒ–è¾“å‡º
        return self._format_edges(result_edges)

    def _find_relevant_nodes(self, query: str, top_k: int = 5) -> List[Tuple[str, float]]:
        """
        æ‰¾åˆ°ä¸ŽæŸ¥è¯¢æœ€ç›¸å…³çš„èŠ‚ç‚¹
        
        ä¼˜å…ˆä½¿ç”¨å‘é‡åŒ¹é…ï¼Œå›žé€€åˆ°å…³é”®è¯åŒ¹é…
        """
        nodes = list(self.graph.nodes())
        if not nodes:
            return []
        
        scored_nodes = []
        
        # å°è¯•å‘é‡åŒ¹é…
        query_vec = self._get_embedding(query) if self.embedding_fn else None
        
        if query_vec is not None and len(self.node_vectors) > 0:
            # è¯­ä¹‰æœç´¢æ¨¡å¼
            for node in nodes:
                node_vec = self.node_vectors.get(node)
                
                if node_vec is not None:
                    sim = self._cosine_similarity(query_vec, node_vec)
                    scored_nodes.append((node, sim))
                else:
                    # æ²¡æœ‰å‘é‡çš„èŠ‚ç‚¹ï¼Œç”¨å…³é”®è¯åŒ¹é…å…œåº•
                    keyword_score = self._keyword_match_score(query, node)
                    scored_nodes.append((node, keyword_score * 0.5))  # é™æƒ
        else:
            # å…³é”®è¯åŒ¹é…æ¨¡å¼ï¼ˆå›žé€€ï¼‰
            for node in nodes:
                score = self._keyword_match_score(query, node)
                if score > 0:
                    scored_nodes.append((node, score))
        
        # æŽ’åºå¹¶è¿”å›ž top_k
        scored_nodes.sort(key=lambda x: x[1], reverse=True)
        
        # è¿‡æ»¤ä½Žåˆ†
        min_score = 0.1 if query_vec is not None else 0.01
        filtered = [(n, s) for n, s in scored_nodes if s > min_score]
        
        return filtered[:top_k]

    def _keyword_match_score(self, query: str, node: str) -> float:
        """å…³é”®è¯åŒ¹é…å¾—åˆ†"""
        query_lower = query.lower()
        node_lower = str(node).lower()
        
        # å®Œå…¨åŒ¹é…
        if query_lower == node_lower:
            return 1.0
        
        # åŒ…å«åŒ¹é…
        if query_lower in node_lower:
            return 0.8
        if node_lower in query_lower:
            return 0.6
        
        # è¯çº§åŒ¹é…
        query_words = set(query_lower.split())
        node_words = set(node_lower.split())
        
        if query_words & node_words:
            overlap = len(query_words & node_words)
            total = len(query_words | node_words)
            return 0.5 * overlap / total
        
        return 0.0

    def _format_edges(self, edges: List[Dict]) -> str:
        """æ ¼å¼åŒ–è¾¹ä¸ºæ–‡æœ¬è¾“å‡º"""
        if not edges:
            return ""
        
        lines = []
        for e in edges:
            source = e['source']
            target = e['target']
            relation = e['relation']
            weight = e['weight']
            desc = e.get('desc', '')
            
            # æƒé‡æ ‡æ³¨
            if weight >= 3:
                weight_tag = "[å¼ºå…³ç³»]"
            elif weight >= 2:
                weight_tag = "[ä¸­å…³ç³»]"
            else:
                weight_tag = ""
            
            line = f"{weight_tag}({source}) --[{relation}]--> ({target})"
            
            # æ·»åŠ æè¿°
            if desc:
                line += f" | {desc}"
            
            lines.append(line)
        
        return "\n".join(lines)

    # ==========================================
    # é«˜çº§æŸ¥è¯¢
    # ==========================================

    def get_entity_relations(self, entity: str) -> Dict:
        """
        èŽ·å–å®žä½“çš„æ‰€æœ‰å…³ç³»
        
        :return: {"outgoing": [...], "incoming": [...]}
        """
        entity = self.resolve_entity(entity)
        
        if not self.graph.has_node(entity):
            return {"outgoing": [], "incoming": []}
        
        outgoing = []
        incoming = []
        
        # å‡ºè¾¹
        for _, target, data in self.graph.out_edges(entity, data=True):
            outgoing.append({
                'target': target,
                'relation': data.get('relation', ''),
                'weight': data.get('weight', 1.0)
            })
        
        # å…¥è¾¹
        for source, _, data in self.graph.in_edges(entity, data=True):
            incoming.append({
                'source': source,
                'relation': data.get('relation', ''),
                'weight': data.get('weight', 1.0)
            })
        
        return {
            "outgoing": sorted(outgoing, key=lambda x: x['weight'], reverse=True),
            "incoming": sorted(incoming, key=lambda x: x['weight'], reverse=True)
        }

    def find_path(self, source: str, target: str, max_depth: int = 3) -> Optional[str]:
        """
        æŸ¥æ‰¾ä¸¤ä¸ªå®žä½“ä¹‹é—´çš„è·¯å¾„
        """
        source = self.resolve_entity(source)
        target = self.resolve_entity(target)
        
        if not self.graph.has_node(source) or not self.graph.has_node(target):
            return None
        
        try:
            path = nx.shortest_path(self.graph, source, target)
            
            if len(path) > max_depth + 1:
                return None
            
            # æ ¼å¼åŒ–è·¯å¾„
            path_parts = []
            for i in range(len(path) - 1):
                u, v = path[i], path[i + 1]
                edge_data = self.graph[u][v]
                relation = edge_data.get('relation', '?')
                path_parts.append(f"({u}) --[{relation}]--> ({v})")
            
            return " => ".join(path_parts)
            
        except nx.NetworkXNoPath:
            return None
        except Exception:
            return None

    def get_common_neighbors(self, entity1: str, entity2: str) -> List[str]:
        """æŸ¥æ‰¾ä¸¤ä¸ªå®žä½“çš„å…±åŒå…³è”å®žä½“"""
        entity1 = self.resolve_entity(entity1)
        entity2 = self.resolve_entity(entity2)
        
        if not self.graph.has_node(entity1) or not self.graph.has_node(entity2):
            return []
        
        # èŽ·å–é‚»å±…ï¼ˆå¿½ç•¥æ–¹å‘ï¼‰
        neighbors1 = set(self.graph.predecessors(entity1)) | set(self.graph.successors(entity1))
        neighbors2 = set(self.graph.predecessors(entity2)) | set(self.graph.successors(entity2))
        
        return list(neighbors1 & neighbors2)

    # ==========================================
    # å›¾è°±ç»´æŠ¤
    # ==========================================

    def merge_entities(self, entity1: str, entity2: str, canonical_name: str = None):
        """
        åˆå¹¶ä¸¤ä¸ªå®žä½“èŠ‚ç‚¹
        
        :param entity1: å®žä½“1
        :param entity2: å®žä½“2
        :param canonical_name: åˆå¹¶åŽçš„æ ‡å‡†åç§°ï¼ˆé»˜è®¤ç”¨ entity1ï¼‰
        """
        if not self.graph.has_node(entity1) and not self.graph.has_node(entity2):
            return
        
        canonical = canonical_name or entity1
        other = entity2 if canonical == entity1 else entity1
        
        if not self.graph.has_node(other):
            return
        
        # ç¡®ä¿ canonical èŠ‚ç‚¹å­˜åœ¨
        if not self.graph.has_node(canonical):
            self.graph.add_node(canonical, type="entity")
        
        # è½¬ç§»æ‰€æœ‰è¾¹åˆ° canonical
        for source, _, data in list(self.graph.in_edges(other, data=True)):
            if source != canonical:
                self.add_triplet(source, data.get('relation', ''), canonical, 
                               data.get('desc', ''), data.get('weight', 1.0))
        
        for _, target, data in list(self.graph.out_edges(other, data=True)):
            if target != canonical:
                self.add_triplet(canonical, data.get('relation', ''), target,
                               data.get('desc', ''), data.get('weight', 1.0))
        
        # åˆ é™¤æ—§èŠ‚ç‚¹
        self.graph.remove_node(other)
        
        # æ·»åŠ åˆ«å
        self.add_alias(other, canonical)
        
        # è½¬ç§»å‘é‡
        if other in self.node_vectors and canonical not in self.node_vectors:
            self.node_vectors[canonical] = self.node_vectors.pop(other)
        elif other in self.node_vectors:
            del self.node_vectors[other]
        
        self.save()
        logger.info(f"[Graph] Merged '{other}' into '{canonical}'")

    def prune_weak_edges(self, min_weight: float = 0.5):
        """
        åˆ é™¤ä½Žæƒé‡çš„è¾¹
        """
        edges_to_remove = []
        
        for u, v, data in self.graph.edges(data=True):
            if data.get('weight', 1.0) < min_weight:
                edges_to_remove.append((u, v))
        
        for u, v in edges_to_remove:
            self.graph.remove_edge(u, v)
        
        if edges_to_remove:
            self._save_now()
            logger.info(f"[Graph] Pruned {len(edges_to_remove)} weak edges")

    def prune_orphan_nodes(self):
        """åˆ é™¤å­¤ç«‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰ä»»ä½•è¾¹ï¼‰"""
        orphans = [n for n in self.graph.nodes() if self.graph.degree(n) == 0]
        
        for node in orphans:
            self.graph.remove_node(node)
            if node in self.node_vectors:
                del self.node_vectors[node]
        
        if orphans:
            self._save_now()
            logger.info(f"[Graph] Removed {len(orphans)} orphan nodes")

    # ==========================================
    # ç»Ÿè®¡ä¸Žè°ƒè¯•
    # ==========================================

    def get_stats(self) -> str:
        """èŽ·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
        node_count = self.graph.number_of_nodes()
        edge_count = self.graph.number_of_edges()
        vector_count = len(self.node_vectors)
        alias_count = len(self.aliases)
        
        return (f"Nodes: {node_count}, Edges: {edge_count}, "
                f"Vectors: {vector_count}, Aliases: {alias_count}")

    def get_detailed_stats(self) -> Dict:
        """èŽ·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        if self.graph.number_of_nodes() == 0:
            return {"empty": True}
        
        weights = [d.get('weight', 1.0) for _, _, d in self.graph.edges(data=True)]
        
        return {
            "nodes": self.graph.number_of_nodes(),
            "edges": self.graph.number_of_edges(),
            "vectors_cached": len(self.node_vectors),
            "aliases": len(self.aliases),
            "avg_edge_weight": sum(weights) / len(weights) if weights else 0,
            "max_edge_weight": max(weights) if weights else 0,
            "density": nx.density(self.graph),
            "is_connected": nx.is_weakly_connected(self.graph) if self.graph.number_of_nodes() > 0 else False
        }

    def export_for_visualization(self) -> Dict:
        """å¯¼å‡ºä¸ºå‰ç«¯å¯è§†åŒ–æ ¼å¼ï¼ˆå¦‚ vis.js, D3.jsï¼‰"""
        nodes = []
        for node in self.graph.nodes():
            nodes.append({
                "id": node,
                "label": node,
                "type": self.graph.nodes[node].get('type', 'entity')
            })
        
        edges = []
        for u, v, data in self.graph.edges(data=True):
            edges.append({
                "from": u,
                "to": v,
                "label": data.get('relation', ''),
                "weight": data.get('weight', 1.0)
            })
        
        return {"nodes": nodes, "edges": edges}

    # ==========================================
    # ä¼šè¯æ¸…ç†
    # ==========================================

    def delete_graph(self, session_uuid: str):
        """åˆ é™¤æŒ‡å®šä¼šè¯çš„å›¾è°±"""
        target_path = os.path.join(GRAPH_DIR, f"graph_{session_uuid}.gml")
        vector_path = os.path.join(VECTOR_CACHE_DIR, f"vectors_{session_uuid}.json")
        alias_path = os.path.join(GRAPH_DIR, f"graph_{session_uuid}_aliases.json")
        
        files_to_delete = [target_path, vector_path, alias_path]
        
        for file_path in files_to_delete:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.info(f"[Graph] Deleted: {file_path}")
                except Exception as e:
                    logger.error(f"[Graph] Delete failed for {file_path}: {e}")
        
        # å¦‚æžœåˆ é™¤çš„æ˜¯å½“å‰ä¼šè¯ï¼Œé‡ç½®
        if self.current_session_uuid == session_uuid:
            self.graph = nx.DiGraph()
            self.node_vectors = {}
            self.aliases = {}
            self.current_file_path = None
            self.current_session_uuid = None

    def clear_current_graph(self):
        """æ¸…ç©ºå½“å‰å›¾è°±ï¼ˆä¿ç•™æ–‡ä»¶ï¼‰"""
        self.graph = nx.DiGraph()
        self.node_vectors = {}
        self._dirty = True
        self.save()
        logger.info("[Graph] Current graph cleared")


========================================
File Path: .\core\database\redis_manager.py
========================================

# core/database/redis_manager.py
import json
import redis
from config.settings import REDIS_HOST, REDIS_PORT, REDIS_DB, REDIS_PASSWORD, USE_REDIS, REDIS_TTL
from core.utils.logger import logger

class RedisManager:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(RedisManager, cls).__new__(cls)
            cls._instance._init_redis()
        return cls._instance

    def _init_redis(self):
        self.enabled = USE_REDIS
        self.client = None
        if self.enabled:
            try:
                self.client = redis.Redis(
                    host=REDIS_HOST,
                    port=REDIS_PORT,
                    db=REDIS_DB,
                    password=REDIS_PASSWORD,
                    decode_responses=True, # è‡ªåŠ¨å°† bytes è§£ç ä¸º str
                    socket_connect_timeout=2
                )
                self.client.ping() # æµ‹è¯•è¿žæŽ¥
                logger.info(f"Redis (Hot DB) Connected [DB:{REDIS_DB}]")
            except Exception as e:
                logger.warning(f"Redis Connection Failed. Downgrading to SQLite only: {e}")
                self.enabled = False

    # ==========================
    # 1. ä¸Šä¸‹æ–‡ç¼“å­˜ (Context Window)
    # ==========================
    
    def cache_context(self, session_uuid, messages):
        """
        ç¼“å­˜æœ€è¿‘çš„å¯¹è¯åŽ†å² (Context Window)
        :param messages: list of dict [{'role': 'user', 'content': '...'}]
        """
        if not self.enabled: return
        key = f"session:{session_uuid}:context"
        try:
            # å­˜ä¸º JSON å­—ç¬¦ä¸²
            self.client.setex(key, REDIS_TTL, json.dumps(messages, ensure_ascii=False))
        except Exception as e:
            logger.error(f"Redis Write Context Failed: {e}")

    def get_context(self, session_uuid):
        """
        èŽ·å–ç¼“å­˜çš„ä¸Šä¸‹æ–‡
        :return: list or None (None è¡¨ç¤º Cache Miss)
        """
        if not self.enabled: return None
        key = f"session:{session_uuid}:context"
        try:
            data = self.client.get(key)
            if data:
                return json.loads(data)
            return None 
        except Exception as e:
            logger.error(f"Redis Read Context Failed: {e}")
            return None

    def clear_context(self, session_uuid):
        """æ¸…é™¤ä¸Šä¸‹æ–‡ç¼“å­˜"""
        if not self.enabled: return
        try:
            self.client.delete(f"session:{session_uuid}:context")
        except: pass

    # ==========================
    # 2. çŠ¶æ€ç¼“å­˜ (State Cache)
    # ==========================

    def cache_state(self, session_uuid, state_dict):
        """ç¼“å­˜æœ€æ–°çš„ RPG çŠ¶æ€"""
        if not self.enabled: return
        key = f"session:{session_uuid}:state"
        try:
            self.client.setex(key, REDIS_TTL, json.dumps(state_dict, ensure_ascii=False))
        except Exception as e:
            logger.error(f"Redis Write State Failed: {e}")

    def get_state(self, session_uuid):
        """èŽ·å–ç¼“å­˜çš„çŠ¶æ€"""
        if not self.enabled: return None
        key = f"session:{session_uuid}:state"
        try:
            data = self.client.get(key)
            if data:
                return json.loads(data)
            return None
        except:
            return None
            
    def clear_state(self, session_uuid):
        """æ¸…é™¤çŠ¶æ€ç¼“å­˜"""
        if not self.enabled: return
        try:
            self.client.delete(f"session:{session_uuid}:state")
        except: pass


========================================
File Path: .\core\database\schema.sql
========================================

-- core/database/schema.sql

-- 1. ä¼šè¯è¡¨
CREATE TABLE IF NOT EXISTS conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    uuid TEXT UNIQUE NOT NULL,
    character_name TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_state_json TEXT
);

-- 2. æ¶ˆæ¯è¡¨ (æ— æŸè®°å½•)
CREATE TABLE IF NOT EXISTS messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    role TEXT NOT NULL,
    content TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_summarized BOOLEAN DEFAULT 0, -- æ˜¯å¦å·²è¢« Left Brain å¤„ç†
    meta_tags TEXT, -- ç”¨äºŽå­˜å‚¨ "Flashback" ç­‰æ ‡è®°
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 3. è®°å¿†èŠ‚ç‚¹è¡¨ (é€’å½’æ‘˜è¦æ ¸å¿ƒ)
CREATE TABLE IF NOT EXISTS memory_nodes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    summary_text TEXT,
    level TEXT DEFAULT 'MICRO',        -- 'MICRO' (5è½®) | 'MACRO' (50è½®)
    timeline_tag TEXT,                 -- æ—¶é—´é”šç‚¹ (Day 1, 14:00)
    is_merged BOOLEAN DEFAULT 0,       -- æ˜¯å¦å·²è¢«åˆå¹¶è¿›æ›´é«˜å±‚çº§
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    vector_id TEXT,                    -- å…³è”å‘é‡åº“ID
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 4. å…³ç³»å›¾è°±è¡¨
CREATE TABLE IF NOT EXISTS relationships (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    source_entity TEXT,
    target_entity TEXT,
    value INTEGER,
    tags TEXT,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 5. å²è¯—ç« èŠ‚è¡¨
CREATE TABLE IF NOT EXISTS saga_entries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    chapter_title TEXT,
    content TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 6. ä¸–ç•Œè®¾å®šè¡¨ (Lore)
CREATE TABLE IF NOT EXISTS lore_entries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    keyword TEXT UNIQUE,
    content TEXT,
    source TEXT, -- 'AI_Generated' or 'Internet'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 7. äº¤äº’æ—¥å¿— (é»‘åŒ£å­ - è°ƒè¯•ç”¨)
CREATE TABLE IF NOT EXISTS interaction_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    message_id INTEGER,
    full_prompt TEXT,
    rag_context TEXT,
    model_name TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);

-- 8. ä¸–ç•ŒçŠ¶æ€å¿«ç…§ (å›žæ»šç”¨)
CREATE TABLE IF NOT EXISTS world_states (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER,
    message_id INTEGER, -- å…³è”åˆ°å…·ä½“çš„æŸæ¡æ¶ˆæ¯IDï¼Œç”¨äºŽå›žæ»šå®šä½
    state_json TEXT,
    diff_summary TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(conversation_id) REFERENCES conversations(id)
);


========================================
File Path: .\core\database\schema_rules.sql
========================================

-- core/database/schema_rules.sql

DROP TABLE IF EXISTS rule_fragments;

CREATE TABLE IF NOT EXISTS rule_fragments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT NOT NULL,           -- æ·±åº¦æ¸…æ´—åŽçš„è§„åˆ™
    raw_content TEXT,                -- åŽŸå§‹å†…å®¹å¤‡ä»½
    category TEXT,                   -- æ™ºèƒ½åˆ†ç±» (STYLE, LOGIC...)
    scope_type TEXT DEFAULT 'GLOBAL',-- ä½œç”¨åŸŸç±»åž‹
    scope_value TEXT,                -- ä½œç”¨åŸŸå€¼ (å¦‚ 'LuXun')
    required_tags TEXT,              -- æ™ºèƒ½æ ‡ç­¾ (JSON)
    summary TEXT,                    -- æ™ºèƒ½æ‘˜è¦
    source_preset TEXT,              -- æ¥æºæ–‡ä»¶
    is_active BOOLEAN DEFAULT 0,     -- æ˜¯å¦é»˜è®¤å¼€å¯
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å»ºç«‹ç´¢å¼•åŠ é€ŸæŸ¥è¯¢
CREATE INDEX IF NOT EXISTS idx_rules_scope ON rule_fragments(scope_type, scope_value);
CREATE INDEX IF NOT EXISTS idx_rules_category ON rule_fragments(category);


========================================
File Path: .\core\database\silicon_client.py
========================================

# core/database/silicon_client.py
import requests
from typing import List
from chromadb import Documents, EmbeddingFunction, Embeddings
# å¼•å…¥æ–°çš„é€šç”¨å˜é‡å
from config.settings import VECTOR_API_KEY, VECTOR_BASE_URL, EMBEDDING_MODEL, RERANK_MODEL
from core.utils.logger import logger

class SiliconFlowEmbedding(EmbeddingFunction):
    def __init__(self):
        pass
        
    def name(self):
        return "SiliconFlowEmbedding"

    # ================= [æ–°å¢žä¿®å¤] =================
    def get_config(self):
        """ä¿®å¤ ChromaDB çš„ DeprecationWarning"""
        return {
            "model": EMBEDDING_MODEL,
            "base_url": VECTOR_BASE_URL
        }
    # =============================================

    def __call__(self, input: Documents) -> Embeddings:
        # ä½¿ç”¨ settings.py è§£æžå‡ºæ¥çš„å‘é‡ä¸“ç”¨é…ç½®
        url = f"{VECTOR_BASE_URL}/embeddings"
        headers = {
            "Authorization": f"Bearer {VECTOR_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": EMBEDDING_MODEL,
            "input": input,
            "encoding_format": "float"
        }

        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            embeddings = [item['embedding'] for item in data['data']]
            return embeddings
        except Exception as e:
            logger.error(f"Embedding API è°ƒç”¨å¤±è´¥: {e}")
            raise e

def rerank_documents(query: str, documents: List[str]) -> List[dict]:
    if not documents:
        return []

    url = f"{VECTOR_BASE_URL}/rerank"
    headers = {
        "Authorization": f"Bearer {VECTOR_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": RERANK_MODEL,
        "query": query,
        "documents": documents,
        "top_n": len(documents),
        "return_documents": False
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        return data['results']
    except Exception as e:
        logger.error(f"Rerank API è°ƒç”¨å¤±è´¥: {e}")
        return []


========================================
File Path: .\core\database\sqlite_manager.py
========================================

# core/database/sqlite_manager.py
"""
DeepTavern SQLite æ•°æ®åº“ç®¡ç†å™¨ v4.5
- é€‚é…æ‰©å±•çŠ¶æ€ç³»ç»Ÿ
- æ”¯æŒæ–°çš„çŠ¶æ€ç»“æž„
"""

import sqlite3
import json
import os
import threading
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any

from core.utils.logger import logger

# è·¯å¾„é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(BASE_DIR))
DB_PATH = os.path.join(PROJECT_ROOT, "data", "chat_core.db")
RULES_DB_PATH = os.path.join(PROJECT_ROOT, "data", "rules_preset.db")

SCHEMA_PATH = os.path.join(BASE_DIR, 'schema.sql')
RULES_SCHEMA_PATH = os.path.join(BASE_DIR, 'schema_rules.sql')


class SQLiteManager:
    """
    SQLite æ•°æ®åº“ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    """
    
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(SQLiteManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = os.path.dirname(DB_PATH)
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        self.db_lock = threading.Lock()
        
        # ä¸»æ•°æ®åº“è¿žæŽ¥
        self.conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self.cursor = self.conn.cursor()
        
        # è§„åˆ™æ•°æ®åº“è¿žæŽ¥
        self.conn_rules = sqlite3.connect(RULES_DB_PATH, check_same_thread=False)
        self.conn_rules.row_factory = sqlite3.Row
        self.cursor_rules = self.conn_rules.cursor()
        
        self.current_conversation_id = None
        self._init_schemas()
        self._initialized = True

    def _init_schemas(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æž„"""
        with self.db_lock:
            if os.path.exists(SCHEMA_PATH):
                try:
                    with open(SCHEMA_PATH, 'r', encoding='utf-8') as f:
                        self.cursor.executescript(f.read())
                    self.conn.commit()
                except Exception as e:
                    logger.error(f"ä¸»æ•°æ®åº“åˆå§‹åŒ–é”™è¯¯: {e}")
            
            # è§„åˆ™åº“
            try:
                self.cursor_rules.execute(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name='rule_fragments'"
                )
                if not self.cursor_rules.fetchone():
                    if os.path.exists(RULES_SCHEMA_PATH):
                        with open(RULES_SCHEMA_PATH, 'r', encoding='utf-8') as f:
                            self.cursor_rules.executescript(f.read())
                        self.conn_rules.commit()
            except Exception as e:
                logger.error(f"è§„åˆ™æ•°æ®åº“åˆå§‹åŒ–é”™è¯¯: {e}")

    def _check_session(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒä¼šè¯"""
        if self.current_conversation_id is None:
            pass  # å…è®¸æ— ä¼šè¯æ—¶çš„åªè¯»æ“ä½œ

    # ==========================================
    # è§„åˆ™åº“æŸ¥è¯¢
    # ==========================================

    def get_rule_by_keyword(self, keyword: str) -> Optional[str]:
        """æ ¹æ®å…³é”®è¯æŸ¥è¯¢è§„åˆ™"""
        with self.db_lock:
            self.cursor_rules.execute(
                "SELECT content FROM rule_fragments WHERE scope_value LIKE ? LIMIT 1",
                (f"%{keyword}%",)
            )
            row = self.cursor_rules.fetchone()
            if row:
                return row['content']
            
            self.cursor_rules.execute(
                "SELECT content FROM rule_fragments WHERE summary LIKE ? LIMIT 1",
                (f"%{keyword}%",)
            )
            row = self.cursor_rules.fetchone()
            return row['content'] if row else None

    def get_random_rule(self, category: str) -> Optional[str]:
        """èŽ·å–éšæœºè§„åˆ™"""
        with self.db_lock:
            self.cursor_rules.execute(
                "SELECT content FROM rule_fragments WHERE category = ? ORDER BY RANDOM() LIMIT 1",
                (category,)
            )
            row = self.cursor_rules.fetchone()
            return row['content'] if row else None

    def get_active_rules(self) -> List[str]:
        """èŽ·å–æ‰€æœ‰é»˜è®¤å¯ç”¨çš„è§„åˆ™"""
        with self.db_lock:
            self.cursor_rules.execute(
                "SELECT content FROM rule_fragments WHERE is_active = 1"
            )
            return [row['content'] for row in self.cursor_rules.fetchall()]

    def get_all_keywords(self) -> List[str]:
        """èŽ·å–æ‰€æœ‰è§„åˆ™å…³é”®è¯"""
        with self.db_lock:
            self.cursor_rules.execute(
                "SELECT scope_value FROM rule_fragments WHERE scope_value IS NOT NULL AND scope_value != ''"
            )
            return list(set([row['scope_value'] for row in self.cursor_rules.fetchall()]))

    def get_context_rules(self, location: str, hp: int, tags_list: List[str]) -> List[str]:
        """æ ¹æ®ä¸Šä¸‹æ–‡èŽ·å–è§„åˆ™"""
        rules = []
        with self.db_lock:
            if location:
                self.cursor_rules.execute(
                    "SELECT content FROM rule_fragments WHERE scope_type='LOCATION' AND scope_value = ?",
                    (location,)
                )
                rules.extend([r['content'] for r in self.cursor_rules.fetchall()])
            
            if hp < 20:
                self.cursor_rules.execute(
                    "SELECT content FROM rule_fragments WHERE scope_type='STATE' AND scope_value = 'LOW_HP'"
                )
                rules.extend([r['content'] for r in self.cursor_rules.fetchall()])
            
            if tags_list:
                for tag in tags_list:
                    self.cursor_rules.execute(
                        "SELECT content FROM rule_fragments WHERE required_tags LIKE ?",
                        (f"%{tag}%",)
                    )
                    rules.extend([r['content'] for r in self.cursor_rules.fetchall()])
        
        return rules

    # ==========================================
    # ä¼šè¯ç®¡ç†
    # ==========================================

    def create_conversation(self, character_name: str, initial_state: Dict) -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_uuid = str(uuid.uuid4())
        json_str = json.dumps(initial_state, ensure_ascii=False)
        
        with self.db_lock:
            self.cursor.execute(
                "INSERT INTO conversations (uuid, character_name, last_state_json) VALUES (?, ?, ?)",
                (session_uuid, character_name, json_str)
            )
            self.current_conversation_id = self.cursor.lastrowid
            self.conn.commit()
        
        return session_uuid

    def load_conversation(self, uuid: str) -> bool:
        """åŠ è½½ä¼šè¯"""
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, character_name FROM conversations WHERE uuid = ?",
                (uuid,)
            )
            row = self.cursor.fetchone()
            if row:
                self.current_conversation_id = row['id']
                return True
            return False

    def list_conversations(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        with self.db_lock:
            self.cursor.execute(
                "SELECT uuid, character_name, created_at FROM conversations ORDER BY id DESC"
            )
            return [dict(row) for row in self.cursor.fetchall()]

    def get_current_character_name(self) -> str:
        """èŽ·å–å½“å‰è§’è‰²å"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT character_name FROM conversations WHERE id = ?",
                (self.current_conversation_id,)
            )
            row = self.cursor.fetchone()
            return row['character_name'] if row else "Unknown"

    def delete_session(self, uuid: str) -> bool:
        """åˆ é™¤ä¼šè¯"""
        with self.db_lock:
            self.cursor.execute("SELECT id FROM conversations WHERE uuid = ?", (uuid,))
            row = self.cursor.fetchone()
            if not row:
                return False
            
            conv_id = row['id']
            
            # çº§è”åˆ é™¤
            tables = [
                "messages", "memory_nodes", "relationships",
                "saga_entries", "lore_entries", "interaction_logs", "world_states"
            ]
            for table in tables:
                self.cursor.execute(f"DELETE FROM {table} WHERE conversation_id = ?", (conv_id,))
            
            self.cursor.execute("DELETE FROM conversations WHERE id = ?", (conv_id,))
            self.conn.commit()
            
            if self.current_conversation_id == conv_id:
                self.current_conversation_id = None
            
            return True

    # ==========================================
    # æ¶ˆæ¯ç®¡ç†
    # ==========================================

    def add_message(self, role: str, content: str) -> int:
        """æ·»åŠ æ¶ˆæ¯"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "INSERT INTO messages (conversation_id, role, content) VALUES (?, ?, ?)",
                (self.current_conversation_id, role, content)
            )
            self.conn.commit()
            return self.cursor.lastrowid

    def get_recent_messages(self, limit: int = 20) -> List[Dict]:
        """èŽ·å–æœ€è¿‘æ¶ˆæ¯"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, role, content FROM messages WHERE conversation_id = ? ORDER BY id DESC LIMIT ?",
                (self.current_conversation_id, limit)
            )
            return [dict(row) for row in reversed(self.cursor.fetchall())]

    def get_unsummarized_messages(self, limit: int = 5) -> List[Dict]:
        """èŽ·å–æœªæ‘˜è¦çš„æ¶ˆæ¯"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, role, content FROM messages WHERE conversation_id = ? AND is_summarized = 0 ORDER BY id ASC LIMIT ?",
                (self.current_conversation_id, limit)
            )
            return [dict(row) for row in self.cursor.fetchall()]

    def mark_messages_summarized(self, ids: List[int]):
        """æ ‡è®°æ¶ˆæ¯ä¸ºå·²æ‘˜è¦"""
        if not ids:
            return
        with self.db_lock:
            placeholders = ','.join(['?' for _ in ids])
            self.cursor.execute(
                f"UPDATE messages SET is_summarized=1 WHERE id IN ({placeholders})",
                ids
            )
            self.conn.commit()

    def get_full_history(self, page: int = 1, page_size: int = 50) -> List[Dict]:
        """èŽ·å–å®Œæ•´åŽ†å²ï¼ˆåˆ†é¡µï¼‰"""
        self._check_session()
        offset = (page - 1) * page_size
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, role, content, timestamp FROM messages WHERE conversation_id = ? ORDER BY id ASC LIMIT ? OFFSET ?",
                (self.current_conversation_id, page_size, offset)
            )
            return [dict(row) for row in self.cursor.fetchall()]

    # ==========================================
    # çŠ¶æ€ç®¡ç†
    # ==========================================

    def get_current_state(self) -> Dict:
        """èŽ·å–å½“å‰çŠ¶æ€"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT last_state_json FROM conversations WHERE id = ?",
                (self.current_conversation_id,)
            )
            row = self.cursor.fetchone()
            if row and row['last_state_json']:
                try:
                    return json.loads(row['last_state_json'])
                except json.JSONDecodeError:
                    return {}
            return {}

    def save_state(self, state: Dict, diff_summary: str = "", message_id: int = None):
        """ä¿å­˜çŠ¶æ€"""
        self._check_session()
        json_str = json.dumps(state, ensure_ascii=False)
        
        with self.db_lock:
            # æ›´æ–°å½“å‰çŠ¶æ€
            self.cursor.execute(
                "UPDATE conversations SET last_state_json = ? WHERE id = ?",
                (json_str, self.current_conversation_id)
            )
            
            # ä¿å­˜çŠ¶æ€å¿«ç…§ï¼ˆç”¨äºŽå›žæ»šï¼‰
            self.cursor.execute(
                "INSERT INTO world_states (conversation_id, message_id, state_json, diff_summary) VALUES (?, ?, ?, ?)",
                (self.current_conversation_id, message_id, json_str, diff_summary)
            )
            self.conn.commit()

    def rollback_to_message(self, target_message_id: int) -> Optional[Dict]:
        """å›žæ»šåˆ°æŒ‡å®šæ¶ˆæ¯"""
        self._check_session()
        with self.db_lock:
            # æŸ¥æ‰¾å¯¹åº”çš„çŠ¶æ€å¿«ç…§
            self.cursor.execute(
                "SELECT state_json FROM world_states WHERE conversation_id = ? AND message_id <= ? ORDER BY message_id DESC LIMIT 1",
                (self.current_conversation_id, target_message_id)
            )
            row = self.cursor.fetchone()
            
            if row:
                state_data = json.loads(row['state_json'])
                json_str = json.dumps(state_data, ensure_ascii=False)
                
                # æ¢å¤çŠ¶æ€
                self.cursor.execute(
                    "UPDATE conversations SET last_state_json = ? WHERE id = ?",
                    (json_str, self.current_conversation_id)
                )
                
                # åˆ é™¤åŽç»­æ¶ˆæ¯
                self.cursor.execute(
                    "DELETE FROM messages WHERE conversation_id = ? AND id > ?",
                    (self.current_conversation_id, target_message_id)
                )
                
                # åˆ é™¤åŽç»­çŠ¶æ€å¿«ç…§
                self.cursor.execute(
                    "DELETE FROM world_states WHERE conversation_id = ? AND message_id > ?",
                    (self.current_conversation_id, target_message_id)
                )
                
                self.conn.commit()
                return state_data
            
            return None

    # ==========================================
    # è®°å¿†èŠ‚ç‚¹ç®¡ç†
    # ==========================================

    def get_memory_spine(self) -> str:
        """èŽ·å–è®°å¿†è„ŠæŸ±"""
        self._check_session()
        spine_text = ""
        
        with self.db_lock:
            # å®è§‚è®°å¿†
            self.cursor.execute(
                "SELECT timeline_tag, summary_text FROM memory_nodes WHERE conversation_id = ? AND level = 'MACRO' ORDER BY id ASC",
                (self.current_conversation_id,)
            )
            for r in self.cursor.fetchall():
                spine_text += f"[Macro|{r['timeline_tag']}] {r['summary_text']}\n"
            
            # æœªåˆå¹¶çš„å¾®è§‚è®°å¿†
            self.cursor.execute(
                "SELECT timeline_tag, summary_text FROM memory_nodes WHERE conversation_id = ? AND level = 'MICRO' AND is_merged = 0 ORDER BY id ASC",
                (self.current_conversation_id,)
            )
            for r in self.cursor.fetchall():
                spine_text += f"[Micro|{r['timeline_tag']}] {r['summary_text']}\n"
        
        return spine_text if spine_text else "No history yet."

    def add_memory_node(self, text: str, level: str, timeline_tag: str, vector_id: str = ""):
        """æ·»åŠ è®°å¿†èŠ‚ç‚¹"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "INSERT INTO memory_nodes (conversation_id, summary_text, level, timeline_tag, vector_id) VALUES (?, ?, ?, ?, ?)",
                (self.current_conversation_id, text, level, timeline_tag, vector_id)
            )
            self.conn.commit()

    def get_unmerged_micro_nodes(self, limit: int = 10) -> List[Dict]:
        """èŽ·å–æœªåˆå¹¶çš„å¾®è§‚èŠ‚ç‚¹"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, summary_text, timeline_tag FROM memory_nodes WHERE conversation_id = ? AND level = 'MICRO' AND is_merged = 0 ORDER BY id ASC LIMIT ?",
                (self.current_conversation_id, limit)
            )
            return [dict(row) for row in self.cursor.fetchall()]

    def mark_nodes_merged(self, ids: List[int]):
        """æ ‡è®°èŠ‚ç‚¹ä¸ºå·²åˆå¹¶"""
        if not ids:
            return
        with self.db_lock:
            placeholders = ','.join(['?' for _ in ids])
            self.cursor.execute(
                f"UPDATE memory_nodes SET is_merged=1 WHERE id IN ({placeholders})",
                ids
            )
            self.conn.commit()

    # ==========================================
    # å…¶ä»–åŠŸèƒ½
    # ==========================================

    def save_saga_entry(self, content: str):
        """ä¿å­˜å²è¯—ç« èŠ‚"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "INSERT INTO saga_entries (conversation_id, content) VALUES (?, ?)",
                (self.current_conversation_id, content)
            )
            self.conn.commit()

    def log_interaction(self, assistant_msg_id: int, full_prompt: str, 
                        rag_context: str, model_name: str):
        """è®°å½•äº¤äº’æ—¥å¿—"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "INSERT INTO interaction_logs (conversation_id, message_id, full_prompt, rag_context, model_name) VALUES (?, ?, ?, ?, ?)",
                (self.current_conversation_id, assistant_msg_id, full_prompt, rag_context, model_name)
            )
            self.conn.commit()

    def get_memories(self, limit: int = 50) -> List[Dict]:
        """èŽ·å–è®°å¿†åˆ—è¡¨"""
        self._check_session()
        with self.db_lock:
            self.cursor.execute(
                "SELECT id, summary_text, level, timeline_tag, created_at FROM memory_nodes WHERE conversation_id = ? ORDER BY id DESC LIMIT ?",
                (self.current_conversation_id, limit)
            )
            return [dict(row) for row in self.cursor.fetchall()]

    def get_latest_rumor(self) -> str:
        """èŽ·å–æœ€æ–°ä¼ é—»ï¼ˆå…¼å®¹æŽ¥å£ï¼‰"""
        return ""


========================================
File Path: .\core\database\vector_store.py
========================================

# core/database/vector_store.py
import chromadb
import os
from core.utils.logger import logger
from core.database.silicon_client import SiliconFlowEmbedding, rerank_documents

VECTOR_DB_PATH = "data/chroma_db"

class VectorStore:
    def __init__(self, collection_name="long_term_memory"):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯
        :param collection_name: é›†åˆåç§°ï¼Œé»˜è®¤ä¸º 'long_term_memory' (å‰§æƒ…è®°å¿†)ï¼Œ
                               ä¹Ÿå¯ä»¥æ˜¯ 'rules_memory' (è§„åˆ™åº“) æˆ–å…¶ä»–ã€‚
        """
        # logger.info(f"Initializing Vector DB (Collection: {collection_name})...")
        self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
        
        # ä½¿ç”¨è‡ªå®šä¹‰çš„ç¡…åŸºæµåŠ¨ Embedding å‡½æ•°
        self.ef = SiliconFlowEmbedding()
        
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.ef
        )
        
        # [æ–°å¢ž] åˆå§‹åŒ–æ£€æŸ¥ï¼šåªæœ‰å½“åº“æ˜¯ç©ºçš„ä¸”æ˜¯ä¸»è®°å¿†åº“æ—¶ï¼Œæ‰å†™å…¥å ä½ç¬¦
        # è§„åˆ™åº“ä¸éœ€è¦å ä½ç¬¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¼šé€šè¿‡è„šæœ¬æ‰¹é‡å¯¼å…¥
        if collection_name == "long_term_memory" and self.collection.count() == 0:
            logger.info("å‘é‡åº“ä¸ºç©ºï¼Œå†™å…¥åˆå§‹å ä½ç¬¦...")
            self.collection.add(
                documents=["ç³»ç»Ÿåˆå§‹åŒ–: è®°å¿†åº“å·²å»ºç«‹ã€‚"],
                metadatas=[{"type": "init", "timestamp": "0", "timeline_index": 0}],
                ids=["init_0"]
            )

    def add_memory(self, text: str, metadata: dict, memory_id: str):
        """
        å­˜å…¥è®°å¿† (è‡ªåŠ¨è°ƒç”¨ API èŽ·å–å‘é‡)
        """
        # logger.debug(f"å­˜å‚¨è®°å¿†: {text[:30]}...")
        self.collection.add(
            documents=[text],
            metadatas=[metadata],
            ids=[memory_id]
        )

    def search(self, query: str, n_results: int = 5, filter_dict: dict = None) -> list:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢ï¼šå‘é‡ç²—æŽ’ -> æ¨¡åž‹é‡æŽ’
        """
        # logger.info(f"æ­£åœ¨æ£€ç´¢: '{query}'")
        
        # 1. å‘é‡æ£€ç´¢
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results, 
            where=filter_dict
        )
        
        # æ£€æŸ¥æ˜¯å¦æ£€ç´¢åˆ°æ•°æ®
        if not results['documents'] or not results['documents'][0]:
            return []

        docs = results['documents'][0]
        metas = results['metadatas'][0]
        ids = results['ids'][0]
        
        # 2. è°ƒç”¨é‡æŽ’ API (Rerank)
        # æ³¨æ„ï¼šå¦‚æžœæ£€ç´¢ç»“æžœå¾ˆå°‘ï¼Œé‡æŽ’å¯èƒ½ä¼šæŠ¥é”™æˆ–æ²¡å¿…è¦ï¼Œè¿™é‡ŒåŠ ä¸ªç®€å•åˆ¤æ–­
        if len(docs) > 0:
            try:
                reranked_scores = rerank_documents(query, docs)
            except Exception as e:
                logger.warning(f"Rerank failed, falling back to vector scores: {e}")
                # é™çº§ï¼šæž„é€ ä¸€ä¸ªä¼ªé€ çš„ rerank ç»“æžœç»“æž„
                reranked_scores = [{'index': i, 'relevance_score': 0.0} for i in range(len(docs))]
        else:
            return []
        
        # 3. æ ¹æ®é‡æŽ’åˆ†æ•°é‡æ–°ç»„åˆç»“æžœ
        final_results = []
        for item in reranked_scores:
            idx = item['index']
            score = item['relevance_score']
            
            meta = metas[idx]
            original_content = docs[idx]
            
            # --- æ ¼å¼åŒ–å‰ç¼€é€»è¾‘ ---
            formatted_content = original_content
            
            # ä»…å¯¹ 'long_term_memory' (å‰§æƒ…è®°å¿†) æ·»åŠ æ—¶é—´è½´å‰ç¼€
            if self.collection.name == "long_term_memory":
                prefix_parts = []
                
                # 1. æ—¶é—´è½´ Index
                if 'timeline_index' in meta:
                    prefix_parts.append(f"[Index:{meta['timeline_index']}]")
                elif 'chunk_index' in meta:
                    prefix_parts.append(f"[ç‰‡æ®µ:{meta['chunk_index']}]")
                elif 'start_id' in meta:
                    prefix_parts.append(f"[ID:{meta['start_id']}]")
                    
                # 2. æƒ…æ„Ÿæ ‡ç­¾
                if 'emotions' in meta:
                    prefix_parts.append(f"[æƒ…æ„Ÿ:{meta['emotions']}]")
                    
                # 3. æ—¶é—´æˆ³
                if 'timestamp' in meta and not prefix_parts:
                    # å°è¯•æ ¼å¼åŒ–æ—¶é—´æˆ³
                    try:
                        ts = str(meta['timestamp']).split('T')[0]
                        prefix_parts.append(f"[æ—¥æœŸ:{ts}]")
                    except: pass
                
                # ç»„åˆå‰ç¼€
                if prefix_parts:
                    prefix_str = " ".join(prefix_parts)
                    formatted_content = f"{prefix_str} {original_content}"

            # å¯¹äºŽ 'rules_memory'ï¼Œæˆ‘ä»¬ä¸éœ€è¦åŠ å‰ç¼€ï¼Œç›´æŽ¥è¿”å›žè§„åˆ™å†…å®¹å³å¯
            # æˆ–è€…å¯ä»¥åŠ ä¸€ä¸ªç®€å•çš„ [Category] æ ‡è®°ï¼Œä½†è¿™é€šå¸¸åœ¨å†…å®¹é‡Œå·²ç»æœ‰äº†

            final_results.append({
                "content": formatted_content, # è¿”å›žå¤„ç†åŽçš„æ–‡æœ¬
                "metadata": meta,
                "id": ids[idx],
                "score": score
            })
            
        # logger.info(f"é‡æŽ’å®Œæˆï¼Œè¿”å›ž {len(final_results)} æ¡ç»“æžœ")
        return final_results

    def exists(self, doc_id: str) -> bool:
        """æ£€æŸ¥æŸä¸ª ID æ˜¯å¦å­˜åœ¨ (ç”¨äºŽåŽ»é‡)"""
        res = self.collection.get(ids=[doc_id])
        return len(res['ids']) > 0

    # [æ–°å¢ž] åˆ é™¤æŒ‡å®šä¼šè¯çš„è®°å¿†
    def delete_session_memories(self, session_uuid):
        """åˆ é™¤æŒ‡å®šä¼šè¯çš„æ‰€æœ‰å‘é‡è®°å¿†"""
        try:
            # ChromaDB çš„ delete æ”¯æŒ where è¿‡æ»¤
            self.collection.delete(where={"session_id": session_uuid})
            logger.info(f"[Vector] Deleted memories for session: {session_uuid}")
        except Exception as e:
            logger.error(f"[Vector] Delete failed: {e}")


========================================
File Path: .\core\harvester\cleaner.py
========================================

# core/harvester/cleaner.py
from core.llm.local_direct import LocalDirectLLM
from core.llm.api_client import APILLM
from config.settings import MODEL_CONFIG
from core.utils.logger import logger

# [æ–°å¢ž] èšåˆæ€»ç»“çš„ Prompt
PROMPT_BATCH_SUMMARY = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“ç¼–è¾‘ã€‚
ä½ éœ€è¦æ ¹æ®ä»¥ä¸‹ {count} ç¯‡å…³äºŽ"{keyword}"çš„ç½‘é¡µå†…å®¹ï¼Œæ’°å†™ä¸€ä»½è¯¦å°½çš„â€œæ·±åº¦ç™¾ç§‘æ¡ç›®â€ã€‚

ã€æ¥æºåˆ—è¡¨ã€‘
{context_str}

ã€ä»»åŠ¡è¦æ±‚ã€‘
1. **ç»¼åˆç»Ÿåˆ**ï¼šå°†ä¸åŒæ¥æºçš„ä¿¡æ¯æ‹¼å‡‘åœ¨ä¸€èµ·ï¼ŒåŽ»é™¤é‡å¤å†…å®¹ï¼Œè§£å†³å†²çªã€‚
2. **æ·±åº¦æŒ–æŽ˜**ï¼šä¿ç•™æ‰€æœ‰ç»†èŠ‚ï¼ˆå¦‚å…·ä½“æ•°å€¼ã€æ­¥éª¤ã€å‰§æƒ…è½¬æŠ˜ã€è¯„ä»·ï¼‰ã€‚
3. **ç»“æž„æ¸…æ™°**ï¼šä½¿ç”¨ Markdown æ ¼å¼ï¼ŒåŒ…å«ä¸€çº§æ ‡é¢˜ã€äºŒçº§æ ‡é¢˜å’Œåˆ—è¡¨ã€‚
4. **å®¢è§‚ä¸­ç«‹**ï¼šåƒç»´åŸºç™¾ç§‘ä¸€æ ·å†™ä½œã€‚
5. **ç¯‡å¹…ä¸é™**ï¼šå†…å®¹è¶Šé•¿è¶Šå¥½ï¼Œè¶Šè¯¦ç»†è¶Šå¥½ï¼Œç›®æ ‡å­—æ•° 1500+ å­—ã€‚
6. è¯·å…ˆåœ¨è„‘æµ·ä¸­æ¢³ç†æ‰€æœ‰çº¿ç´¢ï¼Œç„¶åŽä¸€æ­¥æ­¥æž„å»ºè¿™ç¯‡æŠ¥å‘Šã€‚
ã€æ·±åº¦ç™¾ç§‘æ¡ç›®ã€‘
"""

class LocalCleaner:
    def __init__(self):
        seeker_conf = MODEL_CONFIG.get("seeker", {})
        if not seeker_conf:
            seeker_conf = {"model": "qwen2.5:7b", "provider": "local"}
        
        logger.info(f"[Cleaner] Initializing Seeker LLM: {seeker_conf.get('model')}")
        
        model_path = str(seeker_conf.get("model", "")).lower()
        if model_path.endswith(".gguf"):
            self.llm = LocalDirectLLM(config=seeker_conf)
        else:
            self.llm = APILLM(seeker_conf)

    def clean_batch(self, contents_list, keyword):
        """
        [æ–°å¢ž] æ‰¹é‡æ¸…æ´—èšåˆæ–¹æ³•
        :param contents_list: list of dict [{'source': 'url', 'text': '...'}, ...]
        """
        if not contents_list:
            return None

        # 1. æ‹¼æŽ¥ä¸Šä¸‹æ–‡
        context_parts = []
        total_chars = 0
        
        for i, item in enumerate(contents_list):
            # æ¯ä¸ªæ¥æºæˆªå–å‰ 6000 å­—ï¼Œé˜²æ­¢å•ä¸ªç½‘é¡µå¤ªé•¿æ’‘çˆ†æ˜¾å­˜
            text_segment = item['text'][:6000]
            source_tag = f"=== æ¥æº {i+1}: {item['source']} ==="
            context_parts.append(f"{source_tag}\n{text_segment}\n")
            total_chars += len(text_segment)

        full_context = "\n".join(context_parts)
        
        # å®‰å…¨æˆªæ–­ï¼šå¦‚æžœæ€»é•¿è¶…è¿‡ 25000 å­—ï¼ˆçº¦ 20k tokensï¼‰ï¼Œå¼ºè¡Œæˆªæ–­ï¼Œé˜²æ­¢ OOM
        # Qwen2.5 æ”¯æŒ 32kï¼Œç•™ 7k ç»™è¾“å‡ºå’Œ Prompt
        if len(full_context) > 250000:
            full_context = full_context[:250000] + "\n...(æˆªæ–­)..."

        logger.info(f"[Cleaner] Aggregating {len(contents_list)} sources (Total {len(full_context)} chars)...")

        prompt = PROMPT_BATCH_SUMMARY.format(
            count=len(contents_list),
            keyword=keyword,
            context_str=full_context
        )

        try:
            result = self.llm.generate([{"role": "user", "content": prompt}])
            if not result or "NULL" in result:
                return None
            return result
        except Exception as e:
            logger.error(f"[Cleaner] Batch LLM Error: {e}")
            return None

    # ä¿ç•™æ—§çš„å•æ¡æ¸…æ´—æ–¹æ³•ï¼Œä»¥å¤‡ä¸æ—¶ä¹‹éœ€
    def clean(self, raw_text, keyword):
        # ... (ä¿æŒåŽŸæ ·ï¼Œæˆ–è€…ç›´æŽ¥åˆ æŽ‰ä¹Ÿè¡Œ)
        pass


========================================
File Path: .\core\harvester\crawler.py
========================================

# core/harvester/crawler.py
import requests
import time
import random
import trafilatura
from duckduckgo_search import DDGS
from bs4 import BeautifulSoup # æˆ‘ä»¬éœ€è¦æŠŠ BS4 è¯·å›žæ¥ä¸“é—¨è§£æž Bing çš„æœç´¢ç»“æžœé¡µ
from core.utils.logger import logger
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class WebCrawler:
    def __init__(self):
        # =====================================================
        # [å¯é€‰] å¦‚æžœä½ æœ‰ä»£ç† (å¦‚ v2ray/clash)ï¼Œè¯·åœ¨è¿™é‡Œå¡«å…¥
        # ä¾‹å¦‚: proxies = {"http": "http://127.0.0.1:7890", "https": "http://127.0.0.1:7890"}
        # å¦‚æžœæ²¡æœ‰ä»£ç†ï¼Œä¿æŒä¸º None å³å¯ï¼Œä»£ç ä¼šè‡ªåŠ¨é™çº§åˆ° Bing
        # =====================================================
        self.proxies = None 
        
        try:
            self.ddgs = DDGS(proxy=self.proxies['http'] if self.proxies else None, timeout=10)
        except:
            self.ddgs = None

        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }

    def _fetch_via_jina(self, url):
        """ç­–ç•¥A: ä½¿ç”¨ Jina Reader (æŠ—åçˆ¬ + è½¬Markdown)"""
        jina_url = f"https://r.jina.ai/{url}"
        try:
            # Jina éœ€è¦è®¿é—®å¤–ç½‘ï¼Œå¦‚æžœæœ¬åœ°æœ‰ä»£ç†æœ€å¥½åŠ ä¸Šï¼Œæ²¡æœ‰ä¹Ÿèƒ½è·‘(JinaæœåŠ¡å™¨åœ¨æµ·å¤–)
            resp = requests.get(jina_url, headers=self.headers, timeout=30)
            if resp.status_code == 200:
                text = resp.text
                if len(text) > 200 and "Cloudflare" not in text:
                    return text
        except Exception as e:
            logger.debug(f"[Crawler] Jina fetch failed: {e}")
        return None

    def _fetch_via_local(self, url):
        """ç­–ç•¥B: æœ¬åœ° Requests + Trafilatura (æœ¬åœ°ç›´è¿ž)"""
        try:
            resp = requests.get(url, headers=self.headers, timeout=15, verify=False)
            if resp.status_code == 200:
                # è‡ªåŠ¨ä¿®æ­£ç¼–ç 
                if resp.encoding == 'ISO-8859-1':
                    resp.encoding = resp.apparent_encoding
                
                # æå–æ­£æ–‡
                text = trafilatura.extract(
                    resp.text, 
                    include_comments=False, 
                    include_tables=True, 
                    include_formatting=True, # ä¿ç•™ Markdown æ ¼å¼
                    no_fallback=True
                )
                return text
        except Exception as e:
            logger.debug(f"[Crawler] Local fetch failed: {e}")
        return None

    def _search_ddg(self, keyword, max_results):
        """å¼•æ“Ž 1: DuckDuckGo"""
        links = []
        if not self.ddgs: return []
        try:
            logger.info(f"[Crawler] ðŸ” Searching via DuckDuckGo...")
            results = self.ddgs.text(keyword, region='cn-zh', max_results=max_results+2)
            for r in results:
                links.append({'href': r['href'], 'title': r['title']})
        except Exception as e:
            logger.warning(f"[Crawler] DDG failed (Network Issue?): {e}")
        return links

    def _search_bing(self, keyword, max_results):
        """å¼•æ“Ž 2: Bing CN (å›½å†…ç›´è¿ž)"""
        links = []
        try:
            logger.info(f"[Crawler] ðŸ” Fallback to Bing CN...")
            url = f"https://cn.bing.com/search?q={keyword}"
            resp = requests.get(url, headers=self.headers, timeout=10, verify=False)
            
            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, 'html.parser')
                # è§£æž Bing çš„åˆ—è¡¨ç»“æž„
                items = soup.find_all('li', class_='b_algo')
                for item in items:
                    h2 = item.find('h2')
                    if h2:
                        a_tag = h2.find('a')
                        if a_tag and a_tag.get('href'):
                            links.append({
                                'href': a_tag['href'],
                                'title': a_tag.get_text()
                            })
                            if len(links) >= max_results + 2: break
        except Exception as e:
            logger.error(f"[Crawler] Bing search failed: {e}")
        return links

    def search_and_fetch(self, keyword, whitelist=[], blacklist=[], max_results=3):
        # 1. æœç´¢é˜¶æ®µ (åŒå¼•æ“Ž)
        search_links = self._search_ddg(keyword, max_results)
        
        # å¦‚æžœ DDG æŒ‚äº†ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° Bing
        if not search_links:
            search_links = self._search_bing(keyword, max_results)

        if not search_links:
            logger.warning("[Crawler] All search engines failed.")
            return []

        # 2. ç­›é€‰é˜¶æ®µ
        candidates = []
        for item in search_links:
            url = item['href']
            # ç®€å•çš„åŸŸåæå–
            try:
                domain = url.split('/')[2]
            except:
                domain = ""
            
            if any(black in domain for black in blacklist): continue
            
            score = 50
            if any(white in domain for white in whitelist): score = 100
            
            candidates.append((score, item))
        
        candidates.sort(key=lambda x: x[0], reverse=True)
        targets = candidates[:max_results]
        
        logger.info(f"[Crawler] ðŸŽ¯ Targets: {[t[1]['title'][:10] for t in targets]}")
        
        results = []

        # 3. æŠ“å–é˜¶æ®µ (æ··åˆç­–ç•¥)
        for _, item in targets:
            url = item['href']
            title = item['title']
            domain = url.split('/')[2] if '//' in url else url
            
            time.sleep(random.uniform(1, 3))
            
            # ä¼˜å…ˆ Jina (äº‘ç«¯)
            content = self._fetch_via_jina(url)
            source_type = "Jina-Reader"
            
            # å¤±è´¥åˆ™æœ¬åœ° Trafilatura
            if not content:
                content = self._fetch_via_local(url)
                source_type = "Local-Trafilatura"

            if content and len(content) > 50: # æ”¾å®½é™åˆ¶ï¼Œæœ‰äº›çŸ­è®¾å®šä¹Ÿå¾ˆæœ‰ç”¨
                logger.info(f"[Crawler] âœ… Fetched [{source_type}]: {title[:15]}... ({len(content)} chars)")
                results.append({
                    "title": title,
                    "url": url,
                    "content": content,
                    "domain": domain
                })
            else:
                logger.warning(f"[Crawler] âŒ Content empty: {url}")

        return results


========================================
File Path: .\core\harvester\scheduler.py
========================================

# core/harvester/scheduler.py
import threading
import queue
import time
from core.harvester.crawler import WebCrawler
from core.harvester.cleaner import LocalCleaner
from core.database.vector_store import VectorStore
from core.utils.logger import logger

class KnowledgeHarvester(threading.Thread):
    def __init__(self):
        super().__init__()
        self.name = "HarvesterThread"
        self.daemon = True
        self.queue = queue.PriorityQueue()
        self.running = True
        
        self.crawler = WebCrawler()
        self.cleaner = LocalCleaner()
        self.vec = VectorStore(collection_name="long_term_memory")

        # ç™½åå•/é»‘åå•ä¿æŒä¸å˜...
        self.whitelist = ["wikipedia.org", "baike.baidu.com", "zhihu.com", "gamersky.com", "ali213.net"]
        self.blacklist = ["csdn.net", "baidu.com/link", "weibo.com", "bilibili.com"]

    def add_task(self, keyword, priority=10):
        if keyword:
            logger.info(f"[Harvester] ðŸ“¥ Added task: {keyword}")
            self.queue.put((priority, time.time(), keyword))

    def run(self):
        logger.info("[Harvester] Service Started (Batch Aggregation Mode).")
        while self.running:
            try:
                priority, _, keyword = self.queue.get(timeout=5)
                self._process_task_batch(keyword) # æ”¹ç”¨ Batch æ–¹æ³•
                self.queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"[Harvester] Loop Error: {e}")
                time.sleep(5)

    def _process_task_batch(self, keyword):
        # 1. çˆ¬å–å¤šæ¡ (æ¯”å¦‚ä¸€æ¬¡æŠ“ 4 ä¸ªç½‘é¡µ)
        raw_results = self.crawler.search_and_fetch(
            keyword, 
            whitelist=self.whitelist, 
            blacklist=self.blacklist,
            max_results=6  # å¢žåŠ æ•°é‡ï¼Œå–‚é¥± LLM
        )
        
        if not raw_results:
            return

        # 2. å‡†å¤‡æ•°æ®
        contents_to_merge = []
        for res in raw_results:
            # ç®€å•è¿‡æ»¤å¤ªçŸ­çš„åžƒåœ¾
            if len(res['content']) > 200:
                contents_to_merge.append({
                    'source': res['domain'],
                    'text': res['content']
                })

        if not contents_to_merge:
            logger.warning("[Harvester] No valid content to merge.")
            return

        # 3. èšåˆæ¸…æ´— (One Pass)
        logger.info(f"[Harvester] ðŸ§  Synthesizing {len(contents_to_merge)} pages for '{keyword}'...")
        final_summary = self.cleaner.clean_batch(contents_to_merge, keyword)

        if final_summary:
            # 4. å­˜å…¥å‘é‡åº“ (åªå­˜è¿™ä¸€æ¡é«˜è´¨é‡çš„)
            mem_id = f"lore_{int(time.time())}_{hash(keyword) % 10000}"
            
            # æž„é€ å…ƒæ•°æ®ï¼Œè®°å½•æ‰€æœ‰æ¥æº
            sources_str = ", ".join([c['source'] for c in contents_to_merge])
            
            self.vec.add_memory(
                text=final_summary, 
                metadata={
                    "type": "INTERNET_LORE", 
                    "keyword": keyword,
                    "sources": sources_str,
                    "timestamp": str(int(time.time())),
                    "quality": "high_batch" # æ ‡è®°ä¸ºé«˜è´¨é‡èšåˆ
                }, 
                memory_id=mem_id
            )
            logger.info(f"[Harvester] âœ… Saved Deep Lore for '{keyword}' (Length: {len(final_summary)})")
        else:
            logger.warning("[Harvester] Batch summary failed.")


========================================
File Path: .\core\llm\api_client.py
========================================

# core/llm/api_client.py
import requests
import json
import time
from typing import List, Dict, Generator
from core.llm.base import BaseLLM
from core.utils.logger import logger
from config.settings import CONFIG_JSON_PATH

class APILLM(BaseLLM):
    """é€šç”¨çš„ API LLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒè‡ªåŠ¨å¤‡é€‰ (Fallback) æœºåˆ¶"""
    
    def __init__(self, role_config: dict):
        self.role_config = role_config # ä¿å­˜å®Œæ•´é…ç½®ä»¥ä¾¿è¯»å– fallback ä¿¡æ¯
        self.model_name = role_config["model"]
        self.api_key = role_config["api_key"]
        self.base_url = role_config["base_url"]
        self.default_temp = role_config.get("temperature", 0.7)
        self.max_tokens = role_config.get("max_tokens", 8192)
        
        # åŠ è½½å…¨å±€é…ç½®ï¼Œä»¥ä¾¿æŸ¥æ‰¾ fallback provider çš„å…·ä½“ URL/Key
        self.global_providers = {}
        try:
            with open(CONFIG_JSON_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                self.global_providers = data.get("providers", {})
        except:
            pass

    def _get_endpoint(self, base_url):
        base = base_url.rstrip('/')
        return f"{base}/chat/completions"

    def _try_request(self, model, api_key, base_url, messages, temperature, stream=False):
        """æ‰§è¡Œå•æ¬¡è¯·æ±‚é€»è¾‘"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": self.max_tokens,
            "stream": stream
        }
        
        endpoint = self._get_endpoint(base_url)
        
        if stream:
            return requests.post(endpoint, json=payload, headers=headers, stream=True, timeout=300)
        else:
            return requests.post(endpoint, json=payload, headers=headers, timeout=300)

    def generate(self, messages: List[Dict[str, str]], temperature: float = None) -> str:
        """åŒæ­¥ç”Ÿæˆ (å¸¦ Fallback æœºåˆ¶)"""
        temp = temperature if temperature is not None else self.default_temp
        
        # 1. å°è¯•ä¸»æ¨¡åž‹
        result = self._generate_with_retry(
            self.model_name, self.api_key, self.base_url, messages, temp, "Primary"
        )
        if result: return result

        # 2. å°è¯•å¤‡é€‰æ¨¡åž‹ (Fallback)
        fallback_provider_key = self.role_config.get("fallback_provider")
        fallback_model = self.role_config.get("fallback_model")
        
        if fallback_provider_key and fallback_model and fallback_provider_key in self.global_providers:
            fb_config = self.global_providers[fallback_provider_key]
            logger.warning(f"[{self.model_name}] ä¸»çº¿è·¯å¤±è´¥ï¼Œåˆ‡æ¢å¤‡é€‰çº¿è·¯: {fb_config.get('name')} ({fallback_model})")
            
            result = self._generate_with_retry(
                fallback_model, fb_config["api_key"], fb_config["base_url"], messages, temp, "Fallback"
            )
            if result: return result

        return "Error: All providers failed."

    def _generate_with_retry(self, model, key, url, messages, temp, tag):
        """å†…éƒ¨é‡è¯•é€»è¾‘"""
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = self._try_request(model, key, url, messages, temp, stream=False)
                if response.status_code == 200:
                    return response.json()['choices'][0]['message']['content']
                elif response.status_code in [500, 502, 503, 504, 429]:
                    logger.warning(f"[{tag}:{model}] API ç¹å¿™ ({response.status_code})ï¼Œé‡è¯• {attempt+1}/{max_retries}...")
                    time.sleep(2)
                else:
                    logger.error(f"[{tag}:{model}] API é”™è¯¯: {response.text}")
                    break # 4xx é”™è¯¯é€šå¸¸é‡è¯•æ— æ•ˆ
            except Exception as e:
                logger.error(f"[{tag}:{model}] è¿žæŽ¥å¼‚å¸¸: {e}")
                time.sleep(1)
        return None

    def generate_stream(self, messages: List[Dict[str, str]], temperature: float = None) -> Generator[str, None, None]:
        """æµå¼ç”Ÿæˆ (æš‚ä¸æ”¯æŒ Fallback åˆ‡æ¢ï¼Œå› ä¸ºæµå¼é€šå¸¸ç”¨äºŽ Narratorï¼Œè€Œ Narrator æ˜¯æœ¬åœ°æ¨¡åž‹)"""
        temp = temperature if temperature is not None else self.default_temp
        
        try:
            response = self._try_request(self.model_name, self.api_key, self.base_url, messages, temp, stream=True)
            response.raise_for_status()
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith("data: "):
                        if line == "data: [DONE]": break
                        try:
                            json_str = line[6:]
                            data = json.loads(json_str)
                            content = data['choices'][0]['delta'].get('content', '')
                            if content: yield content
                        except: pass
        except Exception as e:
            logger.error(f"[{self.model_name}] æµå¼å¤±è´¥: {e}")
            yield f"[System Error: {e}]"


========================================
File Path: .\core\llm\base.py
========================================

# core/llm/base.py
from abc import ABC, abstractmethod
from typing import Generator, List, Dict

class BaseLLM(ABC):
    """æ‰€æœ‰ LLM æ¨¡åž‹çš„åŸºç±»"""
    
    def __init__(self, model_name: str, **kwargs):
        self.model_name = model_name
        self.config = kwargs

    @abstractmethod
    def generate(self, messages: List[Dict[str, str]]) -> str:
        """
        åŒæ­¥ç”Ÿæˆæ–‡æœ¬ï¼ˆç”¨äºŽåŽå°ä»»åŠ¡ï¼Œå¦‚æ€»ç»“ã€çŠ¶æ€åˆ†æžï¼‰
        :param messages: [{"role": "user", "content": "..."}]
        :return: å®Œæ•´çš„å›žå¤å­—ç¬¦ä¸²
        """
        pass

    @abstractmethod
    def generate_stream(self, messages: List[Dict[str, str]]) -> Generator[str, None, None]:
        """
        æµå¼ç”Ÿæˆæ–‡æœ¬ï¼ˆç”¨äºŽä¸»å™äº‹ï¼Œå‰ç«¯å®žæ—¶æ˜¾ç¤ºï¼‰
        :return: ç”Ÿæˆå™¨ï¼Œé€å­—è¿”å›ž
        """
        pass


========================================
File Path: .\core\llm\local_direct.py
========================================

# core/llm/local_direct.py
from core.llm.base import BaseLLM
from core.utils.logger import logger
import os
import threading

try:
    from llama_cpp import Llama
except ImportError:
    Llama = None

class LocalDirectLLM(BaseLLM):
    # === ç±»å˜é‡ï¼šç”¨äºŽå­˜å‚¨å·²åŠ è½½çš„æ¨¡åž‹å®žä¾‹ ===
    _loaded_instances = {} 
    _instance_lock = threading.Lock() # è¿™é‡Œçš„é”ç”¨äºŽä¿æŠ¤åŠ è½½è¿‡ç¨‹
    _generate_lock = threading.Lock() # è¿™é‡Œçš„é”ç”¨äºŽä¿æŠ¤æŽ¨ç†è¿‡ç¨‹ï¼ˆé˜²æ­¢å¤šçº¿ç¨‹åŒæ—¶è°ƒç”¨åŒä¸€ä¸ªæ¨¡åž‹ï¼‰

    def __init__(self, config):
        if Llama is None:
            raise ImportError("Please install llama-cpp-python to use local GGUF models!")
            
        self.model_path = config.get("model")
        # ä¿®å¤ model_name æŠ¥é”™
        self.model_name = os.path.basename(self.model_path) if self.model_path else "Local-GGUF"
        
        self.context_window = config.get("n_ctx", 4096)
        # å¦‚æžœæ˜¯ CPU æŽ¨ç†ï¼Œå»ºè®®è®¾ä¸º 0 æˆ– -1ï¼›å¦‚æžœæ˜¯ GPUï¼Œè®¾ä¸º -1
        self.n_gpu_layers = config.get("n_gpu_layers", -1) 

        # === æ ¸å¿ƒä¿®æ”¹ï¼šå•ä¾‹æ¨¡å¼åŠ è½½ ===
        with LocalDirectLLM._instance_lock:
            if self.model_path in LocalDirectLLM._loaded_instances:
                logger.info(f"[Local] Reusing loaded model instance: {self.model_name}")
                self.llm = LocalDirectLLM._loaded_instances[self.model_path]
            else:
                logger.info(f"[Local] Loading NEW model instance: {self.model_path}")
                try:
                    # ç¬¬ä¸€æ¬¡åŠ è½½
                    self.llm = Llama(
                        model_path=self.model_path,
                        n_ctx=self.context_window,
                        n_gpu_layers=self.n_gpu_layers,
                        verbose=False # å…³é—­åº•å±‚å•°å—¦çš„æ—¥å¿—
                    )
                    LocalDirectLLM._loaded_instances[self.model_path] = self.llm
                except Exception as e:
                    logger.error(f"[Local] Init failed: {e}")
                    self.llm = None

    def generate(self, messages, temperature=0.7):
        if not self.llm: return "Error: Model not loaded."
        
        # === æ ¸å¿ƒä¿®æ”¹ï¼šæŽ¨ç†åŠ é” ===
        # æœ¬åœ° GGUF æ¨¡åž‹é€šå¸¸ä¸æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘æŽ¨ç†ï¼Œå¿…é¡»æŽ’é˜Ÿ
        with LocalDirectLLM._generate_lock:
            try:
                response = self.llm.create_chat_completion(
                    messages=messages,
                    temperature=temperature,
                    max_tokens=2048
                )
                return response['choices'][0]['message']['content']
            except Exception as e:
                logger.error(f"[Local] Generate error: {e}")
                return f"Error: {str(e)}"

    def generate_stream(self, messages, temperature=0.7):
        if not self.llm: 
            yield "Error: Model not loaded."
            return

        # === æ ¸å¿ƒä¿®æ”¹ï¼šæŽ¨ç†åŠ é” ===
        with LocalDirectLLM._generate_lock:
            try:
                stream = self.llm.create_chat_completion(
                    messages=messages,
                    temperature=temperature,
                    max_tokens=2048,
                    stream=True
                )
                for chunk in stream:
                    delta = chunk['choices'][0]['delta']
                    if 'content' in delta:
                        yield delta['content']
            except Exception as e:
                logger.error(f"[Local] Stream error: {e}")
                yield f"Error: {str(e)}"


========================================
File Path: .\core\llm\__init__.py
========================================



========================================
File Path: .\core\utils\config_loader.py
========================================

# core/utils/config_loader.py
import json
import os
from core.utils.logger import logger

CONFIG_PATH = "config.json"

class ConfigLoader:
    _instance = None
    _config = {}
    
    # ä»ªè¡¨ç›˜æ‰€éœ€çš„ç¼“å­˜æ•°æ®
    _models = {}
    _prompts = {}
    _global = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigLoader, cls).__new__(cls)
            cls._instance.load()
        return cls._instance

    @classmethod
    def load(cls):
        if not os.path.exists(CONFIG_PATH):
            logger.error("æ‰¾ä¸åˆ° config.jsonï¼è¯·å…ˆè¿è¡Œ config_editor.py ç”Ÿæˆé…ç½®ã€‚")
            cls._config = {}
            return
            
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                cls._config = json.load(f)
            logger.info("é…ç½®å·²åŠ è½½")
            cls._parse_for_dashboard()
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶è§£æžå¤±è´¥: {e}")
            cls._config = {}

    @classmethod
    def _parse_for_dashboard(cls):
        """å°†åŽŸå§‹ config.json ç»“æž„è§£æžä¸º Dashboard æ˜“è¯»çš„æ ¼å¼"""
        cls._models = {}
        cls._prompts = {}
        cls._global = {}

        # 1. è§£æž Global (Vector)
        vec = cls._config.get("vector", {})
        provs = cls._config.get("providers", {})
        vec_prov_key = vec.get("provider", "silicon")
        vec_prov_data = provs.get(vec_prov_key, {})
        
        cls._global = {
            "embedding_model": vec.get("embedding_model", ""),
            "rerank_model": vec.get("rerank_model", ""),
            "vector_api_key": vec_prov_data.get("api_key", ""),
            "vector_base_url": vec_prov_data.get("base_url", "")
        }

        # 2. è§£æž Models & Prompts
        roles = cls._config.get("roles", [])
        for role in roles:
            key = role.get("key")
            if not key: continue
            
            prov_key = role.get("provider", "silicon")
            prov_data = provs.get(prov_key, {})
            
            # Model Data
            cls._models[key] = {
                "name": role.get("name", key),
                "provider": prov_key,
                "model": role.get("model", ""),
                "api_key": prov_data.get("api_key", ""),
                "base_url": prov_data.get("base_url", ""),
                "temperature": role.get("temperature", 0.7)
            }
            
            # Prompt Data
            cls._prompts[key] = {
                "description": f"{role.get('name', key)} çš„ç³»ç»Ÿæç¤ºè¯",
                "content": role.get("prompt", "")
            }

    @classmethod
    def load_configs(cls):
        """Dashboard è°ƒç”¨çš„åˆ«å"""
        cls.load()

    @classmethod
    def save_models(cls, models_data):
        """ä»Ž Dashboard ä¿å­˜æ¨¡åž‹é…ç½®å›ž config.json"""
        cls._models = models_data
        cls._sync_to_config()

    @classmethod
    def save_prompts(cls, prompts_data):
        """ä»Ž Dashboard ä¿å­˜æç¤ºè¯å›ž config.json"""
        cls._prompts = prompts_data
        cls._sync_to_config()

    @classmethod
    def save_global(cls, global_data):
        """ä»Ž Dashboard ä¿å­˜å…¨å±€é…ç½®å›ž config.json"""
        cls._global = global_data
        # æ›´æ–° vector éƒ¨åˆ†
        if "vector" not in cls._config: cls._config["vector"] = {}
        cls._config["vector"]["embedding_model"] = global_data.get("embedding_model")
        cls._config["vector"]["rerank_model"] = global_data.get("rerank_model")
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸åå‘æ›´æ–° provider çš„ keyï¼Œå› ä¸º provider ç»“æž„æ¯”è¾ƒå¤æ‚
        cls._save_file()

    @classmethod
    def _sync_to_config(cls):
        """å°† _models å’Œ _prompts åŒæ­¥å›ž cls._config['roles']"""
        new_roles = []
        
        # éåŽ†çŽ°æœ‰çš„ models
        for key, m_data in cls._models.items():
            p_data = cls._prompts.get(key, {})
            
            role_entry = {
                "key": key,
                "name": m_data.get("name"),
                "provider": m_data.get("provider"),
                "model": m_data.get("model"),
                "temperature": m_data.get("temperature"),
                "max_tokens": 8192, # é»˜è®¤å€¼
                "prompt": p_data.get("content", "")
            }
            new_roles.append(role_entry)
            
            # åŒæ—¶å°è¯•æ›´æ–° providers (å¦‚æžœ API Key å˜äº†)
            prov_key = m_data.get("provider")
            if prov_key and "providers" in cls._config:
                if prov_key not in cls._config["providers"]:
                    cls._config["providers"][prov_key] = {}
                
                # ä»…å½“ dashboard æä¾›äº†éžç©ºå€¼æ—¶æ›´æ–°
                if m_data.get("api_key"):
                    cls._config["providers"][prov_key]["api_key"] = m_data.get("api_key")
                if m_data.get("base_url"):
                    cls._config["providers"][prov_key]["base_url"] = m_data.get("base_url")

        cls._config["roles"] = new_roles
        cls._save_file()

    @classmethod
    def _save_file(cls):
        try:
            with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
                json.dump(cls._config, f, indent=4, ensure_ascii=False)
            logger.info("é…ç½®å·²ä¿å­˜è‡³ config.json")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")

    def get_provider_config(self, provider_key):
        return self._config.get("providers", {}).get(provider_key, {})

    def get_vector_config(self):
        return self._config.get("vector", {})

    def get_role_config(self, role_key):
        """æ ¹æ® key (å¦‚ 'narrator') èŽ·å–å®Œæ•´çš„æ¨¡åž‹é…ç½®å’Œ prompt"""
        roles = self._config.get("roles", [])
        for role in roles:
            if role["key"] == role_key:
                # ç»„åˆæ•°æ®ï¼šæŠŠ provider çš„ url/key æ‹¼è¿›åŽ»
                provider_key = role.get("provider", "silicon")
                provider_info = self.get_provider_config(provider_key)
                
                return {
                    "model": role["model"],
                    "temperature": role.get("temperature", 0.7),
                    "prompt": role.get("prompt", ""),
                    "api_key": provider_info.get("api_key"),
                    "base_url": provider_info.get("base_url")
                }
        logger.warning(f"æœªæ‰¾åˆ°è§’è‰²é…ç½®: {role_key}")
        return {}


========================================
File Path: .\core\utils\logger.py
========================================

# core/utils/logger.py
import logging
import os
from datetime import datetime
import colorlog

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
LOG_DIR = "logs"
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)

def setup_logger(name="DeepTavern"):
    """é…ç½®å…¨å±€æ—¥å¿—"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)

    # é¿å…é‡å¤æ·»åŠ  Handler
    if logger.handlers:
        return logger

    # 1. æ–‡ä»¶å¤„ç†å™¨ (è®°å½•æ‰€æœ‰ç»†èŠ‚)
    log_filename = datetime.now().strftime("%Y-%m-%d_run.log")
    file_handler = logging.FileHandler(os.path.join(LOG_DIR, log_filename), encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_format = logging.Formatter('%(asctime)s - [%(levelname)s] - %(name)s - %(message)s')
    file_handler.setFormatter(file_format)

    # 2. æŽ§åˆ¶å°å¤„ç†å™¨ (å¸¦é¢œè‰²ï¼Œåªçœ‹é‡è¦ä¿¡æ¯)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    color_formatter = colorlog.ColoredFormatter(
        '%(log_color)s%(asctime)s - [%(levelname)s] - %(message)s',
        datefmt='%H:%M:%S',
        log_colors={
            'DEBUG': 'cyan',
            'INFO': 'green',
            'WARNING': 'yellow',
            'ERROR': 'red',
            'CRITICAL': 'bold_red',
        }
    )
    console_handler.setFormatter(color_formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# åˆå§‹åŒ–ä¸€ä¸ªå…¨å±€å®žä¾‹
logger = setup_logger()


========================================
File Path: .\core\utils\__init__.py
========================================



========================================
File Path: .\core\workflow\backend_manager.py
========================================

# core/workflow/backend_manager.py
"""
DeepTavern åŽå°ä»»åŠ¡ç®¡ç†å™¨ v4.5
- é€‚é…æ‰©å±•çŠ¶æ€ç³»ç»Ÿ
- çŠ¶æ€å¼•æ“Žè§£æžæ›´ä¸°å¯Œçš„çŠ¶æ€å˜æ›´
"""

import json
import threading
import re
import time
import uuid
from typing import Dict, Any, Optional

from core.llm.api_client import APILLM
from core.llm.local_direct import LocalDirectLLM
from core.database.sqlite_manager import SQLiteManager
from core.database.vector_store import VectorStore
from core.database.graph_manager import GraphManager
from core.harvester.scheduler import KnowledgeHarvester
from core.workflow.prompts import get_prompt, PROMPT_GRAPH_EXTRACTOR
from config.settings import MODEL_CONFIG
from core.utils.logger import logger


class BackendManager:
    """
    åŽå°ä»»åŠ¡ç®¡ç†å™¨
    è´Ÿè´£ï¼šçŠ¶æ€æ›´æ–°ã€è®°å¿†åŽ‹ç¼©ã€å›¾è°±æå–ã€çŸ¥è¯†çˆ¬å–
    """

    def __init__(self):
        logger.info("âš™ï¸ [åŽå°] åˆå§‹åŒ–åŽå°å·¥ä½œæµç®¡ç†å™¨...")
        
        self.db = SQLiteManager()
        self.vec = VectorStore()
        self.graph = GraphManager()

        # åŠ è½½å„ä¸ªåŽå° LLM
        def load_llm(role_key):
            conf = MODEL_CONFIG.get(role_key, {})
            if not conf:
                return APILLM({"model": "mock", "api_key": "none", "base_url": ""})
            model_path = str(conf.get("model", "")).lower()
            if model_path.endswith(".gguf"):
                return LocalDirectLLM(config=conf)
            else:
                return APILLM(conf)

        self.status_bot = load_llm("status")
        self.left_brain = load_llm("left_brain")
        self.right_brain = load_llm("critic")
        self.historian = load_llm("historian")
        self.sociologist = load_llm("sociologist")
        self.graph_extractor = load_llm("sociologist")  # å¤ç”¨

        # çŸ¥è¯†çˆ¬è™«
        self.harvester = KnowledgeHarvester()
        self.harvester.start()

        logger.info("âœ… [åŽå°] åŽå°æœåŠ¡å°±ç»ª")

    def _clean_json(self, text: str) -> Optional[Dict]:
        """ä»Ž LLM è¾“å‡ºä¸­æå– JSON"""
        if not text:
            return None
        
        try:
            # å°è¯•ç›´æŽ¥è§£æž
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # å°è¯•æå– markdown ä»£ç å—
        match = re.search(r"```(?:json)?\s*([\s\S]*?)```", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1).strip())
            except json.JSONDecodeError:
                pass
        
        # å°è¯•æå–è£¸ JSON
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass
        
        return None

    def _deep_merge_state(self, base: Dict, update: Dict) -> Dict:
        """
        æ·±åº¦åˆå¹¶çŠ¶æ€
        update ä¸­çš„å­—æ®µä¼šè¦†ç›–/æ›´æ–° base ä¸­çš„å¯¹åº”å­—æ®µ
        """
        result = json.loads(json.dumps(base))  # æ·±æ‹·è´
        
        for key, value in update.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                # é€’å½’åˆå¹¶å­—å…¸
                result[key] = self._deep_merge_state(result[key], value)
            elif key in result and isinstance(result[key], list) and isinstance(value, list):
                # åˆ—è¡¨ç›´æŽ¥æ›¿æ¢ï¼ˆæˆ–è€…å¯ä»¥é€‰æ‹©åˆå¹¶ï¼‰
                result[key] = value
            else:
                result[key] = value
        
        return result

    # ==========================================
    # çŠ¶æ€æ›´æ–°ä»»åŠ¡
    # ==========================================

    def _task_status_update(self, user_input: str, narr_output: str) -> str:
        """
        çŠ¶æ€æ›´æ–°ä»»åŠ¡
        è§£æžå¯¹è¯ï¼Œæ›´æ–°å®Œæ•´çš„æ¸¸æˆçŠ¶æ€
        """
        current_state = self.db.get_current_state()
        
        # ç¡®ä¿çŠ¶æ€ç»“æž„å®Œæ•´
        current_state = self._ensure_state_structure(current_state)
        
        prompt = get_prompt("status").format(
            current_state=json.dumps(current_state, ensure_ascii=False, indent=2),
            user_input=user_input,
            narrator_output=narr_output
        )
        
        logger.info("â³ [åŽå°] Status æ¨¡åž‹æ­£åœ¨åˆ†æžçŠ¶æ€å˜åŒ–...")
        
        try:
            raw = self.status_bot.generate([{"role": "user", "content": prompt}])
            data = self._clean_json(raw)
            
            if not data:
                logger.warning("âš ï¸ [çŠ¶æ€æ›´æ–°] JSON è§£æžå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´æŽ¨è¿›")
                # é»˜è®¤æŽ¨è¿› 10 åˆ†é’Ÿ
                return self._advance_time_default(current_state)
            
            timeline_tag = data.get("timeline_tag", "Unknown")
            state_update = data.get("state", {})
            
            if state_update:
                # æ·±åº¦åˆå¹¶çŠ¶æ€
                new_state = self._deep_merge_state(current_state, state_update)
                
                # åŒæ­¥ world_time å’Œ timeline_tag
                if "world_time" in state_update:
                    wt = state_update["world_time"]
                    if isinstance(wt, dict):
                        timeline_tag = f"Day {wt.get('day', 1)}, {wt.get('hour', 8):02d}:{wt.get('minute', 0):02d}"
                
                # ä¿å­˜çŠ¶æ€
                self.db.save_state(new_state, diff_summary=f"Time: {timeline_tag}")
                
                # æ—¥å¿—è®°å½•é‡è¦å˜åŒ–
                self._log_state_changes(current_state, new_state)
                
                logger.info(f"ðŸ•’ [çŠ¶æ€æ›´æ–°] æ—¶é—´æŽ¨è¿›è‡³: {timeline_tag}")
            else:
                timeline_tag = self._advance_time_default(current_state)
            
            return timeline_tag
            
        except Exception as e:
            logger.error(f"âŒ [çŠ¶æ€æ›´æ–°] é”™è¯¯: {e}")
            return self._advance_time_default(current_state)

    def _advance_time_default(self, current_state: Dict) -> str:
        """é»˜è®¤æ—¶é—´æŽ¨è¿›ï¼ˆ10åˆ†é’Ÿï¼‰"""
        world_time = current_state.get("world_time", {})
        
        if isinstance(world_time, dict):
            day = world_time.get("day", 1)
            hour = world_time.get("hour", 8)
            minute = world_time.get("minute", 0)
            
            minute += 10
            if minute >= 60:
                minute -= 60
                hour += 1
            if hour >= 24:
                hour -= 24
                day += 1
            
            world_time["day"] = day
            world_time["hour"] = hour
            world_time["minute"] = minute
            
            current_state["world_time"] = world_time
            
            # æ›´æ–° time_of_day
            if "scene" in current_state:
                current_state["scene"]["time_of_day"] = self._get_time_of_day(hour)
            
            self.db.save_state(current_state, diff_summary="Auto time advance")
            
            return f"Day {day}, {hour:02d}:{minute:02d}"
        else:
            return "Day 1, 08:00"

    def _get_time_of_day(self, hour: int) -> str:
        """æ ¹æ®å°æ—¶åˆ¤æ–­æ—¶æ®µ"""
        if 5 <= hour < 7:
            return "dawn"
        elif 7 <= hour < 12:
            return "morning"
        elif 12 <= hour < 17:
            return "afternoon"
        elif 17 <= hour < 20:
            return "evening"
        else:
            return "night"

    def _log_state_changes(self, old_state: Dict, new_state: Dict):
        """è®°å½•é‡è¦çš„çŠ¶æ€å˜åŒ–"""
        changes = []
        
        # HP å˜åŒ–
        old_hp = old_state.get("player", {}).get("hp", 100)
        new_hp = new_state.get("player", {}).get("hp", 100)
        if old_hp != new_hp:
            diff = new_hp - old_hp
            changes.append(f"HP: {old_hp} â†’ {new_hp} ({'+' if diff > 0 else ''}{diff})")
        
        # å…³ç³»å˜åŒ–
        old_rels = old_state.get("relationships", {})
        new_rels = new_state.get("relationships", {})
        for name in new_rels:
            if name not in old_rels:
                changes.append(f"æ–°å…³ç³»: {name}")
            elif new_rels[name] != old_rels.get(name):
                changes.append(f"å…³ç³»æ›´æ–°: {name}")
        
        # ç‰©å“å˜åŒ–
        old_inv = old_state.get("inventory", {})
        new_inv = new_state.get("inventory", {})
        for item in new_inv:
            if item not in old_inv:
                changes.append(f"èŽ·å¾—ç‰©å“: {item}")
        for item in old_inv:
            if item not in new_inv:
                changes.append(f"å¤±åŽ»ç‰©å“: {item}")
        
        # æŠ€èƒ½å˜åŒ–
        old_skills = old_state.get("skills", {})
        new_skills = new_state.get("skills", {})
        for skill in new_skills:
            if skill not in old_skills:
                changes.append(f"ä¹ å¾—æŠ€èƒ½: {skill}")
            elif isinstance(new_skills[skill], dict) and isinstance(old_skills.get(skill), dict):
                old_lvl = old_skills[skill].get("level", 1)
                new_lvl = new_skills[skill].get("level", 1)
                if new_lvl > old_lvl:
                    changes.append(f"æŠ€èƒ½å‡çº§: {skill} Lv.{old_lvl} â†’ Lv.{new_lvl}")
        
        # æ°›å›´å˜åŒ–
        old_atm = old_state.get("scene", {}).get("atmosphere", "")
        new_atm = new_state.get("scene", {}).get("atmosphere", "")
        if old_atm != new_atm and new_atm:
            changes.append(f"æ°›å›´å˜åŒ–: {old_atm} â†’ {new_atm}")
        
        if changes:
            logger.info(f"ðŸ“Š [çŠ¶æ€å˜åŒ–] {' | '.join(changes)}")

    def _ensure_state_structure(self, state: Dict) -> Dict:
        """ç¡®ä¿çŠ¶æ€ç»“æž„å®Œæ•´"""
        default_state = {
            "player": {
                "name": "Player",
                "hp": 100,
                "max_hp": 100,
                "mp": 50,
                "max_mp": 50,
                "status_effects": []
            },
            "skills": {},
            "inventory": {},
            "relationships": {},
            "scene": {
                "location": "æœªçŸ¥åœ°ç‚¹",
                "sub_location": "",
                "atmosphere": "æ—¥å¸¸",
                "weather": "æ™´æœ—",
                "time_of_day": "morning",
                "npcs_present": []
            },
            "world_time": {
                "day": 1,
                "hour": 8,
                "minute": 0
            },
            "narrator_persona": {
                "current_mood": "å¹³é™",
                "speech_style": "æ­£å¸¸"
            }
        }
        
        # åˆå¹¶ç¼ºå¤±çš„å­—æ®µ
        for key, value in default_state.items():
            if key not in state:
                state[key] = value
            elif isinstance(value, dict) and isinstance(state.get(key), dict):
                for sub_key, sub_value in value.items():
                    if sub_key not in state[key]:
                        state[key][sub_key] = sub_value
        
        # å…¼å®¹æ—§æ ¼å¼
        if "hp" in state and "player" not in state:
            state["player"] = {"hp": state.pop("hp"), "max_hp": 100}
        if "location" in state and "scene" not in state:
            state["scene"] = {"location": state.pop("location")}
        if isinstance(state.get("inventory"), list):
            old_inv = state["inventory"]
            state["inventory"] = {item: {"type": "item", "count": 1} for item in old_inv}
        if isinstance(state.get("world_time"), str):
            state["world_time"] = {"day": 1, "hour": 8, "minute": 0}
        
        return state

    # ==========================================
    # è®°å¿†åŽ‹ç¼©ä»»åŠ¡
    # ==========================================

    def _task_recursive_summary(self, timeline_tag: str, session_id: str):
        """é€’å½’æ‘˜è¦ä»»åŠ¡"""
        msgs = self.db.get_unsummarized_messages(limit=5)
        if len(msgs) < 5:
            return

        logger.info(f"ðŸ“ [åŽå°] è§¦å‘é€’å½’æ€»ç»“ (å¤„ç† 5 æ¡æ¶ˆæ¯)...")
        raw_text = "\n".join([f"{m['role']}: {m['content']}" for m in msgs])

        # ä¸–ç•Œè§‚æ‹“å±•æ£€æµ‹
        try:
            expansion_prompt = (
                f"Analyze the following dialogue:\n{raw_text[:2000]}\n\n"
                "Identify ONE specific proper noun, event, or concept that needs external knowledge. "
                "Return ONLY the keyword. If nothing needs research, return 'NONE'."
            )
            
            keyword_raw = self.left_brain.generate([{"role": "user", "content": expansion_prompt}])
            keyword = keyword_raw.strip().replace('"', '').replace("'", "").split('\n')[0]
            
            if keyword and "NONE" not in keyword.upper() and len(keyword) < 30:
                logger.info(f"ðŸŒ [ä¸–ç•Œè§‚æ‹“å±•] è§¦å‘çˆ¬è™«: '{keyword}'")
                self.harvester.add_task(keyword, priority=5)
                
        except Exception as e:
            logger.error(f"âŒ [ä¸–ç•Œè§‚æ‹“å±•] å¤±è´¥: {e}")

        # å·¦è„‘åŽ‹ç¼©
        left_prompt = get_prompt("left_brain").format(text=raw_text, time=timeline_tag)
        draft = self.left_brain.generate([{"role": "user", "content": left_prompt}])

        # å³è„‘å®¡æ ¸
        right_prompt = get_prompt("critic").format(draft=draft, original=raw_text)
        final_micro = self.right_brain.generate([{"role": "user", "content": right_prompt}])

        # ä¿å­˜å¾®è§‚è®°å¿†
        self.db.add_memory_node(final_micro, "MICRO", timeline_tag)
        self.db.mark_messages_summarized([m['id'] for m in msgs])

        # å‘é‡åŒ–
        vec_id = f"micro_{int(time.time())}_{uuid.uuid4().hex[:4]}"
        self.vec.add_memory(
            text=final_micro,
            metadata={
                "type": "episodic",
                "level": "MICRO",
                "timeline": timeline_tag,
                "session_id": session_id
            },
            memory_id=vec_id
        )
        logger.info(f"ðŸ’¾ [è®°å¿†å­˜å‚¨] å¾®è§‚æ€»ç»“å·²ä¿å­˜ | é¢„è§ˆ: {final_micro[:50]}...")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®è§‚æ€»ç»“
        micros = self.db.get_unmerged_micro_nodes(limit=10)
        if len(micros) >= 10:
            logger.info(f"ðŸ“š [åŽå°] è§¦å‘å®è§‚æ€»ç»“ (åˆå¹¶ 10 æ¡å¾®è§‚è®°å¿†)...")
            micro_text = "\n".join([f"[{m['timeline_tag']}] {m['summary_text']}" for m in micros])
            
            merge_prompt = get_prompt("right_brain_merge", 
                f"è¯·å°†ä»¥ä¸‹å¾®è§‚è®°å¿†åˆå¹¶æˆä¸€æ®µè¿žè´¯çš„å®è§‚å™è¿°:\n{micro_text}")
            macro_summary = self.right_brain.generate([{"role": "user", "content": merge_prompt}])

            self.db.add_memory_node(macro_summary, "MACRO", micros[0]['timeline_tag'])
            self.db.mark_nodes_merged([m['id'] for m in micros])

            vec_id_macro = f"macro_{int(time.time())}_{uuid.uuid4().hex[:4]}"
            self.vec.add_memory(
                text=macro_summary,
                metadata={
                    "type": "episodic",
                    "level": "MACRO",
                    "session_id": session_id
                },
                memory_id=vec_id_macro
            )
            logger.info(f"ðŸ“œ [è®°å¿†å­˜å‚¨] å®è§‚æ€»ç»“å·²ç”Ÿæˆ | é¢„è§ˆ: {macro_summary[:50]}...")

            # å²å®˜è®°å½•
            self._task_historian(macro_summary)

    def _task_historian(self, macro_summary: str):
        """å²å®˜æ’°å†™ç« èŠ‚"""
        logger.info("ðŸ–‹ï¸ [åŽå°] å²å®˜æ­£åœ¨æ’°å†™ç« èŠ‚...")
        
        historian_prompt = get_prompt("historian").format(macro_content=macro_summary)
        saga = self.historian.generate([{"role": "user", "content": historian_prompt}])
        
        self.db.save_saga_entry(saga)
        logger.info("âœ… [å²å®˜] ç« èŠ‚å·²å½’æ¡£")

    # ==========================================
    # ç¤¾ä¼šå­¦åˆ†æžä»»åŠ¡
    # ==========================================

    def _task_sociologist(self, user_input: str, narr_output: str):
        """ç¤¾ä¼šå­¦åˆ†æž"""
        if len(narr_output) < 50:
            return
        
        try:
            prompt = get_prompt("sociologist").format(
                current_graph="{}",
                interaction=f"User: {user_input}\nAI: {narr_output}"
            )
            self.sociologist.generate([{"role": "user", "content": prompt}])
        except Exception as e:
            logger.debug(f"[ç¤¾ä¼šå­¦åˆ†æž] {e}")

    # ==========================================
    # å›¾è°±æ›´æ–°ä»»åŠ¡
    # ==========================================

    def _task_update_graph(self, user_input: str, narr_output: str):
        """å›¾è°±ä¸‰å…ƒç»„æå–"""
        text = f"User: {user_input}\nNarrator: {narr_output}"
        if len(text) < 100:
            return

        prompt = PROMPT_GRAPH_EXTRACTOR.format(text=text)

        try:
            raw = self.graph_extractor.generate([{"role": "user", "content": prompt}])
            data = self._clean_json(raw)
            
            if not data:
                return
            
            triplets = data.get("triplets", [])
            
            count = 0
            preview_rels = []
            
            for t in triplets:
                src = t.get("source")
                rel = t.get("relation")
                tgt = t.get("target")
                desc = t.get("desc", "")
                
                if src and rel and tgt:
                    self.graph.add_triplet(src, rel, tgt, desc)
                    count += 1
                    if len(preview_rels) < 3:
                        preview_rels.append(f"({src}--{rel}-->{tgt})")

            if count > 0:
                logger.info(f"ðŸ•¸ï¸ [å›¾è°±æ›´æ–°] æ–°å¢ž {count} æ¡å…³ç³»: {', '.join(preview_rels)}")
                
        except Exception as e:
            logger.error(f"âŒ [å›¾è°±æ›´æ–°] å¤±è´¥: {e}")

    # ==========================================
    # ä¸»å…¥å£
    # ==========================================

    def run_background_tasks(self, user_input: str, narr_output: str, 
                             search_query: str, session_id: str):
        """
        è¿è¡Œæ‰€æœ‰åŽå°ä»»åŠ¡
        """
        # 1. çŠ¶æ€æ›´æ–°ï¼ˆåŒæ­¥æ‰§è¡Œï¼ŒèŽ·å–æ—¶é—´æ ‡ç­¾ï¼‰
        timeline_tag = self._task_status_update(user_input, narr_output)

        # 2. å¹¶è¡Œæ‰§è¡Œå…¶ä»–ä»»åŠ¡
        tasks = [
            threading.Thread(
                target=self._task_recursive_summary,
                args=(timeline_tag, session_id),
                daemon=True
            ),
            threading.Thread(
                target=self._task_sociologist,
                args=(user_input, narr_output),
                daemon=True
            ),
            threading.Thread(
                target=self._task_update_graph,
                args=(user_input, narr_output),
                daemon=True
            )
        ]

        for t in tasks:
            t.start()


========================================
File Path: .\core\workflow\manager.py
========================================

# core/workflow/manager.py
"""
DeepTavern å·¥ä½œæµç®¡ç†å™¨ v4.5
- æ‰©å±•çŠ¶æ€ç³»ç»Ÿï¼ˆæŠ€èƒ½ã€ç‰©å“ã€åœºæ™¯ã€å…³ç³»æè¿°ï¼‰
- å…³ç³»ä½¿ç”¨æ–‡å­—æè¿°è€Œéžæ•°å€¼
- æ°›å›´ç³»ç»Ÿ
"""

import json
import re
import threading
import time
from typing import Generator, List, Dict, Any, Optional

from core.llm.local_direct import LocalDirectLLM
from core.llm.api_client import APILLM

from core.database.vector_store import VectorStore
from core.database.sqlite_manager import SQLiteManager
from core.database.redis_manager import RedisManager
from core.database.graph_manager import GraphManager
from core.workflow.backend_manager import BackendManager
from core.workflow.prompts import get_prompt
from config.settings import MODEL_CONFIG, DEFAULT_HISTORY_LIMIT, SYSTEM_MAX_HISTORY_CHARS
from core.utils.logger import logger


class WorkflowManager:
    """
    DeepTavern æ ¸å¿ƒå·¥ä½œæµç®¡ç†å™¨
    """
    
    # æ°›å›´â†’å†™ä½œé£Žæ ¼æ˜ å°„
    ATMOSPHERE_STYLES = {
        "ç´§å¼ ": "çŸ­å¥ä¸ºä¸»ï¼ŒåŠ¨è¯å¯†é›†ï¼ŒèŠ‚å¥ç´§å‡‘ï¼Œå°‘ç”¨å½¢å®¹è¯",
        "æˆ˜æ–—": "åŠ¨ä½œæå†™å¯†é›†ï¼Œç´§å¼ åˆºæ¿€ï¼Œå¯æœ‰ç—›æ„Ÿå’Œè¡€è…¥æå†™",
        "æµªæ¼«": "æ„Ÿå®˜ç»†èŠ‚ä¸°å¯Œï¼ŒèŠ‚å¥èˆ’ç¼“ï¼Œæ³¨é‡æƒ…æ„ŸæµåŠ¨å’Œæ°›å›´è¥é€ ",
        "äº²å¯†": "å¤§èƒ†éœ²éª¨ï¼Œæ„Ÿå®˜æå†™è¯¦å°½ï¼Œä¸å›žé¿ä»»ä½•ç»†èŠ‚",
        "è¯¡å¼‚": "æš—ç¤ºæ€§æå†™ï¼Œè¥é€ ä¸å®‰å’Œæ‚¬ç–‘ï¼Œå¤šç”¨éšå–»",
        "ææ€–": "åŽ‹è¿«æ„Ÿï¼ŒæœªçŸ¥çš„ææƒ§ï¼Œæ„Ÿå®˜ä¸Šçš„ä¸é€‚",
        "æ‚²ä¼¤": "å†…çœåŸºè°ƒï¼Œå…³æ³¨å†…å¿ƒæ„Ÿå—ï¼ŒèŠ‚å¥æ”¾ç¼“",
        "è½»æ¾": "è‡ªç„¶å¯¹è¯ï¼Œå¯ä»¥æœ‰å¹½é»˜ï¼ŒèŠ‚å¥è½»å¿«",
        "æ—¥å¸¸": "ç”Ÿæ´»åŒ–æå†™ï¼Œç»†èŠ‚çœŸå®žï¼Œå¯¹è¯è‡ªç„¶"
    }

    # é»˜è®¤åˆå§‹çŠ¶æ€æ¨¡æ¿
    DEFAULT_STATE = {
        "player": {
            "name": "Player",
            "hp": 100,
            "max_hp": 100,
            "mp": 50,
            "max_mp": 50,
            "status_effects": []
        },
        "skills": {},
        "inventory": {},
        "relationships": {},
        "scene": {
            "location": "æœªçŸ¥åœ°ç‚¹",
            "sub_location": "",
            "atmosphere": "æ—¥å¸¸",
            "weather": "æ™´æœ—",
            "time_of_day": "morning",
            "npcs_present": []
        },
        "world_time": {
            "day": 1,
            "hour": 8,
            "minute": 0
        },
        "narrator_persona": {
            "current_mood": "å¹³é™",
            "speech_style": "æ­£å¸¸"
        }
    }

    def __init__(self):
        logger.info("=" * 60)
        logger.info("ðŸ° ç³»ç»Ÿåˆå§‹åŒ–: DeepTavern v4.5 Core")
        logger.info("   (æ‰©å±•çŠ¶æ€ç³»ç»Ÿ & æ–‡å­—å…³ç³»æè¿° & æ°›å›´ç³»ç»Ÿ)")
        logger.info("=" * 60)
        
        # åŠ è½½ LLM
        def load_llm(role_key, default_name="Unknown"):
            conf = MODEL_CONFIG.get(role_key, {})
            if not conf:
                logger.warning(f"âš ï¸ [{role_key}] æœªæ‰¾åˆ°é…ç½®ï¼Œä½¿ç”¨ Mock æ¨¡åž‹")
                return APILLM({"model": "mock", "api_key": "none", "base_url": ""})
            
            model_path = str(conf.get("model", "")).lower()
            
            if model_path.endswith(".gguf"):
                logger.info(f"ðŸ“¥ [åˆå§‹åŒ–] åŠ è½½æœ¬åœ°æ¨¡åž‹ {default_name} (GGUF)...")
                return LocalDirectLLM(config=conf)
            else:
                logger.info(f"â˜ï¸ [åˆå§‹åŒ–] è¿žæŽ¥äº‘ç«¯æ¨¡åž‹ {default_name}...")
                return APILLM(conf)

        self.reflex_bot = load_llm("reflex", "Reflex (æ„å›¾è¯†åˆ«)")
        self.director_bot = load_llm("director", "Director (å¯¼æ¼”)")
        self.narrator_bot = load_llm("narrator", "Narrator (å™äº‹è€…)")
        
        # åŸºç¡€è®¾æ–½
        self.memory_vec = VectorStore(collection_name="long_term_memory")
        self.rules_vec = VectorStore(collection_name="rules_memory")
        self.graph = GraphManager()
        
        self.db = SQLiteManager()
        self.redis = RedisManager()
        self.backend = BackendManager()
        
        self.current_session_uuid = None
        self.context_limit = DEFAULT_HISTORY_LIMIT
        self.max_chars = SYSTEM_MAX_HISTORY_CHARS
        
        self.char_name = "AI Character"
        self.char_persona = "A helpful roleplay assistant."
        
        logger.info("=" * 60)
        logger.info("âœ… ç³»ç»Ÿå°±ç»ª")
        logger.info("=" * 60)

    # ==========================================
    # ä¼šè¯ç®¡ç†
    # ==========================================

    def start_new_session(self, user_name: str = "Player", char_name: str = None, 
                          char_persona: str = None) -> str:
        """å¼€å¯æ–°ä¼šè¯"""
        if char_name:
            self.char_name = char_name
        if char_persona:
            self.char_persona = char_persona
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = self._create_initial_state(user_name)
        
        uuid = self.db.create_conversation(
            character_name=self.char_name,
            initial_state=initial_state
        )
        
        self.current_session_uuid = uuid
        self.graph.switch_session(uuid)
        self.redis.clear_context(uuid)
        self.redis.clear_state(uuid)
        
        logger.info(f"ðŸ†• æ–°ä¼šè¯å·²åˆ›å»º: {user_name} vs {self.char_name} (UUID: {uuid})")
        return uuid

    def _create_initial_state(self, user_name: str) -> Dict:
        """åˆ›å»ºåˆå§‹çŠ¶æ€"""
        state = json.loads(json.dumps(self.DEFAULT_STATE))  # æ·±æ‹·è´
        state["player"]["name"] = user_name
        return state

    def load_session(self, uuid: str) -> bool:
        """åŠ è½½ä¼šè¯"""
        if self.db.load_conversation(uuid):
            self.current_session_uuid = uuid
            self.char_name = self.db.get_current_character_name()
            self.graph.switch_session(uuid)
            self._get_history_list()
            self._get_current_state()
            logger.info(f"ðŸ“‚ å­˜æ¡£å·²åŠ è½½: {uuid} (è§’è‰²: {self.char_name})")
            return True
        logger.error(f"âŒ åŠ è½½å­˜æ¡£å¤±è´¥: {uuid}")
        return False

    def list_all_sessions(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        return self.db.list_conversations()

    def delete_session(self, uuid: str) -> bool:
        """åˆ é™¤ä¼šè¯"""
        logger.warning(f"ðŸ—‘ï¸ æ­£åœ¨é”€æ¯ä¼šè¯: {uuid}")
        
        db_success = self.db.delete_session(uuid)
        if not db_success:
            return False
        
        self.memory_vec.delete_session_memories(uuid)
        self.graph.delete_graph(uuid)
        self.redis.clear_context(uuid)
        self.redis.clear_state(uuid)
        
        if self.current_session_uuid == uuid:
            self.current_session_uuid = None
        
        logger.info("âœ… ä¼šè¯é”€æ¯å®Œæˆ")
        return True

    # ==========================================
    # çŠ¶æ€æ ¼å¼åŒ–æ–¹æ³•
    # ==========================================

    def _format_player_status(self, state: Dict) -> str:
        """æ ¼å¼åŒ–çŽ©å®¶çŠ¶æ€"""
        player = state.get("player", {})
        
        hp = player.get("hp", 100)
        max_hp = player.get("max_hp", 100)
        mp = player.get("mp", 0)
        max_mp = player.get("max_mp", 0)
        effects = player.get("status_effects", [])
        
        lines = [f"HP: {hp}/{max_hp}"]
        
        if max_mp > 0:
            lines.append(f"MP: {mp}/{max_mp}")
        
        if effects:
            lines.append(f"çŠ¶æ€: {', '.join(effects)}")
        
        return " | ".join(lines)

    def _format_relationships(self, state: Dict) -> str:
        """æ ¼å¼åŒ–äººç‰©å…³ç³»ï¼ˆæ–‡å­—æè¿°ï¼‰"""
        relationships = state.get("relationships", {})
        
        if not relationships:
            return "æš‚æ— å·²å»ºç«‹çš„äººç‰©å…³ç³»"
        
        lines = []
        for name, info in relationships.items():
            if isinstance(info, dict):
                relation = info.get("å…³ç³»", "æœªçŸ¥")
                events = info.get("è¿‘æœŸäº‹ä»¶", [])
                personality = info.get("æ€§æ ¼å¤‡æ³¨", "")
                
                line = f"ã€{name}ã€‘{relation}"
                if events:
                    line += f"\n  è¿‘æœŸ: {'; '.join(events[-3:])}"  # æœ€è¿‘3ä»¶äº‹
                if personality:
                    line += f"\n  å¤‡æ³¨: {personality}"
                lines.append(line)
            else:
                # å…¼å®¹æ—§æ ¼å¼ï¼ˆçº¯æ•°å€¼ï¼‰
                lines.append(f"ã€{name}ã€‘å…³ç³»å€¼: {info}")
        
        return "\n".join(lines)

    def _format_skills(self, state: Dict) -> str:
        """æ ¼å¼åŒ–æŠ€èƒ½"""
        skills = state.get("skills", {})
        
        if not skills:
            return "æš‚æ— æŠ€èƒ½"
        
        lines = []
        for name, info in skills.items():
            if isinstance(info, dict):
                level = info.get("level", 1)
                exp = info.get("exp", 0)
                desc = info.get("description", "")
                line = f"- {name} Lv.{level} (ç»éªŒ: {exp}/100)"
                if desc:
                    line += f" - {desc}"
                lines.append(line)
            else:
                lines.append(f"- {name}: {info}")
        
        return "\n".join(lines)

    def _format_inventory(self, state: Dict) -> str:
        """æ ¼å¼åŒ–ç‰©å“"""
        inventory = state.get("inventory", {})
        
        if not inventory:
            return "èƒŒåŒ…ä¸ºç©º"
        
        equipped = []
        items = []
        
        for name, info in inventory.items():
            if isinstance(info, dict):
                count = info.get("count", 1)
                item_type = info.get("type", "")
                is_equipped = info.get("equipped", False)
                desc = info.get("description", "")
                
                if count > 1:
                    item_str = f"{name} x{count}"
                else:
                    item_str = name
                
                if desc:
                    item_str += f" ({desc})"
                
                if is_equipped:
                    equipped.append(f"[è£…å¤‡ä¸­] {item_str}")
                else:
                    items.append(f"- {item_str}")
            else:
                items.append(f"- {name}")
        
        result = []
        if equipped:
            result.extend(equipped)
        if items:
            result.extend(items)
        
        return "\n".join(result) if result else "èƒŒåŒ…ä¸ºç©º"

    def _format_skills_and_items(self, state: Dict) -> str:
        """ç»„åˆæŠ€èƒ½å’Œç‰©å“ä¿¡æ¯"""
        skills_text = self._format_skills(state)
        items_text = self._format_inventory(state)
        
        return f"ã€æŠ€èƒ½ã€‘\n{skills_text}\n\nã€ç‰©å“ã€‘\n{items_text}"

    def _format_scene(self, state: Dict) -> Dict[str, str]:
        """æå–åœºæ™¯ä¿¡æ¯"""
        scene = state.get("scene", {})
        world_time = state.get("world_time", {})
        
        location = scene.get("location", "æœªçŸ¥")
        sub_loc = scene.get("sub_location", "")
        if sub_loc:
            location = f"{location} - {sub_loc}"
        
        atmosphere = scene.get("atmosphere", "æ—¥å¸¸")
        weather = scene.get("weather", "")
        time_of_day = scene.get("time_of_day", "")
        npcs = scene.get("npcs_present", [])
        
        return {
            "location": location,
            "atmosphere": atmosphere,
            "weather": weather,
            "time_of_day": time_of_day,
            "npcs_present": ", ".join(npcs) if npcs else "æ— "
        }

    def _get_atmosphere_style(self, atmosphere: str) -> str:
        """èŽ·å–æ°›å›´å¯¹åº”çš„å†™ä½œé£Žæ ¼æŒ‡å¯¼"""
        return self.ATMOSPHERE_STYLES.get(atmosphere, "æ­£å¸¸å™äº‹é£Žæ ¼")

    def _format_timeline_tag(self, state: Dict) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ ‡ç­¾"""
        world_time = state.get("world_time", {})
        day = world_time.get("day", 1)
        hour = world_time.get("hour", 8)
        minute = world_time.get("minute", 0)
        return f"Day {day}, {hour:02d}:{minute:02d}"

    def _format_persona_voice(self, state: Dict) -> str:
        """æ ¼å¼åŒ–å™äº‹è€…äººæ ¼çŠ¶æ€"""
        persona = state.get("narrator_persona", {})
        mood = persona.get("current_mood", "å¹³é™")
        style = persona.get("speech_style", "æ­£å¸¸")
        
        return f"å½“å‰å¿ƒæƒ…: {mood}\nè¯´è¯é£Žæ ¼: {style}"

    # ==========================================
    # è§„åˆ™è§£æžè¾…åŠ©
    # ==========================================

    def _parse_rule_selection(self, selection_res: str, max_options: int) -> List[int]:
        """è§£æžè§„åˆ™é€‰æ‹©ç»“æžœ"""
        if not selection_res or "NONE" in selection_res.upper():
            return []
        
        selected = []
        numbers = re.findall(r'\d+', selection_res)
        
        for num_str in numbers:
            try:
                num = int(num_str)
                if 1 <= num <= max_options and num not in selected:
                    selected.append(num)
            except ValueError:
                continue
        
        return selected

    # ==========================================
    # æ ¸å¿ƒå¯¹è¯å¾ªçŽ¯
    # ==========================================

    def chat(self, user_input: str, deep_mode: bool = False, 
             lite_mode: bool = False) -> Generator[str, None, None]:
        """æ ¸å¿ƒå¯¹è¯æ–¹æ³•"""
        
        if not self.current_session_uuid:
            yield "[ç³»ç»Ÿé”™è¯¯]: æœªåŠ è½½ä»»ä½•ä¼šè¯ã€‚"
            return

        start_time = time.time()
        
        history_list = self._get_history_list()
        current_turn = (len(history_list) // 2) + 1
        current_state = self._get_current_state()
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ðŸ [ç¬¬ {current_turn} è½®å¯¹è¯å¼€å§‹]")
        logger.info(f"   æ·±åº¦æ¨¡å¼: {deep_mode}, è½»é‡æ¨¡å¼: {lite_mode}")
        logger.info(f"{'='*60}")
        logger.info(f"ðŸ‘¤ [ç”¨æˆ·è¾“å…¥]: {user_input}")
        
        # æ ¼å¼åŒ–çŠ¶æ€ä¿¡æ¯
        scene_info = self._format_scene(current_state)
        timeline_tag = self._format_timeline_tag(current_state)
        player_status = self._format_player_status(current_state)
        relationships_text = self._format_relationships(current_state)
        skills_and_items = self._format_skills_and_items(current_state)
        persona_voice = self._format_persona_voice(current_state)
        atmosphere = scene_info.get("atmosphere", "æ—¥å¸¸")
        atmosphere_style = self._get_atmosphere_style(atmosphere)
        
        # åˆå§‹åŒ–
        logic_verdict = "ï¼ˆè½»é‡æ¨¡å¼è·³è¿‡ï¼‰"
        weighted_memory_text = ""
        weighted_rules_text = ""
        search_query = user_input

        # === é˜¶æ®µ A: æ„ŸçŸ¥ä¸Žæ€è€ƒ ===
        if not lite_mode:
            # 1. Reflex (æ„å›¾è¯†åˆ«)
            logger.info("ðŸ” [Reflex] æ„å›¾è¯†åˆ«ä¸­...")
            
            reflex_limit = 5
            short_history = history_list[-reflex_limit:] if len(history_list) > reflex_limit else history_list
            short_history_text = self._format_history_text(short_history)
            
            reflex_prompt = get_prompt("reflex").format(
                history=short_history_text,
                user_input=user_input
            )
            reflex_response = self.reflex_bot.generate([{"role": "user", "content": reflex_prompt}])
            
            if "Error" in reflex_response or "exceed" in reflex_response:
                logger.error(f"âŒ [Reflex] é”™è¯¯: {reflex_response}")
                search_query = user_input
            else:
                search_query = reflex_response.strip().replace('"', '').replace("Search Query:", "").strip()
                logger.info(f"âœ… [Reflex] æœç´¢å…³é”®è¯: '{search_query}'")
            
            if "BLOCK" in reflex_response.upper() and "BLOCK" not in user_input.upper():
                logger.warning("ðŸ›¡ï¸ [å®‰å…¨æ‹¦æˆª]")
                yield "ç³»ç»Ÿæ‹¦æˆªï¼šè¾“å…¥åŒ…å«ä¸å®‰å…¨å†…å®¹ã€‚"
                return

            # 2. Rules RAG
            logger.info("ðŸ“œ [Rules RAG] æ£€ç´¢è§„åˆ™åº“...")
            
            rule_candidates = self.rules_vec.search(search_query, n_results=5)
            active_rules = self.db.get_active_rules()
            
            if rule_candidates:
                options_text = ""
                for i, r in enumerate(rule_candidates):
                    preview = r['content'][:100].replace('\n', ' ')
                    options_text += f"Option {i+1}: {preview}...\n"
                
                selection_prompt = (
                    f"User Input: {user_input}\n"
                    f"Candidates:\n{options_text}\n"
                    f"Task: Which rules apply? Output numbers (e.g. 1,3) or NONE."
                )
                selection_res = self.reflex_bot.generate([{"role": "user", "content": selection_prompt}])
                
                selected_indices = self._parse_rule_selection(selection_res, len(rule_candidates))
                
                for idx in selected_indices:
                    r = rule_candidates[idx - 1]
                    full_content = r.get('metadata', {}).get('full_content', r['content'])
                    active_rules.append(full_content)
                
                logger.info(f"âœ… [Rules RAG] æ¿€æ´» {len(selected_indices)} æ¡è§„åˆ™")

            weighted_rules_text = "\n\n".join(active_rules) if active_rules else ""

            # 3. Memory RAG
            n_results = 100 if deep_mode else 20
            logger.info(f"ðŸ§  [Memory RAG] æ£€ç´¢è®°å¿† (ç›®æ ‡: {n_results})...")
            
            filter_condition = {
                "$or": [
                    {"session_id": self.current_session_uuid},
                    {"type": "INTERNET_LORE"}
                ]
            }
            
            memories = self.memory_vec.search(
                search_query,
                n_results=n_results,
                filter_dict=filter_condition
            )
            
            if memories:
                memory_parts = [f"- {m['content']}" for m in memories if m.get('score', 0) > 0.2]
                weighted_memory_text = "\n".join(memory_parts) if memory_parts else "æ— ç›¸å…³è®°å¿†"
                logger.info(f"âœ… [Memory RAG] å¬å›ž {len(memory_parts)} æ¡")
            else:
                weighted_memory_text = "æ— ç›¸å…³è®°å¿†"

            # 4. GraphRAG
            logger.info("ðŸ•¸ï¸ [GraphRAG] æ£€ç´¢çŸ¥è¯†å›¾è°±...")
            keywords = search_query.split()
            graph_context = self.graph.search_subgraph(search_query, top_k=5, depth=1)
            
            if graph_context:
                weighted_memory_text += f"\n\nã€çŸ¥è¯†å›¾è°±ã€‘\n{graph_context}"
                logger.info("âœ… [GraphRAG] å‘çŽ°å…³è”")

            # 5. Director
            logger.info("ðŸŽ¬ [Director] ç¼–æŽ’å‰§æƒ…...")
            
            memory_spine = self.db.get_memory_spine()
            
            director_history_limit = 10
            recent_msgs = history_list[-director_history_limit:] if len(history_list) > director_history_limit else history_list
            recent_history_text = self._format_history_text(recent_msgs)
            if not recent_history_text:
                recent_history_text = "(å¯¹è¯åˆšå¼€å§‹)"

            director_prompt = get_prompt("director").format(
                timeline_tag=timeline_tag,
                location=scene_info["location"],
                atmosphere=atmosphere,
                weather=scene_info["weather"],
                npcs_present=scene_info["npcs_present"],
                player_status=player_status,
                relationships_text=relationships_text,
                skills_and_items=skills_and_items,
                state=json.dumps(current_state, ensure_ascii=False, indent=2),
                dynamic_rules=weighted_rules_text,
                spine=memory_spine,
                rag_details=weighted_memory_text,
                user_input=user_input
            )
            
            logic_verdict = self.director_bot.generate([{"role": "user", "content": director_prompt}])
            
            logger.info(f"ðŸŽ¬ [Director æŒ‡ä»¤]:\n{'-'*40}\n{logic_verdict[:500]}...\n{'-'*40}")
            
            yield f"\n[å¯¼æ¼”]: {logic_verdict[:80]}...\n\n"

        # === é˜¶æ®µ B: Narrator ===
        logger.info("ðŸ—£ï¸ [Narrator] ç”Ÿæˆå›žå¤...")
        
        narrator_system_prompt = get_prompt("narrator").format(
            atmosphere=atmosphere,
            persona_voice=persona_voice,
            scene_info=scene_info["location"],
            npcs_present=scene_info["npcs_present"],
            director_note=logic_verdict,
            dynamic_rules=weighted_rules_text,
            persona=self.char_persona,
            user_input=user_input
        )
        
        safe_history_limit = 20
        messages = [{"role": "system", "content": narrator_system_prompt}]
        recent_history = history_list[-safe_history_limit:] if len(history_list) > safe_history_limit else history_list
        
        for msg in recent_history:
            messages.append({"role": msg["role"], "content": msg["content"]})
        
        messages.append({"role": "user", "content": user_input})
        
        full_response = ""
        
        try:
            for chunk in self.narrator_bot.generate_stream(messages):
                full_response += chunk
                yield chunk
        except Exception as e:
            logger.error(f"âŒ [Narrator] ç”Ÿæˆä¸­æ–­: {e}")
            if not full_response:
                full_response = "(å™äº‹è€…æ•…éšœï¼Œè¯·é‡è¯•)"
                yield full_response

        logger.info(f"ðŸ—£ï¸ [Narrator] è¾“å‡º {len(full_response)} å­—")

        # === é˜¶æ®µ C: åŽå°ä»»åŠ¡ ===
        logger.info("âš™ï¸ [åŽå°] è§¦å‘å¼‚æ­¥ä»»åŠ¡...")
        
        self.db.add_message("user", user_input)
        ai_msg_id = self.db.add_message("assistant", full_response)
        
        full_prompt_log = json.dumps(messages, ensure_ascii=False)
        self.db.log_interaction(ai_msg_id, full_prompt_log, weighted_memory_text, 
                               getattr(self.narrator_bot, 'model_name', 'unknown'))
        
        new_history = history_list + [
            {"role": "user", "content": user_input},
            {"role": "assistant", "content": full_response}
        ]
        if len(new_history) > self.context_limit:
            new_history = new_history[-self.context_limit:]
        self.redis.cache_context(self.current_session_uuid, new_history)
        
        threading.Thread(
            target=self.backend.run_background_tasks,
            args=(user_input, full_response, search_query, self.current_session_uuid),
            daemon=True
        ).start()
        
        elapsed = time.time() - start_time
        logger.info(f"{'='*60}")
        logger.info(f"ðŸ [ç¬¬ {current_turn} è½®ç»“æŸ] è€—æ—¶: {elapsed:.2f}s")
        logger.info(f"{'='*60}")

    # ==========================================
    # é«˜çº§åŠŸèƒ½æŽ¥å£
    # ==========================================

    def rollback(self, target_message_id: int) -> bool:
        """å›žæ»šåˆ°æŒ‡å®šæ¶ˆæ¯"""
        if not self.current_session_uuid:
            return False
        
        logger.warning(f"âª [å›žæ»š] è‡³æ¶ˆæ¯ ID {target_message_id}")
        new_state = self.db.rollback_to_message(target_message_id)
        
        if new_state:
            self.redis.clear_context(self.current_session_uuid)
            self.redis.clear_state(self.current_session_uuid)
            self.redis.cache_state(self.current_session_uuid, new_state)
            logger.info("âœ… [å›žæ»š] æˆåŠŸ")
            return True
        
        logger.error("âŒ [å›žæ»š] å¤±è´¥")
        return False

    def get_full_history(self, page: int = 1, page_size: int = 50) -> List[Dict]:
        """èŽ·å–å®Œæ•´åŽ†å²"""
        if not self.current_session_uuid:
            return []
        return self.db.get_full_history(page, page_size)

    def get_archived_memories(self) -> List[Dict]:
        """èŽ·å–å½’æ¡£è®°å¿†"""
        if not self.current_session_uuid:
            return []
        return self.db.get_memories()

    # ==========================================
    # å†…éƒ¨è¾…åŠ©æ–¹æ³•
    # ==========================================

    def _get_history_list(self) -> List[Dict]:
        """èŽ·å–åŽ†å²æ¶ˆæ¯åˆ—è¡¨"""
        if not self.current_session_uuid:
            return []
        
        cached = self.redis.get_context(self.current_session_uuid)
        if cached:
            return cached
        
        history = self.db.get_recent_messages(limit=self.context_limit)
        self.redis.cache_context(self.current_session_uuid, history)
        return history

    def _get_current_state(self) -> Dict:
        """èŽ·å–å½“å‰çŠ¶æ€"""
        if not self.current_session_uuid:
            return {}
        
        cached = self.redis.get_state(self.current_session_uuid)
        if cached:
            return cached
        
        state = self.db.get_current_state()
        
        # ç¡®ä¿çŠ¶æ€æœ‰æ‰€æœ‰å¿…éœ€å­—æ®µ
        state = self._ensure_state_structure(state)
        
        self.redis.cache_state(self.current_session_uuid, state)
        return state

    def _ensure_state_structure(self, state: Dict) -> Dict:
        """ç¡®ä¿çŠ¶æ€ç»“æž„å®Œæ•´ï¼ˆå…¼å®¹æ—§å­˜æ¡£ï¼‰"""
        default = self.DEFAULT_STATE
        
        # åˆå¹¶ç¼ºå¤±çš„å­—æ®µ
        for key, value in default.items():
            if key not in state:
                state[key] = value
            elif isinstance(value, dict) and isinstance(state.get(key), dict):
                for sub_key, sub_value in value.items():
                    if sub_key not in state[key]:
                        state[key][sub_key] = sub_value
        
        # å…¼å®¹æ—§çš„æ‰å¹³ç»“æž„
        if "hp" in state and "player" in state:
            state["player"]["hp"] = state.pop("hp", 100)
        if "inventory" in state and isinstance(state["inventory"], list):
            # æ—§æ ¼å¼æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—å…¸
            old_inv = state["inventory"]
            state["inventory"] = {item: {"type": "item", "count": 1} for item in old_inv}
        if "location" in state and "scene" in state:
            state["scene"]["location"] = state.pop("location", "æœªçŸ¥")
        if "world_time" in state and isinstance(state["world_time"], str):
            # æ—§æ ¼å¼æ˜¯å­—ç¬¦ä¸² "Day 1, 08:00"
            state["world_time"] = {"day": 1, "hour": 8, "minute": 0}
        
        return state

    def _format_history_text(self, history_list: List[Dict]) -> str:
        """æ ¼å¼åŒ–åŽ†å²æ¶ˆæ¯"""
        buffer = []
        for msg in history_list:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            
            if role == "user":
                buffer.append(f"Player: {content}")
            elif role == "assistant":
                buffer.append(f"{self.char_name}: {content}")
            else:
                buffer.append(f"[{role}]: {content}")
        
        return "\n".join(buffer)


========================================
File Path: .\core\workflow\prompts.py
========================================

# core/workflow/prompts.py
from config.settings import MODEL_CONFIG

def get_prompt(role_key, default=""):
    """
    å®‰å…¨èŽ·å– Promptã€‚
    ä¼˜å…ˆä»Ž config.json (MODEL_CONFIG) ä¸­è¯»å–ã€‚
    å¦‚æžœé…ç½®ä¸­æ²¡æœ‰ï¼Œåˆ™è¿”å›ž defaultã€‚
    """
    return MODEL_CONFIG.get(role_key, {}).get("prompt", default)

# --- é»˜è®¤ Prompt æ¨¡æ¿ (å½“ config.json ä¸­ç¼ºå¤±æ—¶ä½¿ç”¨) ---

DEFAULT_GRAPH_EXTRACTOR = """[System: Knowledge Graph Extractor]
Analyze the narrative and extract Entities and Relationships.

[Input Text]
{text}

[Instructions]
1. Identify key entities (Characters, Locations, Items, Factions).
2. Identify relationships between them (e.g., hates, loves, owns, located_in, member_of).
3. Output strictly in JSON format:
{{
  "triplets": [
    {{"source": "Alice", "relation": "owns", "target": "Rusty Sword", "desc": "Alice found it in the cave"}},
    {{"source": "Alice", "relation": "located_in", "target": "Dark Cave", "desc": ""}}
  ]
}}
4. If no significant relationship changes, return empty list.
"""

# --- å¯¼å‡ºå˜é‡ ---

# 1. æ„å›¾è¯†åˆ« & æŸ¥è¯¢é‡å†™
PROMPT_REWRITER = get_prompt("reflex")
PROMPT_GATEKEEPER = get_prompt("gatekeeper", PROMPT_REWRITER)

# 2. å¯¼æ¼”
PROMPT_DIRECTOR = get_prompt("director")

# 3. ä¸»å™äº‹
PROMPT_NARRATOR = get_prompt("narrator")

# 4. çŠ¶æ€å¼•æ“Ž
PROMPT_STATUS_UPDATE = get_prompt("status")

# 5. è®°å¿†æ¸…æ´—
PROMPT_CLEANER = get_prompt("cleaner")

# 6. æƒ…æ„Ÿåˆ†æž
PROMPT_EMOTION = get_prompt("empath")

# 7. èˆžå°ç›‘ç£
PROMPT_STAGE = get_prompt("stage")

# 8. ä¸–ç•Œæ¨¡æ‹Ÿå™¨ (åŽŸ gossip)
PROMPT_WORLD_SIM = get_prompt("world_sim")

# 9. çŸ¥è¯†å›¾è°±æå– (GraphRAG)
# å°è¯•ä»Žé…ç½®ä¸­è¯»å– key="graph_extractor" çš„ promptï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
PROMPT_GRAPH_EXTRACTOR = get_prompt("graph_extractor", DEFAULT_GRAPH_EXTRACTOR)


========================================
File Path: .\scripts\check_db.py
========================================

import sqlite3
import os

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(BASE_DIR, "data", "rules_preset.db")

def check():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # 1. ç»Ÿè®¡å„åˆ†ç±»æ•°é‡
    print("=== è§„åˆ™åˆ†ç±»ç»Ÿè®¡ ===")
    cursor.execute("SELECT category, COUNT(*) FROM rule_fragments GROUP BY category")
    for cat, count in cursor.fetchall():
        print(f"[{cat}]: {count} æ¡")
        
    # 2. æŸ¥çœ‹å‡ æ¡åˆšåˆšå¯¼å…¥çš„å†…å®¹ (æ£€æŸ¥æ¸…æ´—æ•ˆæžœ)
    print("\n=== å†…å®¹æŠ½æŸ¥ (å‰3æ¡) ===")
    cursor.execute("SELECT category, scope_value, content FROM rule_fragments ORDER BY id DESC LIMIT 3")
    for row in cursor.fetchall():
        print(f"--- [{row[0]}] {row[1]} ---")
        # åªæ˜¾ç¤ºå‰100ä¸ªå­—ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰ä¹±ç æˆ– {{setvar}}
        print(row[2][:100].replace("\n", " ") + "...") 
        
    conn.close()

if __name__ == "__main__":
    check()


========================================
File Path: .\scripts\fix_db.py
========================================

import sys
import os
import uuid

# å®šä½é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from core.database.vector_store import VectorStore

def fix_chroma():
    print("æ­£åœ¨ä¿®å¤å‘é‡æ•°æ®åº“ç´¢å¼•...")
    
    # 1. ä¿®å¤å‰§æƒ…è®°å¿†åº“ (Long Term Memory)
    try:
        print("æ£€æŸ¥å‰§æƒ…è®°å¿†åº“ (long_term_memory)...")
        mem_store = VectorStore(collection_name="long_term_memory")
        count = mem_store.collection.count()
        print(f"å½“å‰å‰§æƒ…è®°å¿†æ•°é‡: {count}")
        
        if count == 0:
            print("âš ï¸ å‘çŽ°ç©ºåº“ï¼Œæ­£åœ¨å†™å…¥åˆå§‹åŒ–é”šç‚¹...")
            mem_store.add_memory(
                text="[System] Memory Initialized.",
                metadata={"type": "init", "timestamp": "0"},
                memory_id="init_anchor_001"
            )
            print("âœ… å‰§æƒ…åº“åˆå§‹åŒ–å®Œæˆã€‚")
        else:
            print("âœ… å‰§æƒ…åº“æ­£å¸¸ã€‚")
            
    except Exception as e:
        print(f"âŒ å‰§æƒ…åº“ä¿®å¤å¤±è´¥: {e}")

    # 2. æ£€æŸ¥è§„åˆ™åº“ (Rules Memory)
    try:
        print("\næ£€æŸ¥è§„åˆ™åº“ (rules_memory)...")
        rule_store = VectorStore(collection_name="rules_memory")
        count = rule_store.collection.count()
        print(f"å½“å‰è§„åˆ™æ•°é‡: {count}")
        
        if count == 0:
            print("âš ï¸ è­¦å‘Šï¼šè§„åˆ™åº“æ˜¯ç©ºçš„ï¼ä½ ä¹‹å‰çš„å¯¼å…¥å¯èƒ½æ²¡æˆåŠŸä¿å­˜ï¼Ÿ")
        else:
            print(f"âœ… è§„åˆ™åº“æ­£å¸¸ (åŒ…å« {count} æ¡è§„åˆ™)ã€‚")
            
    except Exception as e:
        print(f"âŒ è§„åˆ™åº“æ£€æŸ¥å¤±è´¥: {e}")

    print("\nä¿®å¤å®Œæˆï¼è¯·é‡å¯ DeepTavernã€‚")

if __name__ == "__main__":
    fix_chroma()


========================================
File Path: .\scripts\ingest_gui.py
========================================

# scripts/ingest_gui.py
import sys
import os
import json

from PyQt6.QtCore import Qt, QThread, pyqtSignal
from PyQt6.QtWidgets import (QApplication, QVBoxLayout, QHBoxLayout, QFileDialog, QWidget)

# å¼•å…¥ qfluentwidgets
from qfluentwidgets import (
    FluentWindow, SubtitleLabel, BodyLabel, CardWidget, 
    PrimaryPushButton, LineEdit, TextEdit, InfoBar, 
    StrongBodyLabel, CaptionLabel, ComboBox, FluentIcon as FIF
)

# å¼•å…¥åŽç«¯é€»è¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from scripts.ingest_preset import PresetIngester

class IngestWorker(QThread):
    log_signal = pyqtSignal(str)
    finished_signal = pyqtSignal()

    def __init__(self, file_path, llm_config):
        super().__init__()
        self.file_path = file_path
        self.llm_config = llm_config

    def run(self):
        try:
            ingester = PresetIngester(
                self.llm_config, 
                log_callback=self.log_signal.emit
            )
            ingester.ingest(self.file_path)
        except Exception as e:
            self.log_signal.emit(f"âŒ è‡´å‘½é”™è¯¯: {str(e)}")
        finally:
            self.finished_signal.emit()

class IngestWindow(FluentWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("DeepTavern é¢„è®¾æ¸…æ´—å·¥å…·")
        self.resize(800, 650)
        
        # ä½¿ç”¨é€šç”¨å›¾æ ‡é˜²æ­¢æŠ¥é”™
        self.setWindowIcon(FIF.SYNC.icon())

        # ä¸»å®¹å™¨
        self.main_widget = QWidget()
        # ã€ä¿®å¤ç‚¹ã€‘è®¾ç½® objectName
        self.main_widget.setObjectName("ingestInterface")
        
        self.addSubInterface(self.main_widget, FIF.FOLDER, "æ¸…æ´—æŽ§åˆ¶å°")
        
        self.layout = QVBoxLayout(self.main_widget)
        self.layout.setContentsMargins(30, 20, 30, 20)
        self.layout.setSpacing(15)

        # 1. æ–‡ä»¶é€‰æ‹©åŒº
        self.layout.addWidget(SubtitleLabel("1. é€‰æ‹©é¢„è®¾æ–‡ä»¶ (SillyTavern æ ¼å¼)", self))
        
        file_card = CardWidget(self.main_widget)
        file_layout = QHBoxLayout(file_card)
        
        self.path_edit = LineEdit()
        self.path_edit.setPlaceholderText("è¯·é€‰æ‹© .json æ–‡ä»¶...")
        self.browse_btn = PrimaryPushButton("æµè§ˆ", self)
        self.browse_btn.clicked.connect(self.browse_file)
        
        file_layout.addWidget(self.path_edit)
        file_layout.addWidget(self.browse_btn)
        self.layout.addWidget(file_card)

        # 2. LLM é…ç½®åŒº
        self.layout.addWidget(SubtitleLabel("2. é…ç½®æ¸…æ´—ç”¨ LLM (æŽ¨èé«˜æ™ºå•†æ¨¡åž‹)", self))
        
        config_card = CardWidget(self.main_widget)
        config_layout = QVBoxLayout(config_card)
        
        # Base URL
        config_layout.addWidget(CaptionLabel("Base URL"))
        self.url_edit = LineEdit()
        self.url_edit.setText("https://api.siliconflow.cn/v1") # é»˜è®¤å€¼
        config_layout.addWidget(self.url_edit)
        
        # API Key
        config_layout.addWidget(CaptionLabel("API Key"))
        self.key_edit = LineEdit()
        self.key_edit.setPlaceholderText("sk-...")
        self.key_edit.setEchoMode(LineEdit.EchoMode.Password)
        config_layout.addWidget(self.key_edit)
        
        # Model Name
        config_layout.addWidget(CaptionLabel("æ¨¡åž‹åç§°"))
        self.model_edit = LineEdit()
        self.model_edit.setText("deepseek-ai/DeepSeek-V3") # é»˜è®¤å€¼
        self.model_edit.setPlaceholderText("ä¾‹å¦‚: gemini-pro, gpt-4o")
        config_layout.addWidget(self.model_edit)
        
        self.layout.addWidget(config_card)

        # 3. æ“ä½œåŒº
        action_layout = QHBoxLayout()
        self.start_btn = PrimaryPushButton("å¼€å§‹æ¸…æ´—å…¥åº“", self)
        self.start_btn.clicked.connect(self.start_ingest)
        self.start_btn.setFixedWidth(200)
        action_layout.addStretch(1)
        action_layout.addWidget(self.start_btn)
        self.layout.addLayout(action_layout)

        # 4. æ—¥å¿—åŒº
        self.layout.addWidget(StrongBodyLabel("è¿è¡Œæ—¥å¿—", self))
        self.log_view = TextEdit()
        self.log_view.setReadOnly(True)
        self.layout.addWidget(self.log_view)

    def browse_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©é¢„è®¾æ–‡ä»¶", "", "JSON Files (*.json)"
        )
        if file_path:
            self.path_edit.setText(file_path)

    def start_ingest(self):
        path = self.path_edit.text().strip()
        if not os.path.exists(path):
            InfoBar.error("é”™è¯¯", "æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼", parent=self)
            return

        api_key = self.key_edit.text().strip()
        if not api_key:
            InfoBar.warning("æç¤º", "è¯·è¾“å…¥ API Key", parent=self)
            return

        llm_config = {
            "base_url": self.url_edit.text().strip(),
            "api_key": api_key,
            "model": self.model_edit.text().strip(),
            "temperature": 0.1
        }

        # é”å®šç•Œé¢
        self.start_btn.setEnabled(False)
        self.start_btn.setText("æ­£åœ¨æ¸…æ´—ä¸­...")
        self.log_view.clear()

        # å¯åŠ¨çº¿ç¨‹
        self.worker = IngestWorker(path, llm_config)
        self.worker.log_signal.connect(self.append_log)
        self.worker.finished_signal.connect(self.on_finished)
        self.worker.start()

    def append_log(self, text):
        self.log_view.append(text)
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        self.log_view.verticalScrollBar().setValue(
            self.log_view.verticalScrollBar().maximum()
        )

    def on_finished(self):
        self.start_btn.setEnabled(True)
        self.start_btn.setText("å¼€å§‹æ¸…æ´—å…¥åº“")
        InfoBar.success("å®Œæˆ", "æ¸…æ´—ä»»åŠ¡å·²ç»“æŸï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚", parent=self)

if __name__ == '__main__':
    app = QApplication(sys.argv)
    w = IngestWindow()
    w.show()
    sys.exit(app.exec())


========================================
File Path: .\scripts\ingest_preset.py
========================================

# scripts/ingest_preset.py
import json
import sqlite3
import re
import os
import sys
import uuid

# è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from core.database.vector_store import VectorStore
from core.llm.api_client import APILLM

RULES_DB_PATH = os.path.join(BASE_DIR, "data", "rules_preset.db")

SCHEMA_SQL = """
CREATE TABLE IF NOT EXISTS rule_fragments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT NOT NULL,
    raw_content TEXT,
    category TEXT,
    scope_type TEXT DEFAULT 'GLOBAL',
    scope_value TEXT,
    required_tags TEXT,
    summary TEXT,
    source_preset TEXT,
    is_active BOOLEAN DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
CREATE INDEX IF NOT EXISTS idx_rules_scope ON rule_fragments(scope_type, scope_value);
"""

PROMPT_DEEP_ANALYSIS = """
You are an expert Prompt Engineer and Data Architect.
Analyze the following raw preset fragment from "SillyTavern".

[Raw Text]
{raw_text}

[Tasks]
1. **Clean & Rewrite**: Remove all `{{...}}` variables, XML tags, and irrelevant glue text. Rewrite the core logic into a **clear, professional System Instruction** for an LLM.
2. **Categorize**: Choose ONE: STYLE, LOGIC, NSFW, SYSTEM, FORMAT, CONSTRAINT, OTHER.
3. **Tagging**: Extract 3-5 semantic tags.
4. **Scope**: When should this trigger? (e.g., GLOBAL, COMBAT, H_SCENE).
5. **Summary**: A one-sentence summary in Chinese.

[Output Format]
Strictly output valid JSON only:
{{
    "optimized_content": "Rewritten instruction...",
    "category": "STYLE",
    "tags": ["Tag1", "Tag2"],
    "scope": "GLOBAL",
    "summary": "ä¸­æ–‡æ‘˜è¦..."
}}
"""

class PresetIngester:
    def __init__(self, llm_config, log_callback=print):
        """
        :param llm_config: dict {"api_key": "...", "base_url": "...", "model": "..."}
        :param log_callback: function to handle log strings
        """
        self.log = log_callback
        self.conn = self._init_db()
        self.cursor = self.conn.cursor()
        self.vec_store = VectorStore(collection_name="rules_memory")
        
        # åˆå§‹åŒ– LLM
        self.log(f"æ­£åœ¨åˆå§‹åŒ–æ¸…æ´—æ¨¡åž‹: {llm_config.get('model')}...")
        self.llm = APILLM(llm_config)

    def _init_db(self):
        db_dir = os.path.dirname(RULES_DB_PATH)
        if not os.path.exists(db_dir): os.makedirs(db_dir)
        conn = sqlite3.connect(RULES_DB_PATH, check_same_thread=False)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å†æ¯æ¬¡éƒ½ Drop Tableï¼Œä»¥å…è¯¯åˆ æ•°æ®ï¼Œæ”¹ä¸ºç”±ç”¨æˆ·å†³å®šæ˜¯å¦æ¸…ç©º
        # å¦‚æžœéœ€è¦å¼ºåˆ¶æ¸…ç©ºï¼Œå¯ä»¥åœ¨å¤–éƒ¨æ‰‹åŠ¨æ‰§è¡Œ SQL
        conn.cursor().executescript(SCHEMA_SQL)
        conn.commit()
        return conn

    def extract_raw_content(self, text):
        matches = re.findall(r"\{\{setvar::.*?::([\s\S]*?)\}\}", text)
        if matches:
            return "\n".join(matches).strip()
        return text.strip()

    def _parse_json_response(self, response):
        try:
            return json.loads(response)
        except:
            match = re.search(r"```json(.*?)```", response, re.DOTALL)
            if match:
                try: return json.loads(match.group(1).strip())
                except: pass
            match = re.search(r"\{.*\}", response, re.DOTALL)
            if match:
                try: return json.loads(match.group(0).strip())
                except: pass
        return None

    def process_item(self, name, raw_text, source_name):
        content_to_analyze = self.extract_raw_content(raw_text)
        
        if len(content_to_analyze) < 5 or "åˆå§‹åŒ–å˜é‡" in name or "è¿‡æ¸¡" in name:
            self.log(f"â­ï¸ è·³è¿‡ (å†…å®¹è¿‡çŸ­æˆ–æ— å…³): {name}")
            return

        self.log(f"ðŸ’Ž æ­£åœ¨åˆ†æž: {name} ...")
        
        try:
            prompt = PROMPT_DEEP_ANALYSIS.format(raw_text=content_to_analyze[:10000])
            response = self.llm.generate([{"role": "user", "content": prompt}])
            analysis = self._parse_json_response(response)
            
            if not analysis:
                self.log("âŒ JSON è§£æžå¤±è´¥ï¼Œä½¿ç”¨åŽŸå§‹å†…å®¹é™çº§å¤„ç†ã€‚")
                analysis = {
                    "optimized_content": content_to_analyze,
                    "category": "OTHER",
                    "tags": [],
                    "scope": "GLOBAL",
                    "summary": name
                }
            else:
                self.log("âœ… åˆ†æžå®Œæˆã€‚")

        except Exception as e:
            self.log(f"âŒ API è¯·æ±‚é”™è¯¯: {e}")
            return

        # å…¥åº“
        opt_content = analysis.get("optimized_content", content_to_analyze)
        category = analysis.get("category", "OTHER")
        tags = analysis.get("tags", [])
        scope = analysis.get("scope", "GLOBAL")
        summary = analysis.get("summary", name)
        
        scope_value = name
        if "-" in name: scope_value = name.split("-")[-1].strip()
        
        is_active = 1 if category in ["SYSTEM", "CONSTRAINT"] else 0

        self.cursor.execute(
            """INSERT INTO rule_fragments 
               (content, raw_content, category, scope_type, scope_value, required_tags, summary, source_preset, is_active) 
               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)""",
            (opt_content, raw_text, category, scope, scope_value, json.dumps(tags, ensure_ascii=False), summary, source_name, is_active)
        )
        rule_id = self.cursor.lastrowid

        vec_id = f"rule_{rule_id}_{uuid.uuid4().hex[:6]}"
        meta = {
            "category": category,
            "tags": ",".join(tags),
            "scope": scope,
            "source": source_name,
            "summary": summary
        }
        vector_text = f"[{category}] {summary}\nTags: {', '.join(tags)}\n{opt_content}"
        
        self.vec_store.add_memory(vector_text, meta, vec_id)

    def ingest(self, json_path):
        self.log(f"ðŸ“‚ åŠ è½½æ–‡ä»¶: {json_path}")
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            self.log(f"âŒ JSON è¯»å–é”™è¯¯: {e}")
            return

        prompts = data.get('prompts', [])
        self.log(f"ðŸ” å‘çŽ° {len(prompts)} æ¡é¢„è®¾ã€‚å¼€å§‹æ¸…æ´—...")

        for p in prompts:
            if not p.get('enabled', False): continue
            name = p.get('name', 'Unknown')
            content = p.get('content', '')
            
            self.process_item(name, content, os.path.basename(json_path))
            
        self.conn.commit()
        self.log("ðŸŽ‰ æ¸…æ´—å…¥åº“å®Œæˆï¼")


========================================
File Path: .\scripts\test_harvester.py
========================================

# scripts/test_harvester.py
import sys
import os
import time

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.harvester.crawler import WebCrawler
from core.harvester.cleaner import LocalCleaner

def test_batch_pipeline():
    print("\n" + "="*50)
    print("ðŸ§ª æµ‹è¯•: å¤šæºèšåˆæŠ“å–æµç¨‹")
    print("="*50)
    
    keyword = "é»‘ç¥žè¯æ‚Ÿç©º ç¬¬ä¸‰ç«  å‰§æƒ…è§£æž"
    crawler = WebCrawler()
    cleaner = LocalCleaner()
    
    # 1. æŠ“å–
    print(f"1ï¸âƒ£ æ­£åœ¨æœç´¢å¹¶æŠ“å– 3 ä¸ªç½‘é¡µ: {keyword} ...")
    results = crawler.search_and_fetch(keyword, max_results=3)
    
    if not results:
        print("âŒ æŠ“å–å¤±è´¥")
        return

    print(f"ðŸ“¦ æˆåŠŸæŠ“å– {len(results)} ä¸ªç½‘é¡µã€‚")
    
    # 2. æž„é€ æ•°æ®
    batch_data = [{'source': r['domain'], 'text': r['content']} for r in results]
    
    # 3. èšåˆ
    print(f"2ï¸âƒ£ æ­£åœ¨å‘é€ç»™ LLM è¿›è¡Œèšåˆæ€»ç»“ (è¾“å…¥æ€»é•¿: {sum(len(x['text']) for x in batch_data)} å­—ç¬¦)...")
    start = time.time()
    summary = cleaner.clean_batch(batch_data, keyword)
    end = time.time()
    
    print(f"\nâ±ï¸ LLM è€—æ—¶: {end - start:.2f} ç§’")
    
    if summary:
        print("\nâœ… [æ·±åº¦ç™¾ç§‘æ¡ç›®]:")
        print("-" * 40)
        print(summary)
        print("-" * 40)
    else:
        print("âŒ èšåˆå¤±è´¥")

if __name__ == "__main__":
    test_batch_pipeline()

